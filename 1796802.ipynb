{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Homework 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gdown\n",
    "import zipfile\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded.\n"
     ]
    }
   ],
   "source": [
    "#Check if files exists in data folder\n",
    "if os.path.exists('data/'):\n",
    "    print('Files already downloaded.')\n",
    "\n",
    "else:\n",
    "    output_path = 'data.zip'\n",
    "    file_id = '1KDN-rFCq9IDJ7_kNW5y5Co100KNpklz-'\n",
    "    url = f'https://drive.google.com/uc?id={file_id}'\n",
    "    # Download the zip file\n",
    "    gdown.download(url, output_path, quiet=False)\n",
    "\n",
    "    # Extract the contents of the zip file\n",
    "    with zipfile.ZipFile(output_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall('data')\n",
    "\n",
    "    # Remove the zip file\n",
    "    os.remove(output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already extracted\n"
     ]
    }
   ],
   "source": [
    "if(os.path.exists('test/') and os.path.exists('train')):\n",
    "    print('Files already extracted')\n",
    "else:\n",
    "    print('Extracting the test.zip and train.zip files...')\n",
    "    # Extract the test.zip file\n",
    "    with zipfile.ZipFile('data/public/test.zip', 'r') as zip_ref:\n",
    "        zip_ref.extractall()\n",
    "\n",
    "    # Extract the train.zip file\n",
    "    with zipfile.ZipFile('data/public/train.zip', 'r') as zip_ref:\n",
    "        zip_ref.extractall()\n",
    "\n",
    "    print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Approach\n",
    "\n",
    "For the first approach, we will use a different architecture to train our model. We will use a custom convolutional neural network (CNN) architecture.\n",
    "\n",
    "### Step 1: Data Loading and Preprocessing\n",
    "\n",
    "Similar to the first approach, we will load and preprocess our dataset using the same transformations. We will also create data loaders for the training and validation sets.\n",
    "\n",
    "### Step 2: Model Architecture\n",
    "\n",
    "In this approach, we will define a custom CNN model. The model will consist of multiple convolutional layers followed by fully connected layers. We will use ReLU activation functions and dropout regularization to prevent overfitting.\n",
    "\n",
    "### Step 3: Training Loop\n",
    "\n",
    "We will train the model using a similar training loop as in the first approach. We will iterate over the training set, compute the loss, perform backpropagation, and update the model's weights.\n",
    "\n",
    "### Step 4: Model Evaluation\n",
    "\n",
    "After training, we will evaluate the model on the validation set. We will calculate the accuracy of the model by comparing the predicted labels with the ground truth labels.\n",
    "\n",
    "### Step 5: Save the Model\n",
    "\n",
    "Finally, we will save the trained model to a file for future use.\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "In this second approach, we used a custom CNN architecture to train our model. This approach allows us to have more control over the model's architecture and potentially achieve better performance. However, it requires more manual design and experimentation compared to using a pre-trained model like ResNet18.\n",
    "\n",
    "It is important to note that the choice of architecture depends on the specific problem and dataset. It is recommended to experiment with different architectures and hyperparameters to find the best model for your task.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 5095 training images\n",
      "Loaded 1274 validation images\n",
      "Device: cuda\n",
      "Input Shape: torch.Size([64, 3, 96, 96])\n",
      "Input Shape Validation: torch.Size([64, 3, 96, 96])\n",
      "Number of Classes: 5\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "# Define directories for training and validation data\n",
    "train_dir = 'train'\n",
    "val_dir = 'test'  \n",
    "\n",
    "# Define the data transformations\n",
    "common_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    common_transform\n",
    "])\n",
    "\n",
    "# No augmentation for validation\n",
    "val_transform = common_transform\n",
    "\n",
    "# Load datasets\n",
    "full_dataset = ImageFolder(root=train_dir, transform=train_transform)\n",
    "\n",
    "# Split into training and validation datasets\n",
    "train_size = int(0.8 * len(full_dataset))\n",
    "val_size = len(full_dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n",
    "\n",
    "print('Loaded', len(train_dataset), 'training images')\n",
    "print('Loaded', len(val_dataset), 'validation images')\n",
    "\n",
    "num_workers = 2\n",
    "\n",
    "# Use GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('Device:', device)\n",
    "\n",
    "# Create data loaders\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "# Get Input Shape from train_loader and val_loader\n",
    "input_shape = next(iter(train_loader))[0].shape\n",
    "input_shape_val = next(iter(val_loader))[0].shape\n",
    "num_classes = len(train_dataset.dataset.classes)\n",
    "print('Input Shape:', input_shape)\n",
    "print('Input Shape Validation:', input_shape_val)\n",
    "print('Number of Classes:', num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 5])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class MyCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(MyCNN, self).__init__()\n",
    "\n",
    "        # Adjust the input channels in the first Conv2d layer\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # Second Conv2d layer\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # Third Conv2d layer\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # Flatten\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(128 * 12 * 12, 256)\n",
    "        self.bn4 = nn.BatchNorm1d(256)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.bn5 = nn.BatchNorm1d(128)\n",
    "        self.relu5 = nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "\n",
    "        # Output layer\n",
    "        self.fc3 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x / 255.0  # Normalize input to the range [0, 1]\n",
    "        x = self.pool1(self.relu1(self.bn1(self.conv1(x))))\n",
    "        x = self.pool2(self.relu2(self.bn2(self.conv2(x))))\n",
    "        x = self.pool3(self.relu3(self.bn3(self.conv3(x))))\n",
    "        x = self.flatten(x)\n",
    "        x = self.dropout1(self.relu4(self.bn4(self.fc1(x))))\n",
    "        x = self.dropout2(self.relu5(self.bn5(self.fc2(x))))\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "# Create an instance of the model\n",
    "model = MyCNN(num_classes)\n",
    "\n",
    "# Use GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Example of using the model with random input\n",
    "random_input = torch.randn(64, 3, 96, 96).to(device)  # Correct input size\n",
    "output = model(random_input)\n",
    "print(output.shape)  # Check the output shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Loss: 1.2996817335486412\n",
      "Validation Loss: 1.6357459425926208, Validation Accuracy: 0.260596546310832\n",
      "Epoch 2/100, Loss: 1.1988581441342832\n",
      "Validation Loss: 1.2179329514503479, Validation Accuracy: 0.5416012558869702\n",
      "Epoch 3/100, Loss: 1.1592801868915559\n",
      "Validation Loss: 1.389476579427719, Validation Accuracy: 0.4050235478806907\n",
      "Epoch 4/100, Loss: 1.1216984994709491\n",
      "Validation Loss: 1.8209225237369537, Validation Accuracy: 0.29748822605965464\n",
      "Epoch 5/100, Loss: 1.1160398155450821\n",
      "Validation Loss: 1.4636202692985534, Validation Accuracy: 0.3673469387755102\n",
      "Epoch 6/100, Loss: 1.0697466015815735\n",
      "Validation Loss: 1.0064929574728012, Validation Accuracy: 0.6248037676609105\n",
      "Epoch 7/100, Loss: 1.040901967138052\n",
      "Validation Loss: 0.980846843123436, Validation Accuracy: 0.631083202511774\n",
      "Epoch 8/100, Loss: 1.0362601466476917\n",
      "Validation Loss: 1.015329474210739, Validation Accuracy: 0.6185243328100472\n",
      "Epoch 9/100, Loss: 1.0129684954881668\n",
      "Validation Loss: 1.0329231947660447, Validation Accuracy: 0.619309262166405\n",
      "Epoch 10/100, Loss: 1.002790555357933\n",
      "Validation Loss: 1.0141897737979888, Validation Accuracy: 0.6397174254317112\n",
      "Epoch 11/100, Loss: 0.9882139168679714\n",
      "Validation Loss: 0.9526306957006454, Validation Accuracy: 0.6491365777080063\n",
      "Epoch 12/100, Loss: 0.9919850409030915\n",
      "Validation Loss: 0.949547466635704, Validation Accuracy: 0.6514913657770801\n",
      "Epoch 13/100, Loss: 0.9952303379774093\n",
      "Validation Loss: 0.9488356471061706, Validation Accuracy: 0.652276295133438\n",
      "Epoch 14/100, Loss: 0.9756789207458496\n",
      "Validation Loss: 0.9510901927947998, Validation Accuracy: 0.6514913657770801\n",
      "Epoch 15/100, Loss: 0.997976191341877\n",
      "Validation Loss: 0.9496422171592712, Validation Accuracy: 0.6530612244897959\n",
      "Epoch 16/100, Loss: 0.9779167741537094\n",
      "Validation Loss: 0.9525787889957428, Validation Accuracy: 0.6585557299843015\n",
      "Epoch 17/100, Loss: 0.9928357206285\n",
      "Validation Loss: 0.9470130681991578, Validation Accuracy: 0.6546310832025117\n",
      "Epoch 18/100, Loss: 0.986059432476759\n",
      "Validation Loss: 0.9561532080173493, Validation Accuracy: 0.6546310832025117\n",
      "Epoch 19/100, Loss: 0.986759851872921\n",
      "Validation Loss: 0.9514537930488587, Validation Accuracy: 0.6499215070643642\n",
      "Epoch 20/100, Loss: 0.9791184194386006\n",
      "Validation Loss: 0.9535630106925964, Validation Accuracy: 0.6467817896389325\n",
      "Epoch 21/100, Loss: 0.9759653687477112\n",
      "Validation Loss: 0.9431435465812683, Validation Accuracy: 0.6585557299843015\n",
      "Epoch 22/100, Loss: 0.9827773615717887\n",
      "Validation Loss: 0.9513484090566635, Validation Accuracy: 0.6577708006279435\n",
      "Epoch 23/100, Loss: 0.982205655425787\n",
      "Validation Loss: 0.9502778619527816, Validation Accuracy: 0.6530612244897959\n",
      "Epoch 24/100, Loss: 0.9903974212706089\n",
      "Validation Loss: 0.9509538233280181, Validation Accuracy: 0.6538461538461539\n",
      "Epoch 25/100, Loss: 0.9831824935972691\n",
      "Validation Loss: 0.9524009495973587, Validation Accuracy: 0.6475667189952904\n",
      "Epoch 26/100, Loss: 0.9901371337473392\n",
      "Validation Loss: 0.948007532954216, Validation Accuracy: 0.6507064364207221\n",
      "Early stopping after 26 epochs.\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "# Optimizer, scheduler, and criterion\n",
    "optimizer = optim.RMSprop(model.parameters(), lr=0.001)\n",
    "scheduler = StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 100\n",
    "best_val_accuracy = 0.0\n",
    "early_stopping_patience = 10\n",
    "early_stopping_counter = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    average_loss = running_loss / len(train_loader)\n",
    "    print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {average_loss}')\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_running_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for val_images, val_labels in val_loader:\n",
    "            val_images, val_labels = val_images.to(device), val_labels.to(device)\n",
    "            val_outputs = model(val_images)\n",
    "            val_loss = criterion(val_outputs, val_labels)\n",
    "            val_running_loss += val_loss.item()\n",
    "\n",
    "            _, predicted = torch.max(val_outputs.data, 1)\n",
    "            total_samples += val_labels.size(0)\n",
    "            correct_predictions += (predicted == val_labels).sum().item()\n",
    "\n",
    "    val_accuracy = correct_predictions / total_samples\n",
    "    average_val_loss = val_running_loss / len(val_loader)\n",
    "    print(f'Validation Loss: {average_val_loss}, Validation Accuracy: {val_accuracy}')\n",
    "\n",
    "    # Adjust learning rate with scheduler\n",
    "    scheduler.step()\n",
    "\n",
    "    # Early stopping\n",
    "    if val_accuracy > best_val_accuracy:\n",
    "        best_val_accuracy = val_accuracy\n",
    "        early_stopping_counter = 0\n",
    "    else:\n",
    "        early_stopping_counter += 1\n",
    "\n",
    "    if early_stopping_counter >= early_stopping_patience:\n",
    "        print(f'Early stopping after {epoch + 1} epochs.')\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'MyCNN.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load model from file\n",
    "#model = MyCNN(num_classes)\n",
    "#model.load_state_dict(torch.load('MyCNN.pth'))\n",
    "#model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment: CarRacing-v2\n",
      "Action space: Discrete(5)\n",
      "Observation space: Box(0, 255, (96, 96, 3), uint8)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "try:\n",
    "    import gymnasium as gym\n",
    "except ModuleNotFoundError:\n",
    "    print('gymnasium module not found. Try to install with')\n",
    "    print('pip install gymnasium[box2d]')\n",
    "    sys.exit(1)\n",
    "\n",
    "\n",
    "def play(env, model):\n",
    "\n",
    "    seed = 2000\n",
    "    obs, _ = env.reset(seed=seed)\n",
    "    \n",
    "    # drop initial frames\n",
    "    action0 = 0\n",
    "    for i in range(50):\n",
    "        obs,_,_,_,_ = env.step(action0)\n",
    "    \n",
    "    done = False\n",
    "    while not done:\n",
    "         # Print and normalize the observation\n",
    "        obs = torch.from_numpy(obs).float().to(device) / 255.0\n",
    "        obs = obs.permute(2, 0, 1).unsqueeze(0)  # Adjust the dimensions for the model\n",
    "        p = model(obs)  # Adapt to your model\n",
    "        action = np.argmax(p.cpu().detach().numpy())  # Adapt to your model\n",
    "        obs, _, terminated, truncated, _ = env.step(action)\n",
    "        done = terminated or truncated\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "env_arguments = {\n",
    "    'domain_randomize': False,\n",
    "    'continuous': False,\n",
    "    'render_mode': 'human'\n",
    "}\n",
    "\n",
    "env_name = 'CarRacing-v2'\n",
    "env = gym.make(env_name, **env_arguments)\n",
    "\n",
    "print(\"Environment:\", env_name)\n",
    "print(\"Action space:\", env.action_space)\n",
    "print(\"Observation space:\", env.observation_space)\n",
    "\n",
    "play(env, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second Approach: Deep Reinforcement Learning (DRL)\n",
    "\n",
    "In this approach, we will utilize Deep Reinforcement Learning (DRL) techniques to solve our problem. DRL combines the power of deep neural networks with reinforcement learning algorithms to learn optimal policies in complex environments.\n",
    "\n",
    "### Step 1: Environment Setup\n",
    "\n",
    "First, we need to define our environment. This includes selecting an appropriate gym environment or creating a custom environment that suits our problem. The environment should provide observations, actions, and rewards.\n",
    "\n",
    "### Step 2: Agent Design\n",
    "\n",
    "Next, we design our DRL agent. The agent consists of a deep neural network, often referred to as the Q-network, which takes observations as input and outputs action values for each possible action. We can use popular deep learning frameworks like PyTorch or TensorFlow to implement the Q-network.\n",
    "\n",
    "### Step 3: Training Loop\n",
    "\n",
    "The training loop involves the following steps:\n",
    "\n",
    "1. Initialize the Q-network with random weights.\n",
    "2. Observe the current state from the environment.\n",
    "3. Select an action using an exploration-exploitation strategy, such as epsilon-greedy or softmax.\n",
    "4. Execute the selected action in the environment and observe the next state and reward.\n",
    "5. Update the Q-network using the observed state, action, next state, and reward.\n",
    "6. Repeat steps 2-5 until convergence or a maximum number of iterations.\n",
    "\n",
    "During training, we can use techniques like experience replay and target networks to stabilize and improve the learning process.\n",
    "\n",
    "### Step 4: Evaluation\n",
    "\n",
    "After training, we evaluate the performance of our agent by running it in the environment and measuring its performance metrics, such as average reward or success rate. This helps us assess the effectiveness of our DRL approach.\n",
    "\n",
    "### Step 5: Fine-tuning and Optimization\n",
    "\n",
    "Based on the evaluation results, we can fine-tune and optimize our DRL approach. This may involve adjusting hyperparameters, modifying the network architecture, or trying different exploration-exploitation strategies.\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "Deep Reinforcement Learning (DRL) offers a powerful approach to solving complex problems by combining deep neural networks with reinforcement learning algorithms. By following the steps outlined above, we can develop and train a DRL agent to learn optimal policies in our environment. However, it is important to note that DRL can be computationally intensive and may require significant computational resources and time for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "    def __init__(self, n_frames, n_actions, h_dimension):\n",
    "        super(DQN, self).__init__()\n",
    "\n",
    "        # CNN\n",
    "        self.layers_cnn = nn.Sequential(\n",
    "            nn.Conv2d(n_frames, 6, kernel_size=(7, 7), stride=3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2, 2)),\n",
    "            nn.Conv2d(6, 12, kernel_size=(4, 4)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2, 2)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(432, h_dimension),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(h_dimension, n_actions)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        o = self.layers_cnn(x)  # (BS, ACTIONS)\n",
    "        return o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from collections import deque\n",
    "import numpy as np\n",
    "\n",
    "class DQNAgent:\n",
    "    def __init__(self,\n",
    "                 action_space,\n",
    "                 epsilon=1.0,\n",
    "                 gamma=0.95,\n",
    "                 epsilon_min=0.1,\n",
    "                 epsilon_decay=0.9999,\n",
    "                 lr=1e-3,\n",
    "                 memory_len=5000,\n",
    "                 frames=3,\n",
    "                 hidden_dimension=None,\n",
    "                 device=None):\n",
    "\n",
    "        self.device = device\n",
    "        self.epsilon = epsilon\n",
    "        self.gamma = gamma\n",
    "        self.epsilon_min = epsilon_min\n",
    "        self.epsilon_decay = epsilon_decay\n",
    "        self.memory_len = memory_len\n",
    "        self.lr = lr\n",
    "        self.memory = deque(maxlen=self.memory_len)\n",
    "        self.action_space = action_space\n",
    "\n",
    "        self.target_model = DQN(frames, len(self.action_space), hidden_dimension).to(self.device)\n",
    "        self.model =        DQN(frames, len(self.action_space), hidden_dimension).to(self.device)\n",
    "\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=self.lr)\n",
    "\n",
    "    def update_target_model(self):\n",
    "        self.target_model.load_state_dict(self.model.state_dict())\n",
    "\n",
    "    def is_explore(self):\n",
    "        flip = np.random.rand() <= self.epsilon\n",
    "        return flip\n",
    "\n",
    "    def act(self, state, is_only_random=False, is_only_exploit=False):\n",
    "        if not is_only_exploit and self.is_explore() or is_only_random:\n",
    "            action_index = np.random.randint(len(self.action_space))\n",
    "            # print(action_index, self.ACTION_SPACE[action_index])\n",
    "        else:\n",
    "            q_values = self.target_model(state)[0]\n",
    "            action_index = torch.argmax(q_values)\n",
    "            # print(\"predicted action\", action_index)\n",
    "        return self.action_space[action_index]\n",
    "\n",
    "    def memorize(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, self.action_space.index(action), reward, next_state, done))\n",
    "\n",
    "    def replay(self, batch_size):\n",
    "        minibatch = random.sample(self.memory, batch_size)\n",
    "        train_state = []\n",
    "        train_target = []\n",
    "\n",
    "        for state, action_index, reward, next_state, done in minibatch:\n",
    "            # state = torch.Tensor(state)\n",
    "            target = self.model(state)[0]\n",
    "            train_state.append(target)\n",
    "\n",
    "            target_copy = target.detach().clone().to(self.device)\n",
    "            if done:\n",
    "                target_copy[action_index] = reward\n",
    "            else:\n",
    "                t = self.target_model(next_state)[0]\n",
    "                target_copy[action_index] = reward + self.gamma * torch.max(t)\n",
    "            train_target.append(target_copy)\n",
    "\n",
    "        # Actual training\n",
    "        criterion = nn.MSELoss()\n",
    "        pred, tru = torch.stack(train_state), torch.stack(train_target)\n",
    "        loss = criterion(pred, tru)\n",
    "\n",
    "        # Optimize the model\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "\n",
    "    def load_model(self, name):\n",
    "        self.model = torch.load(name)\n",
    "        self.target_model = torch.load(name)\n",
    "        self.model.eval()\n",
    "\n",
    "    def save_model(self, name):\n",
    "        torch.save(self.target_model, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "\n",
    "    SEED = 1\n",
    "\n",
    "    STARTING_EPISODE_TRAIN = 0\n",
    "    ENDING_EPISODE_TRAIN = STARTING_EPISODE_TRAIN + 1000\n",
    "\n",
    "    STARTING_EPISODE_TEST = ENDING_EPISODE_TRAIN + 1\n",
    "    ENDING_EPISODE_TEST = STARTING_EPISODE_TEST + 100\n",
    "\n",
    "    SKIP_FRAMES = 2\n",
    "    TRAINING_BATCH_SIZE = 64\n",
    "    UPDATE_TARGET_MODEL_FREQUENCY = 5\n",
    "    N_FRAMES = 3\n",
    "    HIDDEN_DIMENSION_FC = 150\n",
    "\n",
    "    GAS_WEIGHT = 1.3\n",
    "\n",
    "    ACTION_SPACE = [\n",
    "        (-1, 1, 0.2), (0, 1, 0.2), (1, 1, 0.2),  # .  Action Space Structure\n",
    "        (-1, 1, 0), (0, 1, 0), (1, 1, 0),        # (Steering Wheel, Gas, Break)\n",
    "        (-1, 0, 0.2), (0, 0, 0.2), (1, 0, 0.2),  # .  -1~1     0~1        0~1\n",
    "        (-1, 0, 0), (0, 0, 0), (1, 0, 0)\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "from datetime import datetime\n",
    "import cv2\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import json\n",
    "\n",
    "\n",
    "def write_json_to_file(data, file_path):\n",
    "    \"\"\"\n",
    "    Write JSON data to a file.\n",
    "\n",
    "    Parameters:\n",
    "    - data: A dictionary representing the JSON data.\n",
    "    - file_path: The path where the JSON file will be written.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'w') as json_file:\n",
    "            json.dump(data, json_file, indent=4)\n",
    "        print(f\"JSON data successfully written to {file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error writing JSON data to {file_path}: {e}\")\n",
    "\n",
    "\n",
    "def read_json_from_file(file_path):\n",
    "    \"\"\"\n",
    "    Read JSON data from a file.\n",
    "\n",
    "    Parameters:\n",
    "    - file_path: The path of the JSON file to be read.\n",
    "\n",
    "    Returns:\n",
    "    - A dictionary representing the JSON data.\n",
    "    - If there is an error reading the file, returns None.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r') as json_file:\n",
    "            data = json.load(json_file)\n",
    "        print(f\"JSON data successfully read from {file_path}\")\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading JSON data from {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def make_all_paths(is_dynamic_root=True, dir_name=\"rl_class\"):\n",
    "    ROOT = \"data\"\n",
    "\n",
    "    if is_dynamic_root:\n",
    "        date_str = datetime.now().strftime(\"%m-%d-%Y_%H-%M-%S\")\n",
    "        dir_name = \"rl_class_{}\".format(date_str)\n",
    "    else:\n",
    "        dir_name = dir_name\n",
    "\n",
    "    path_root = ROOT + \"/\" + dir_name + \"/\"\n",
    "    dirs = [\"models\", \"plots\", \"videos\"]\n",
    "    for d in dirs:\n",
    "        path = path_root + d\n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path)\n",
    "        print(\">> Created dir\", path)\n",
    "    return path_root\n",
    "\n",
    "\n",
    "def plot_state_car(data, title=None):\n",
    "    assert len(data.shape) == 3, \"Can only handle 3D mats.\"\n",
    "    assert data.shape[0] < 10, \"Too many states to plot. Adjust the plots position first.\"\n",
    "\n",
    "    # Create a figure with three subplots\n",
    "    fig, axs = plt.subplots(1, data.shape[0], figsize=(10, 4))\n",
    "\n",
    "    # Plot each image using imshow()\n",
    "    for i in range(data.shape[0]):\n",
    "        axs[i].imshow(data[i], cmap='gray')  # You can adjust the colormap if needed\n",
    "        axs[i].axis('off')                   # Turn off axis labels\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_frame_car(data, title=None):\n",
    "    plt.imshow(data, cmap=\"gray\")  # You can adjust the colormap if needed\n",
    "    plt.axis('off')  # Turn off axis labels\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def preprocess_frame_car(frame):\n",
    "    def crop(frame):\n",
    "        # Crop to 84x84\n",
    "        return frame[:-12, 6:-6]\n",
    "\n",
    "    def make_img_gray(frame):\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        return frame\n",
    "\n",
    "    def normalize(frame):\n",
    "        return frame / 255.0\n",
    "\n",
    "    # frame = crop(frame)\n",
    "    frame = make_img_gray(frame)\n",
    "    frame = frame.astype(float)\n",
    "    frame = normalize(frame)\n",
    "    # frame = frame * 2 - 1   # maps [0,1] to [-1,1]\n",
    "    return frame\n",
    "\n",
    "\n",
    "def seed_everything(seed=42):\n",
    "    # Set seed for Python random module\n",
    "    random.seed(seed)\n",
    "\n",
    "    # Set seed for NumPy\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # Set seed for PyTorch\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False  # disable if deterministic mode is desired\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#import cv2   # open cv\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "import gymnasium as gym\n",
    "from collections import deque\n",
    "import numpy as np\n",
    "from gymnasium.wrappers import RecordVideo\n",
    "\n",
    "\n",
    "def train_car_racing():\n",
    "    seed_everything(seed=Config.SEED)\n",
    "    PATH_ROOT = make_all_paths(is_dynamic_root=True)\n",
    "    write_json_to_file(dict(Config.__dict__), file_path=PATH_ROOT + \"config.json\")\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print('>> Using device:', device)\n",
    "\n",
    "    agent = DQNAgent(frames=Config.N_FRAMES, action_space=Config.ACTION_SPACE, device=device,\n",
    "                     hidden_dimension=Config.HIDDEN_DIMENSION_FC)\n",
    "\n",
    "    # https://www.gymlibrary.dev/environments/box2d/car_racing/\n",
    "    env = gym.make('CarRacing-v2', render_mode=\"rgb_array\")  # , render_mode='human')\n",
    "    env = RecordVideo(env, PATH_ROOT + 'videos', episode_trigger=lambda x: x % Config.UPDATE_TARGET_MODEL_FREQUENCY == 0)\n",
    "\n",
    "    epi_total_rewards = []\n",
    "    for e in range(Config.STARTING_EPISODE_TRAIN, Config.ENDING_EPISODE_TRAIN + 1):\n",
    "        env.episode_id = e\n",
    "\n",
    "        epi_total_reward = 0\n",
    "        epi_negative_reward_counter = 0\n",
    "        epi_time_frame_counter = 1\n",
    "        epi_done = False\n",
    "\n",
    "        init_state = env.reset(seed=e)[0]  # 96, 96, 3 pixels image RGB\n",
    "        init_state = preprocess_frame_car(init_state)  # 96, 96 pixels image GRAY\n",
    "\n",
    "        # (1) EVALUATE STATE: S\n",
    "        state_queue = deque([init_state] * Config.N_FRAMES, maxlen=Config.N_FRAMES)\n",
    "        # plot_state_car(np.array(state_queue))  # visualize S0\n",
    "\n",
    "        while True:\n",
    "            state_tensor = torch.Tensor(np.array(state_queue)).unsqueeze(0).to(device)\n",
    "            action = agent.act(state_tensor)\n",
    "\n",
    "            # (2) EXECUTE ACTION (for several steps)\n",
    "            # (3) EVALUATE S' STATE, REWARD\n",
    "            reward = 0\n",
    "            for _ in range(Config.SKIP_FRAMES):\n",
    "                # execute action\n",
    "                next_state, r, epi_done, _, _ = env.step(action)\n",
    "                # plot_frame_car(next_state)\n",
    "                reward += r\n",
    "                if epi_done:\n",
    "                    break\n",
    "\n",
    "            # (4) ADJUST REWARD\n",
    "            # if getting negative reward 10 times after the tolerance steps, terminate this episode\n",
    "            if epi_time_frame_counter > 100 and reward < 0:\n",
    "                epi_negative_reward_counter += 1\n",
    "            else:\n",
    "                epi_negative_reward_counter = 0\n",
    "\n",
    "            # extra bonus for the model if it uses full gas\n",
    "            if action[1] == 1 and action[2] == 0:\n",
    "                reward *= Config.GAS_WEIGHT\n",
    "\n",
    "            epi_total_reward += reward\n",
    "\n",
    "            # plot_state_car(np.array(state_queue), title=\"STATE 0\")\n",
    "            # process state S'\n",
    "            next_state = preprocess_frame_car(next_state)\n",
    "            next_state_queue = deque([frame for frame in state_queue], maxlen=Config.N_FRAMES)\n",
    "            next_state_queue.append(next_state)\n",
    "            # plot_state_car(np.array(next_state_queue), title=\"STATE 1\")\n",
    "\n",
    "            next_state_tensor = torch.Tensor(np.array(next_state_queue)).unsqueeze(0).to(device)\n",
    "\n",
    "            # (5) STORE OBSERVATIONS\n",
    "            # Memorizing saving state, action reward tuples\n",
    "            agent.memorize(state_tensor, action, reward, next_state_tensor, epi_done)\n",
    "\n",
    "            # S = S'\n",
    "            state_queue = next_state_queue\n",
    "\n",
    "            # early stop if the number of\n",
    "            if epi_negative_reward_counter >= 25 or epi_total_reward < 0:\n",
    "                break\n",
    "\n",
    "            # (6) TRAIN ON BATCHES OF OBSERVATIONS\n",
    "            # train the model with tuple, if there are enough tuples\n",
    "            if len(agent.memory) > Config.TRAINING_BATCH_SIZE:\n",
    "                agent.replay(Config.TRAINING_BATCH_SIZE)\n",
    "\n",
    "            epi_time_frame_counter += 1\n",
    "        epi_total_rewards += [epi_total_reward]\n",
    "\n",
    "        # >>> ON EPISODE END\n",
    "        # print stats\n",
    "        stats_string = 'Episode: {}/{}, Scores(Time Frames): {}, Total Rewards: {:.2}, Epsilon: {:.2}'\n",
    "        print(stats_string.format(\n",
    "            e,\n",
    "            Config.ENDING_EPISODE_TRAIN,\n",
    "            epi_time_frame_counter,\n",
    "            float(epi_total_reward),\n",
    "            float(agent.epsilon))\n",
    "        )\n",
    "\n",
    "        if e % Config.UPDATE_TARGET_MODEL_FREQUENCY == 0:\n",
    "            # plot rewards stats\n",
    "            plt.plot(epi_total_rewards, label=\"cum rew\", color=\"blue\")\n",
    "            plt.title(\"Rewards during episode episode\")\n",
    "            plt.savefig(PATH_ROOT + 'plots/reward_{}.pdf'.format(e))\n",
    "\n",
    "            # save model frequently\n",
    "            agent.save_model(PATH_ROOT + 'models/trial_{}.h5'.format(e))\n",
    "\n",
    "            # swap model\n",
    "            agent.update_target_model()\n",
    "            write_json_to_file({\"CUM_REW\": epi_total_rewards}, PATH_ROOT + \"/stats.json\")\n",
    "\n",
    "    env.close()\n",
    "\n",
    "\n",
    "#train_car_racing()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
