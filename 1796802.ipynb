{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Homework 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gdown\n",
    "import zipfile\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded.\n"
     ]
    }
   ],
   "source": [
    "#Check if files exists in data folder\n",
    "if os.path.exists('data/'):\n",
    "    print('Files already downloaded.')\n",
    "\n",
    "else:\n",
    "    output_path = 'data.zip'\n",
    "    file_id = '1KDN-rFCq9IDJ7_kNW5y5Co100KNpklz-'\n",
    "    url = f'https://drive.google.com/uc?id={file_id}'\n",
    "    # Download the zip file\n",
    "    gdown.download(url, output_path, quiet=False)\n",
    "\n",
    "    # Extract the contents of the zip file\n",
    "    with zipfile.ZipFile(output_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall('data')\n",
    "\n",
    "    # Remove the zip file\n",
    "    os.remove(output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already extracted\n"
     ]
    }
   ],
   "source": [
    "if(os.path.exists('test/') and os.path.exists('train')):\n",
    "    print('Files already extracted')\n",
    "else:\n",
    "    print('Extracting the test.zip and train.zip files...')\n",
    "    # Extract the test.zip file\n",
    "    with zipfile.ZipFile('data/public/test.zip', 'r') as zip_ref:\n",
    "        zip_ref.extractall()\n",
    "\n",
    "    # Extract the train.zip file\n",
    "    with zipfile.ZipFile('data/public/train.zip', 'r') as zip_ref:\n",
    "        zip_ref.extractall()\n",
    "\n",
    "    print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Approach\n",
    "\n",
    "For the first approach, we will use a different architecture to train our model. We will use a custom convolutional neural network (CNN) architecture.\n",
    "\n",
    "### Step 1: Data Loading and Preprocessing\n",
    "\n",
    "Similar to the first approach, we will load and preprocess our dataset using the same transformations. We will also create data loaders for the training and validation sets.\n",
    "\n",
    "### Step 2: Model Architecture\n",
    "\n",
    "In this approach, we will define a custom CNN model. The model will consist of multiple convolutional layers followed by fully connected layers. We will use ReLU activation functions and dropout regularization to prevent overfitting.\n",
    "\n",
    "### Step 3: Training Loop\n",
    "\n",
    "We will train the model using a similar training loop as in the first approach. We will iterate over the training set, compute the loss, perform backpropagation, and update the model's weights.\n",
    "\n",
    "### Step 4: Model Evaluation\n",
    "\n",
    "After training, we will evaluate the model on the validation set. We will calculate the accuracy of the model by comparing the predicted labels with the ground truth labels.\n",
    "\n",
    "### Step 5: Save the Model\n",
    "\n",
    "Finally, we will save the trained model to a file for future use.\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "In this second approach, we used a custom CNN architecture to train our model. This approach allows us to have more control over the model's architecture and potentially achieve better performance. However, it requires more manual design and experimentation compared to using a pre-trained model like ResNet18.\n",
    "\n",
    "It is important to note that the choice of architecture depends on the specific problem and dataset. It is recommended to experiment with different architectures and hyperparameters to find the best model for your task.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Dataset: Dataset ImageFolder\n",
      "    Number of datapoints: 6369\n",
      "    Root location: train\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               RandomHorizontalFlip(p=0.5)\n",
      "               ToTensor()\n",
      "               Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
      "           )\n",
      "Validation Dataset: Dataset ImageFolder\n",
      "    Number of datapoints: 2749\n",
      "    Root location: test\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               ToTensor()\n",
      "               Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
      "           )\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Device: cuda\n",
      "Input Shape: torch.Size([64, 3, 96, 96])\n",
      "Input Shape Validation: torch.Size([64, 3, 96, 96])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "# Step 1: Data Loading and Preprocessing\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),  # Randomly flip the image horizontally\n",
    "    transforms.ToTensor(),  # Convert the image to a PyTorch tensor\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Normalize the image\n",
    "])\n",
    "\n",
    "# Define data transformations for validation (you can modify these based on your needs)\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Convert the image to a PyTorch tensor\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Normalize the image\n",
    "])\n",
    "\n",
    "# Load your dataset (adjust this based on your dataset structure)\n",
    "train_dataset = ImageFolder(root='train' , transform=train_transform)\n",
    "val_dataset = ImageFolder(root='test' , transform=val_transform)\n",
    "\n",
    "print('Train Dataset:', train_dataset)\n",
    "print('Validation Dataset:', val_dataset)\n",
    "print('\\n\\n\\n')\n",
    "\n",
    "num_workers = 2\n",
    "\n",
    "# Use GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('Device:', device)\n",
    "\n",
    "# Create data loaders to load data batches for training and validation\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=num_workers)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "# Get Input Shape from train_loader and validate_loader\n",
    "input_shape = next(iter(train_loader))[0].shape\n",
    "input_shape_val = next(iter(val_loader))[0].shape\n",
    "print('Input Shape:', input_shape)\n",
    "print('Input Shape Validation:', input_shape_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, input_shape, num_classes):\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        # Calculate the flattened size based on input_shape\n",
    "        flattened_size = input_shape[1] * input_shape[2] * input_shape[3]\n",
    "\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(flattened_size, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(128, 96),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(96, num_classes),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.layers(x)\n",
    "        return output\n",
    "\n",
    "# Correct Input Shape: torch.Size([64, 3, 96, 96])\n",
    "num_classes = 5\n",
    "\n",
    "# Create an instance of your CNN model\n",
    "model = CNN(input_shape, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example forward pass\n",
    "image_batch = torch.randn(64, 3, 96, 96)  # Example image batch\n",
    "label_batch = torch.randint(5, (64,))  # Example label batch\n",
    "output = model(image_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Loss: 1.5403588688373566\n",
      "Epoch 2/50, Loss: 1.4775311195850371\n",
      "Epoch 3/50, Loss: 1.4499806320667268\n",
      "Epoch 4/50, Loss: 1.4362401926517487\n",
      "Epoch 5/50, Loss: 1.4254686391353608\n",
      "Epoch 6/50, Loss: 1.4131470501422883\n",
      "Epoch 7/50, Loss: 1.4016046559810638\n",
      "Epoch 8/50, Loss: 1.3869520545005798\n",
      "Epoch 9/50, Loss: 1.3809609949588775\n",
      "Epoch 10/50, Loss: 1.377813310623169\n",
      "Epoch 11/50, Loss: 1.370360723733902\n",
      "Epoch 12/50, Loss: 1.3612689685821533\n",
      "Epoch 13/50, Loss: 1.3613256561756133\n",
      "Epoch 14/50, Loss: 1.3555573856830596\n",
      "Epoch 15/50, Loss: 1.3557213306427003\n",
      "Epoch 16/50, Loss: 1.3536635279655456\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()  \u001b[38;5;66;03m# Set the model to training mode\u001b[39;00m\n\u001b[0;32m     15\u001b[0m running_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m---> 17\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m:\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Assuming you have a DataLoader for your training set\u001b[39;49;00m\n\u001b[0;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Zero the gradients\u001b[39;49;00m\n",
      "File \u001b[1;32mc:\\Users\\andri\\miniconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:438\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    436\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator\n\u001b[0;32m    437\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 438\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\andri\\miniconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:386\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    384\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    385\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_worker_number_rationality()\n\u001b[1;32m--> 386\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_MultiProcessingDataLoaderIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\andri\\miniconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1039\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m   1032\u001b[0m w\u001b[38;5;241m.\u001b[39mdaemon \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1033\u001b[0m \u001b[38;5;66;03m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[0;32m   1034\u001b[0m \u001b[38;5;66;03m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[0;32m   1035\u001b[0m \u001b[38;5;66;03m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[0;32m   1036\u001b[0m \u001b[38;5;66;03m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[0;32m   1037\u001b[0m \u001b[38;5;66;03m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[0;32m   1038\u001b[0m \u001b[38;5;66;03m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[1;32m-> 1039\u001b[0m \u001b[43mw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1040\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_queues\u001b[38;5;241m.\u001b[39mappend(index_queue)\n\u001b[0;32m   1041\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_workers\u001b[38;5;241m.\u001b[39mappend(w)\n",
      "File \u001b[1;32mc:\\Users\\andri\\miniconda3\\Lib\\multiprocessing\\process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _current_process\u001b[38;5;241m.\u001b[39m_config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemon\u001b[39m\u001b[38;5;124m'\u001b[39m), \\\n\u001b[0;32m    119\u001b[0m        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemonic processes are not allowed to have children\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    120\u001b[0m _cleanup()\n\u001b[1;32m--> 121\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sentinel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen\u001b[38;5;241m.\u001b[39msentinel\n\u001b[0;32m    123\u001b[0m \u001b[38;5;66;03m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;66;03m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\andri\\miniconda3\\Lib\\multiprocessing\\context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[1;32m--> 224\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mProcess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\andri\\miniconda3\\Lib\\multiprocessing\\context.py:336\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[0;32m    335\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpopen_spawn_win32\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Popen\n\u001b[1;32m--> 336\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\andri\\miniconda3\\Lib\\multiprocessing\\popen_spawn_win32.py:94\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     93\u001b[0m     reduction\u001b[38;5;241m.\u001b[39mdump(prep_data, to_child)\n\u001b[1;32m---> 94\u001b[0m     \u001b[43mreduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_child\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     96\u001b[0m     set_spawning_popen(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\andri\\miniconda3\\Lib\\multiprocessing\\reduction.py:60\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdump\u001b[39m(obj, file, protocol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     59\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m     \u001b[43mForkingPickler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "model.to(device)\n",
    "criterion.to(device)\n",
    "\n",
    "# Optimizer and Scheduler\n",
    "optimizer = optim.RMSprop(model.parameters(), lr=0.0001)\n",
    "scheduler = StepLR(optimizer, step_size=5, gamma=0.1)  # Optional learning rate scheduler\n",
    "\n",
    "# Step 3: Training loop\n",
    "num_epochs = 50\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, labels in train_loader:  # Assuming you have a DataLoader for your training set\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()  # Zero the gradients\n",
    "        outputs = model(images)  # Forward pass\n",
    "        loss = criterion(outputs, labels)  # Compute the loss\n",
    "        loss.backward()  # Backward pass\n",
    "        optimizer.step()  # Update weights\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # Print the average loss for the epoch\n",
    "    average_loss = running_loss / len(train_loader)\n",
    "    print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {average_loss}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6584212440887596\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# After training, you can evaluate the model on your validation set\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:  # Assuming you have a DataLoader for your validation set\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = correct / total\n",
    "print(f'Validation Accuracy: {accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'MyCNN.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6711531465987632\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 5: Model Evaluation\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in val_loader:\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = correct / total\n",
    "print(f'Validation Accuracy: {accuracy}')\n",
    "\n",
    "\n",
    "# Repeat steps 2-5 with a different architecture for Approach B\n",
    "# ...\n",
    "\n",
    "# Provide analysis and comments\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second Approach: Deep Reinforcement Learning (DRL)\n",
    "\n",
    "In this approach, we will utilize Deep Reinforcement Learning (DRL) techniques to solve our problem. DRL combines the power of deep neural networks with reinforcement learning algorithms to learn optimal policies in complex environments.\n",
    "\n",
    "### Step 1: Environment Setup\n",
    "\n",
    "First, we need to define our environment. This includes selecting an appropriate gym environment or creating a custom environment that suits our problem. The environment should provide observations, actions, and rewards.\n",
    "\n",
    "### Step 2: Agent Design\n",
    "\n",
    "Next, we design our DRL agent. The agent consists of a deep neural network, often referred to as the Q-network, which takes observations as input and outputs action values for each possible action. We can use popular deep learning frameworks like PyTorch or TensorFlow to implement the Q-network.\n",
    "\n",
    "### Step 3: Training Loop\n",
    "\n",
    "The training loop involves the following steps:\n",
    "\n",
    "1. Initialize the Q-network with random weights.\n",
    "2. Observe the current state from the environment.\n",
    "3. Select an action using an exploration-exploitation strategy, such as epsilon-greedy or softmax.\n",
    "4. Execute the selected action in the environment and observe the next state and reward.\n",
    "5. Update the Q-network using the observed state, action, next state, and reward.\n",
    "6. Repeat steps 2-5 until convergence or a maximum number of iterations.\n",
    "\n",
    "During training, we can use techniques like experience replay and target networks to stabilize and improve the learning process.\n",
    "\n",
    "### Step 4: Evaluation\n",
    "\n",
    "After training, we evaluate the performance of our agent by running it in the environment and measuring its performance metrics, such as average reward or success rate. This helps us assess the effectiveness of our DRL approach.\n",
    "\n",
    "### Step 5: Fine-tuning and Optimization\n",
    "\n",
    "Based on the evaluation results, we can fine-tune and optimize our DRL approach. This may involve adjusting hyperparameters, modifying the network architecture, or trying different exploration-exploitation strategies.\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "Deep Reinforcement Learning (DRL) offers a powerful approach to solving complex problems by combining deep neural networks with reinforcement learning algorithms. By following the steps outlined above, we can develop and train a DRL agent to learn optimal policies in our environment. However, it is important to note that DRL can be computationally intensive and may require significant computational resources and time for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "    def __init__(self, n_frames, n_actions, h_dimension):\n",
    "        super(DQN, self).__init__()\n",
    "\n",
    "        # CNN\n",
    "        self.layers_cnn = nn.Sequential(\n",
    "            nn.Conv2d(n_frames, 6, kernel_size=(7, 7), stride=3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2, 2)),\n",
    "            nn.Conv2d(6, 12, kernel_size=(4, 4)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2, 2)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(432, h_dimension),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(h_dimension, n_actions)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        o = self.layers_cnn(x)  # (BS, ACTIONS)\n",
    "        return o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from collections import deque\n",
    "import numpy as np\n",
    "\n",
    "class DQNAgent:\n",
    "    def __init__(self,\n",
    "                 action_space,\n",
    "                 epsilon=1.0,\n",
    "                 gamma=0.95,\n",
    "                 epsilon_min=0.1,\n",
    "                 epsilon_decay=0.9999,\n",
    "                 lr=1e-3,\n",
    "                 memory_len=5000,\n",
    "                 frames=3,\n",
    "                 hidden_dimension=None,\n",
    "                 device=None):\n",
    "\n",
    "        self.device = device\n",
    "        self.epsilon = epsilon\n",
    "        self.gamma = gamma\n",
    "        self.epsilon_min = epsilon_min\n",
    "        self.epsilon_decay = epsilon_decay\n",
    "        self.memory_len = memory_len\n",
    "        self.lr = lr\n",
    "        self.memory = deque(maxlen=self.memory_len)\n",
    "        self.action_space = action_space\n",
    "\n",
    "        self.target_model = DQN(frames, len(self.action_space), hidden_dimension).to(self.device)\n",
    "        self.model =        DQN(frames, len(self.action_space), hidden_dimension).to(self.device)\n",
    "\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=self.lr)\n",
    "\n",
    "    def update_target_model(self):\n",
    "        self.target_model.load_state_dict(self.model.state_dict())\n",
    "\n",
    "    def is_explore(self):\n",
    "        flip = np.random.rand() <= self.epsilon\n",
    "        return flip\n",
    "\n",
    "    def act(self, state, is_only_random=False, is_only_exploit=False):\n",
    "        if not is_only_exploit and self.is_explore() or is_only_random:\n",
    "            action_index = np.random.randint(len(self.action_space))\n",
    "            # print(action_index, self.ACTION_SPACE[action_index])\n",
    "        else:\n",
    "            q_values = self.target_model(state)[0]\n",
    "            action_index = torch.argmax(q_values)\n",
    "            # print(\"predicted action\", action_index)\n",
    "        return self.action_space[action_index]\n",
    "\n",
    "    def memorize(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, self.action_space.index(action), reward, next_state, done))\n",
    "\n",
    "    def replay(self, batch_size):\n",
    "        minibatch = random.sample(self.memory, batch_size)\n",
    "        train_state = []\n",
    "        train_target = []\n",
    "\n",
    "        for state, action_index, reward, next_state, done in minibatch:\n",
    "            # state = torch.Tensor(state)\n",
    "            target = self.model(state)[0]\n",
    "            train_state.append(target)\n",
    "\n",
    "            target_copy = target.detach().clone().to(self.device)\n",
    "            if done:\n",
    "                target_copy[action_index] = reward\n",
    "            else:\n",
    "                t = self.target_model(next_state)[0]\n",
    "                target_copy[action_index] = reward + self.gamma * torch.max(t)\n",
    "            train_target.append(target_copy)\n",
    "\n",
    "        # Actual training\n",
    "        criterion = nn.MSELoss()\n",
    "        pred, tru = torch.stack(train_state), torch.stack(train_target)\n",
    "        loss = criterion(pred, tru)\n",
    "\n",
    "        # Optimize the model\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "\n",
    "    def load_model(self, name):\n",
    "        self.model = torch.load(name)\n",
    "        self.target_model = torch.load(name)\n",
    "        self.model.eval()\n",
    "\n",
    "    def save_model(self, name):\n",
    "        torch.save(self.target_model, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "\n",
    "    SEED = 1\n",
    "\n",
    "    STARTING_EPISODE_TRAIN = 0\n",
    "    ENDING_EPISODE_TRAIN = STARTING_EPISODE_TRAIN + 1000\n",
    "\n",
    "    STARTING_EPISODE_TEST = ENDING_EPISODE_TRAIN + 1\n",
    "    ENDING_EPISODE_TEST = STARTING_EPISODE_TEST + 100\n",
    "\n",
    "    SKIP_FRAMES = 2\n",
    "    TRAINING_BATCH_SIZE = 64\n",
    "    UPDATE_TARGET_MODEL_FREQUENCY = 5\n",
    "    N_FRAMES = 3\n",
    "    HIDDEN_DIMENSION_FC = 150\n",
    "\n",
    "    GAS_WEIGHT = 1.3\n",
    "\n",
    "    ACTION_SPACE = [\n",
    "        (-1, 1, 0.2), (0, 1, 0.2), (1, 1, 0.2),  # .  Action Space Structure\n",
    "        (-1, 1, 0), (0, 1, 0), (1, 1, 0),        # (Steering Wheel, Gas, Break)\n",
    "        (-1, 0, 0.2), (0, 0, 0.2), (1, 0, 0.2),  # .  -1~1     0~1        0~1\n",
    "        (-1, 0, 0), (0, 0, 0), (1, 0, 0)\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "from datetime import datetime\n",
    "import cv2\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import json\n",
    "\n",
    "\n",
    "def write_json_to_file(data, file_path):\n",
    "    \"\"\"\n",
    "    Write JSON data to a file.\n",
    "\n",
    "    Parameters:\n",
    "    - data: A dictionary representing the JSON data.\n",
    "    - file_path: The path where the JSON file will be written.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'w') as json_file:\n",
    "            json.dump(data, json_file, indent=4)\n",
    "        print(f\"JSON data successfully written to {file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error writing JSON data to {file_path}: {e}\")\n",
    "\n",
    "\n",
    "def read_json_from_file(file_path):\n",
    "    \"\"\"\n",
    "    Read JSON data from a file.\n",
    "\n",
    "    Parameters:\n",
    "    - file_path: The path of the JSON file to be read.\n",
    "\n",
    "    Returns:\n",
    "    - A dictionary representing the JSON data.\n",
    "    - If there is an error reading the file, returns None.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r') as json_file:\n",
    "            data = json.load(json_file)\n",
    "        print(f\"JSON data successfully read from {file_path}\")\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading JSON data from {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def make_all_paths(is_dynamic_root=True, dir_name=\"rl_class\"):\n",
    "    ROOT = \"data\"\n",
    "\n",
    "    if is_dynamic_root:\n",
    "        date_str = datetime.now().strftime(\"%m-%d-%Y_%H-%M-%S\")\n",
    "        dir_name = \"rl_class_{}\".format(date_str)\n",
    "    else:\n",
    "        dir_name = dir_name\n",
    "\n",
    "    path_root = ROOT + \"/\" + dir_name + \"/\"\n",
    "    dirs = [\"models\", \"plots\", \"videos\"]\n",
    "    for d in dirs:\n",
    "        path = path_root + d\n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path)\n",
    "        print(\">> Created dir\", path)\n",
    "    return path_root\n",
    "\n",
    "\n",
    "def plot_state_car(data, title=None):\n",
    "    assert len(data.shape) == 3, \"Can only handle 3D mats.\"\n",
    "    assert data.shape[0] < 10, \"Too many states to plot. Adjust the plots position first.\"\n",
    "\n",
    "    # Create a figure with three subplots\n",
    "    fig, axs = plt.subplots(1, data.shape[0], figsize=(10, 4))\n",
    "\n",
    "    # Plot each image using imshow()\n",
    "    for i in range(data.shape[0]):\n",
    "        axs[i].imshow(data[i], cmap='gray')  # You can adjust the colormap if needed\n",
    "        axs[i].axis('off')                   # Turn off axis labels\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_frame_car(data, title=None):\n",
    "    plt.imshow(data, cmap=\"gray\")  # You can adjust the colormap if needed\n",
    "    plt.axis('off')  # Turn off axis labels\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def preprocess_frame_car(frame):\n",
    "    def crop(frame):\n",
    "        # Crop to 84x84\n",
    "        return frame[:-12, 6:-6]\n",
    "\n",
    "    def make_img_gray(frame):\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        return frame\n",
    "\n",
    "    def normalize(frame):\n",
    "        return frame / 255.0\n",
    "\n",
    "    # frame = crop(frame)\n",
    "    frame = make_img_gray(frame)\n",
    "    frame = frame.astype(float)\n",
    "    frame = normalize(frame)\n",
    "    # frame = frame * 2 - 1   # maps [0,1] to [-1,1]\n",
    "    return frame\n",
    "\n",
    "\n",
    "def seed_everything(seed=42):\n",
    "    # Set seed for Python random module\n",
    "    random.seed(seed)\n",
    "\n",
    "    # Set seed for NumPy\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # Set seed for PyTorch\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False  # disable if deterministic mode is desired\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#import cv2   # open cv\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "import gymnasium as gym\n",
    "from collections import deque\n",
    "import numpy as np\n",
    "from gymnasium.wrappers import RecordVideo\n",
    "\n",
    "\n",
    "def train_car_racing():\n",
    "    seed_everything(seed=Config.SEED)\n",
    "    PATH_ROOT = make_all_paths(is_dynamic_root=True)\n",
    "    write_json_to_file(dict(Config.__dict__), file_path=PATH_ROOT + \"config.json\")\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print('>> Using device:', device)\n",
    "\n",
    "    agent = DQNAgent(frames=Config.N_FRAMES, action_space=Config.ACTION_SPACE, device=device,\n",
    "                     hidden_dimension=Config.HIDDEN_DIMENSION_FC)\n",
    "\n",
    "    # https://www.gymlibrary.dev/environments/box2d/car_racing/\n",
    "    env = gym.make('CarRacing-v2', render_mode=\"rgb_array\")  # , render_mode='human')\n",
    "    env = RecordVideo(env, PATH_ROOT + 'videos', episode_trigger=lambda x: x % Config.UPDATE_TARGET_MODEL_FREQUENCY == 0)\n",
    "\n",
    "    epi_total_rewards = []\n",
    "    for e in range(Config.STARTING_EPISODE_TRAIN, Config.ENDING_EPISODE_TRAIN + 1):\n",
    "        env.episode_id = e\n",
    "\n",
    "        epi_total_reward = 0\n",
    "        epi_negative_reward_counter = 0\n",
    "        epi_time_frame_counter = 1\n",
    "        epi_done = False\n",
    "\n",
    "        init_state = env.reset(seed=e)[0]  # 96, 96, 3 pixels image RGB\n",
    "        init_state = preprocess_frame_car(init_state)  # 96, 96 pixels image GRAY\n",
    "\n",
    "        # (1) EVALUATE STATE: S\n",
    "        state_queue = deque([init_state] * Config.N_FRAMES, maxlen=Config.N_FRAMES)\n",
    "        # plot_state_car(np.array(state_queue))  # visualize S0\n",
    "\n",
    "        while True:\n",
    "            state_tensor = torch.Tensor(np.array(state_queue)).unsqueeze(0).to(device)\n",
    "            action = agent.act(state_tensor)\n",
    "\n",
    "            # (2) EXECUTE ACTION (for several steps)\n",
    "            # (3) EVALUATE S' STATE, REWARD\n",
    "            reward = 0\n",
    "            for _ in range(Config.SKIP_FRAMES):\n",
    "                # execute action\n",
    "                next_state, r, epi_done, _, _ = env.step(action)\n",
    "                # plot_frame_car(next_state)\n",
    "                reward += r\n",
    "                if epi_done:\n",
    "                    break\n",
    "\n",
    "            # (4) ADJUST REWARD\n",
    "            # if getting negative reward 10 times after the tolerance steps, terminate this episode\n",
    "            if epi_time_frame_counter > 100 and reward < 0:\n",
    "                epi_negative_reward_counter += 1\n",
    "            else:\n",
    "                epi_negative_reward_counter = 0\n",
    "\n",
    "            # extra bonus for the model if it uses full gas\n",
    "            if action[1] == 1 and action[2] == 0:\n",
    "                reward *= Config.GAS_WEIGHT\n",
    "\n",
    "            epi_total_reward += reward\n",
    "\n",
    "            # plot_state_car(np.array(state_queue), title=\"STATE 0\")\n",
    "            # process state S'\n",
    "            next_state = preprocess_frame_car(next_state)\n",
    "            next_state_queue = deque([frame for frame in state_queue], maxlen=Config.N_FRAMES)\n",
    "            next_state_queue.append(next_state)\n",
    "            # plot_state_car(np.array(next_state_queue), title=\"STATE 1\")\n",
    "\n",
    "            next_state_tensor = torch.Tensor(np.array(next_state_queue)).unsqueeze(0).to(device)\n",
    "\n",
    "            # (5) STORE OBSERVATIONS\n",
    "            # Memorizing saving state, action reward tuples\n",
    "            agent.memorize(state_tensor, action, reward, next_state_tensor, epi_done)\n",
    "\n",
    "            # S = S'\n",
    "            state_queue = next_state_queue\n",
    "\n",
    "            # early stop if the number of\n",
    "            if epi_negative_reward_counter >= 25 or epi_total_reward < 0:\n",
    "                break\n",
    "\n",
    "            # (6) TRAIN ON BATCHES OF OBSERVATIONS\n",
    "            # train the model with tuple, if there are enough tuples\n",
    "            if len(agent.memory) > Config.TRAINING_BATCH_SIZE:\n",
    "                agent.replay(Config.TRAINING_BATCH_SIZE)\n",
    "\n",
    "            epi_time_frame_counter += 1\n",
    "        epi_total_rewards += [epi_total_reward]\n",
    "\n",
    "        # >>> ON EPISODE END\n",
    "        # print stats\n",
    "        stats_string = 'Episode: {}/{}, Scores(Time Frames): {}, Total Rewards: {:.2}, Epsilon: {:.2}'\n",
    "        print(stats_string.format(\n",
    "            e,\n",
    "            Config.ENDING_EPISODE_TRAIN,\n",
    "            epi_time_frame_counter,\n",
    "            float(epi_total_reward),\n",
    "            float(agent.epsilon))\n",
    "        )\n",
    "\n",
    "        if e % Config.UPDATE_TARGET_MODEL_FREQUENCY == 0:\n",
    "            # plot rewards stats\n",
    "            plt.plot(epi_total_rewards, label=\"cum rew\", color=\"blue\")\n",
    "            plt.title(\"Rewards during episode episode\")\n",
    "            plt.savefig(PATH_ROOT + 'plots/reward_{}.pdf'.format(e))\n",
    "\n",
    "            # save model frequently\n",
    "            agent.save_model(PATH_ROOT + 'models/trial_{}.h5'.format(e))\n",
    "\n",
    "            # swap model\n",
    "            agent.update_target_model()\n",
    "            write_json_to_file({\"CUM_REW\": epi_total_rewards}, PATH_ROOT + \"/stats.json\")\n",
    "\n",
    "    env.close()\n",
    "\n",
    "\n",
    "#train_car_racing()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
