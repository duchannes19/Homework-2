{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Homework 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gdown\n",
    "import zipfile\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded.\n"
     ]
    }
   ],
   "source": [
    "#Check if files exists in data folder\n",
    "if os.path.exists('data/'):\n",
    "    print('Files already downloaded.')\n",
    "\n",
    "else:\n",
    "    output_path = 'data.zip'\n",
    "    file_id = '1KDN-rFCq9IDJ7_kNW5y5Co100KNpklz-'\n",
    "    url = f'https://drive.google.com/uc?id={file_id}'\n",
    "    # Download the zip file\n",
    "    gdown.download(url, output_path, quiet=False)\n",
    "\n",
    "    # Extract the contents of the zip file\n",
    "    with zipfile.ZipFile(output_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall('data')\n",
    "\n",
    "    # Remove the zip file\n",
    "    os.remove(output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already extracted\n"
     ]
    }
   ],
   "source": [
    "if(os.path.exists('test/') and os.path.exists('train')):\n",
    "    print('Files already extracted')\n",
    "else:\n",
    "    print('Extracting the test.zip and train.zip files...')\n",
    "    # Extract the test.zip file\n",
    "    with zipfile.ZipFile('data/public/test.zip', 'r') as zip_ref:\n",
    "        zip_ref.extractall()\n",
    "\n",
    "    # Extract the train.zip file\n",
    "    with zipfile.ZipFile('data/public/train.zip', 'r') as zip_ref:\n",
    "        zip_ref.extractall()\n",
    "\n",
    "    print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Approach\n",
    "\n",
    "For the first approach, we will use a different architecture to train our model. We will use a custom convolutional neural network (CNN) architecture.\n",
    "\n",
    "### Step 1: Data Loading and Preprocessing\n",
    "\n",
    "Similar to the first approach, we will load and preprocess our dataset using the same transformations. We will also create data loaders for the training and validation sets.\n",
    "\n",
    "### Step 2: Model Architecture\n",
    "\n",
    "In this approach, we will define a custom CNN model. The model will consist of multiple convolutional layers followed by fully connected layers. We will use ReLU activation functions and dropout regularization to prevent overfitting.\n",
    "\n",
    "### Step 3: Training Loop\n",
    "\n",
    "We will train the model using a similar training loop as in the first approach. We will iterate over the training set, compute the loss, perform backpropagation, and update the model's weights.\n",
    "\n",
    "### Step 4: Model Evaluation\n",
    "\n",
    "After training, we will evaluate the model on the validation set. We will calculate the accuracy of the model by comparing the predicted labels with the ground truth labels.\n",
    "\n",
    "### Step 5: Save the Model\n",
    "\n",
    "Finally, we will save the trained model to a file for future use.\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "In this second approach, we used a custom CNN architecture to train our model. This approach allows us to have more control over the model's architecture and potentially achieve better performance. However, it requires more manual design and experimentation compared to using a pre-trained model like ResNet18.\n",
    "\n",
    "It is important to note that the choice of architecture depends on the specific problem and dataset. It is recommended to experiment with different architectures and hyperparameters to find the best model for your task.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Check if GPU is available\n",
    "print('GPU is', 'available' if tf.config.list_physical_devices('GPU') else 'NOT AVAILABLE')\n",
    "\n",
    "# Enable GPU\n",
    "physical_devices = tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6369 images belonging to 5 classes.\n",
      "Found 2749 images belonging to 5 classes.\n",
      "Image height = 96, Image Width = 96\n",
      "Image input (96, 96, 3)\n",
      "Classes: ['0', '1', '2', '3', '4']\n",
      "Loaded 6369 training samples from  5 classes.\n",
      "Loaded 2749 test samples from 5 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Define the path to your training data\n",
    "trainingset = 'train/'\n",
    "validationset = 'test/'\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "# Define batch size and input shape\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    zoom_range=0.1,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=False,\n",
    ")\n",
    "\n",
    "# Augment training data\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    directory=trainingset,\n",
    "    target_size=(96, 96),\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=True,\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "# No augmentation for validation data\n",
    "validation_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    directory=validationset,\n",
    "    target_size=(96, 96),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    class_mode='categorical'\n",
    ")  # set as validation data\n",
    "\n",
    "num_samples = train_generator.n\n",
    "num_classes = train_generator.num_classes\n",
    "input_shape = train_generator.image_shape\n",
    "\n",
    "classnames = [k for k, v in train_generator.class_indices.items()]\n",
    "img_h = input_shape[0]\n",
    "img_w = input_shape[1]\n",
    "print(\"Image height = %d, Image Width = %d\" % (img_h, img_w))\n",
    "print(\"Image input %s\" % str(input_shape))\n",
    "print(\"Classes: %r\" % classnames)\n",
    "print('Loaded %d training samples from  %d classes.' % (num_samples, num_classes))\n",
    "print('Loaded %d test samples from %d classes.' % (validation_generator.n, validation_generator.num_classes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"MyOptimizedCNN\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_50 (Conv2D)          (None, 93, 93, 15)        735       \n",
      "                                                                 \n",
      " activation_83 (Activation)  (None, 93, 93, 15)        0         \n",
      "                                                                 \n",
      " conv2d_51 (Conv2D)          (None, 90, 90, 20)        4820      \n",
      "                                                                 \n",
      " activation_84 (Activation)  (None, 90, 90, 20)        0         \n",
      "                                                                 \n",
      " max_pooling2d_43 (MaxPoolin  (None, 45, 45, 20)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_52 (Conv2D)          (None, 42, 42, 30)        9630      \n",
      "                                                                 \n",
      " activation_85 (Activation)  (None, 42, 42, 30)        0         \n",
      "                                                                 \n",
      " max_pooling2d_44 (MaxPoolin  (None, 21, 21, 30)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_19 (Flatten)        (None, 13230)             0         \n",
      "                                                                 \n",
      " dense_52 (Dense)            (None, 128)               1693568   \n",
      "                                                                 \n",
      " activation_86 (Activation)  (None, 128)               0         \n",
      "                                                                 \n",
      " dropout_27 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_53 (Dense)            (None, 96)                12384     \n",
      "                                                                 \n",
      " activation_87 (Activation)  (None, 96)                0         \n",
      "                                                                 \n",
      " dropout_28 (Dropout)        (None, 96)                0         \n",
      "                                                                 \n",
      " dense_54 (Dense)            (None, 5)                 485       \n",
      "                                                                 \n",
      " activation_88 (Activation)  (None, 5)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,721,622\n",
      "Trainable params: 1,721,622\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten,\\\n",
    "                         Conv2D, MaxPooling2D\n",
    "from keras import optimizers\n",
    "\n",
    "def MyCNN(input_shape, num_classes):\n",
    "    model = Sequential(name=\"MyOptimizedCNN\")\n",
    "\n",
    "    # C1 Convolutional Layer \n",
    "    model.add(Conv2D(filters=15, input_shape=input_shape, kernel_size=(4,4)))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    # C2 Convolutional Layer\n",
    "    model.add(Conv2D(filters=20, kernel_size=(4,4)))\n",
    "    model.add(Activation('relu'))\n",
    "    # Pooling\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "    # C3 Convolutional Layer\n",
    "    model.add(Conv2D(filters=30, kernel_size=(4,4)))\n",
    "    model.add(Activation('relu'))\n",
    "    # Pooling\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "    # Flatten\n",
    "    model.add(Flatten())\n",
    "\n",
    "    # D1 Dense Layer\n",
    "    model.add(Dense(128))\n",
    "    model.add(Activation('relu'))\n",
    "    # Dropout\n",
    "    model.add(Dropout(0.4))\n",
    "    # D2 Dense Layer\n",
    "    model.add(Dense(96))\n",
    "    model.add(Activation('relu'))\n",
    "    # Dropout\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    # Output Layer\n",
    "    model.add(Dense(num_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    # Compile\n",
    "\n",
    "    optimizer = optimizers.RMSprop(lr=0.0001)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "# create the model\n",
    "# Input shape is (3, 96, 96) for the RGB image\n",
    "model = MyCNN(input_shape, num_classes)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "100/100 [==============================] - 13s 118ms/step - loss: 1.5359 - accuracy: 0.3395 - val_loss: 1.2635 - val_accuracy: 0.6457 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "100/100 [==============================] - 11s 115ms/step - loss: 1.4276 - accuracy: 0.4242 - val_loss: 1.1915 - val_accuracy: 0.6672 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "100/100 [==============================] - 12s 120ms/step - loss: 1.3962 - accuracy: 0.4572 - val_loss: 1.0764 - val_accuracy: 0.6511 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "100/100 [==============================] - 12s 115ms/step - loss: 1.3302 - accuracy: 0.4966 - val_loss: 1.0959 - val_accuracy: 0.6562 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "100/100 [==============================] - 11s 114ms/step - loss: 1.3078 - accuracy: 0.5048 - val_loss: 1.0368 - val_accuracy: 0.6661 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "100/100 [==============================] - 11s 115ms/step - loss: 1.2912 - accuracy: 0.5109 - val_loss: 1.0576 - val_accuracy: 0.6468 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "100/100 [==============================] - 11s 114ms/step - loss: 1.2766 - accuracy: 0.5230 - val_loss: 1.0293 - val_accuracy: 0.6821 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 1.2657 - accuracy: 0.5216 - val_loss: 1.1287 - val_accuracy: 0.6366 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 1.2622 - accuracy: 0.5214 - val_loss: 1.0280 - val_accuracy: 0.6613 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 1.2421 - accuracy: 0.5368 - val_loss: 1.0388 - val_accuracy: 0.6377 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "100/100 [==============================] - 12s 119ms/step - loss: 1.2414 - accuracy: 0.5365 - val_loss: 0.9815 - val_accuracy: 0.6639 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 1.2346 - accuracy: 0.5400 - val_loss: 1.0404 - val_accuracy: 0.6588 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 1.2342 - accuracy: 0.5359 - val_loss: 0.9505 - val_accuracy: 0.6755 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 1.2315 - accuracy: 0.5459 - val_loss: 1.0182 - val_accuracy: 0.6591 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 1.2209 - accuracy: 0.5483 - val_loss: 1.0209 - val_accuracy: 0.6450 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 1.2108 - accuracy: 0.5499 - val_loss: 1.0687 - val_accuracy: 0.6471 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 1.1940 - accuracy: 0.5575 - val_loss: 0.9828 - val_accuracy: 0.6664 - lr: 2.0000e-04\n",
      "Epoch 18/50\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.1814 - accuracy: 0.5605Restoring model weights from the end of the best epoch: 13.\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 1.1814 - accuracy: 0.5605 - val_loss: 1.0243 - val_accuracy: 0.6450 - lr: 2.0000e-04\n",
      "Epoch 18: early stopping\n"
     ]
    }
   ],
   "source": [
    "from keras import callbacks\n",
    "\n",
    "# Define callbacks\n",
    "early_stopping = callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='auto', restore_best_weights=True)\n",
    "reduce_lr = callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-6)\n",
    "\n",
    "# Assuming you have a `train_generator` and `validation_generator` defined\n",
    "\n",
    "# Calculate steps per epoch and validation steps\n",
    "steps_per_epoch = len(train_generator)\n",
    "val_steps = len(validation_generator)\n",
    "\n",
    "try:\n",
    "    # Train the model with better training parameters\n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        epochs=50,\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=val_steps,\n",
    "        callbacks=[early_stopping, reduce_lr]\n",
    "    )\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model to disk\n",
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andri\\AppData\\Local\\Temp\\ipykernel_14484\\989374102.py:2: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n",
      "  loss, acc = model.evaluate_generator(validation_generator,steps=val_steps)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.120741\n",
      "Test accuracy: 0.654784\n"
     ]
    }
   ],
   "source": [
    "val_steps=validation_generator.n//validation_generator.batch_size+1\n",
    "loss, acc = model.evaluate_generator(validation_generator,steps=val_steps)\n",
    "print('Test loss: %f' %loss)\n",
    "print('Test accuracy: %f' %acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 2s 99ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.500     0.075     0.131        53\n",
      "           1      0.287     0.509     0.367       110\n",
      "           2      0.417     0.512     0.460       162\n",
      "           3      0.810     0.736     0.771       758\n",
      "           4      0.000     0.000     0.000        15\n",
      "\n",
      "    accuracy                          0.638      1098\n",
      "   macro avg      0.403     0.367     0.346      1098\n",
      "weighted avg      0.674     0.638     0.643      1098\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    " \n",
    "preds = model.predict(validation_generator,steps=val_steps)\n",
    "\n",
    "Ypred = np.argmax(preds, axis=1)\n",
    "Ytest = validation_generator.classes  # shuffle=False in test_generator\n",
    "\n",
    "print(classification_report(Ytest, Ypred, labels=None, target_names=classnames, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 2s 99ms/step\n",
      "True                 Predicted         \terrors \terr % \n",
      "------------------------------------------------------------------\n",
      "3                ->  1                 \t107 \t9.74 % \n",
      "3                ->  2                 \t94 \t8.56 % \n",
      "2                ->  3                 \t58 \t5.28 % \n",
      "1                ->  3                 \t36 \t3.28 % \n",
      "0                ->  3                 \t27 \t2.46 % \n",
      "0                ->  1                 \t15 \t1.37 % \n",
      "2                ->  1                 \t15 \t1.37 % \n",
      "1                ->  2                 \t13 \t1.18 % \n",
      "4                ->  3                 \t9 \t0.82 % \n",
      "0                ->  2                 \t5 \t0.46 % \n",
      "2                ->  4                 \t3 \t0.27 % \n",
      "4                ->  1                 \t3 \t0.27 % \n",
      "4                ->  2                 \t2 \t0.18 % \n",
      "3                ->  4                 \t2 \t0.18 % \n",
      "2                ->  0                 \t1 \t0.09 % \n",
      "1                ->  0                 \t1 \t0.09 % \n",
      "3                ->  0                 \t1 \t0.09 % \n",
      "0                ->  4                 \t1 \t0.09 % \n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "preds = model.predict(validation_generator,verbose=1,steps=val_steps)\n",
    "\n",
    "Ypred = np.argmax(preds, axis=1)\n",
    "Ytest = validation_generator.classes  # shuffle=False in test_generator\n",
    "\n",
    "cm = confusion_matrix(Ytest, Ypred)\n",
    "\n",
    "conf = [] # data structure for confusions: list of (i,j,cm[i][j])\n",
    "for i in range(0,cm.shape[0]):\n",
    "  for j in range(0,cm.shape[1]):\n",
    "    if (i!=j and cm[i][j]>0):\n",
    "      conf.append([i,j,cm[i][j]])\n",
    "\n",
    "col=2\n",
    "conf = np.array(conf)\n",
    "conf = conf[np.argsort(-conf[:,col])]  # decreasing order by 3-rd column (i.e., cm[i][j])\n",
    "\n",
    "print('%-16s     %-16s  \\t%s \\t%s ' %('True','Predicted','errors','err %'))\n",
    "print('------------------------------------------------------------------')\n",
    "for k in conf:\n",
    "  print('%-16s ->  %-16s  \\t%d \\t%.2f %% ' %(classnames[k[0]],classnames[k[1]],k[2],k[2]*100.0/validation_generator.n))\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment: CarRacing-v2\n",
      "Action space: Discrete(5)\n",
      "Observation space: Box(0, 255, (96, 96, 3), uint8)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "try:\n",
    "    import gymnasium as gym\n",
    "except ModuleNotFoundError:\n",
    "    print('gymnasium module not found. Try to install with')\n",
    "    print('pip install gymnasium[box2d]')\n",
    "    sys.exit(1)\n",
    "\n",
    "\n",
    "\n",
    "def play(env, model):\n",
    "\n",
    "    seed = 2000\n",
    "    obs, _ = env.reset(seed=seed)\n",
    "    \n",
    "    # drop initial frames\n",
    "    action0 = 0\n",
    "    for i in range(50):\n",
    "        obs,_,_,_,_ = env.step(action0)\n",
    "    \n",
    "    done = False\n",
    "    while not done:\n",
    "        p = model(np.expand_dims(obs, axis=0)) # reshape input data to have a batch dimension of size 1\n",
    "        action = np.argmax(p)  # adapt to your model\n",
    "        obs, _, terminated, truncated, _ = env.step(action)\n",
    "        done = terminated or truncated\n",
    "\n",
    "    env.close()\n",
    "\n",
    "\n",
    "env_arguments = {\n",
    "    'domain_randomize': False,\n",
    "    'continuous': False,\n",
    "    'render_mode': 'human'\n",
    "}\n",
    "\n",
    "env_name = 'CarRacing-v2'\n",
    "env = gym.make(env_name, **env_arguments)\n",
    "\n",
    "print(\"Environment:\", env_name)\n",
    "print(\"Action space:\", env.action_space)\n",
    "print(\"Observation space:\", env.observation_space)\n",
    "\n",
    "play(env, model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second Try ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6369 images belonging to 5 classes.\n",
      "Found 2749 images belonging to 5 classes.\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_71 (Conv2D)          (None, 92, 92, 15)        1140      \n",
      "                                                                 \n",
      " activation_89 (Activation)  (None, 92, 92, 15)        0         \n",
      "                                                                 \n",
      " conv2d_72 (Conv2D)          (None, 88, 88, 20)        7520      \n",
      "                                                                 \n",
      " activation_90 (Activation)  (None, 88, 88, 20)        0         \n",
      "                                                                 \n",
      " max_pooling2d_57 (MaxPoolin  (None, 44, 44, 20)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_73 (Conv2D)          (None, 42, 42, 30)        5430      \n",
      "                                                                 \n",
      " activation_91 (Activation)  (None, 42, 42, 30)        0         \n",
      "                                                                 \n",
      " max_pooling2d_58 (MaxPoolin  (None, 21, 21, 30)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_23 (Flatten)        (None, 13230)             0         \n",
      "                                                                 \n",
      " dense_63 (Dense)            (None, 128)               1693568   \n",
      "                                                                 \n",
      " activation_92 (Activation)  (None, 128)               0         \n",
      "                                                                 \n",
      " dropout_33 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_64 (Dense)            (None, 96)                12384     \n",
      "                                                                 \n",
      " activation_93 (Activation)  (None, 96)                0         \n",
      "                                                                 \n",
      " dropout_34 (Dropout)        (None, 96)                0         \n",
      "                                                                 \n",
      " dense_65 (Dense)            (None, 5)                 485       \n",
      "                                                                 \n",
      " activation_94 (Activation)  (None, 5)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,720,527\n",
      "Trainable params: 1,720,527\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "100/100 [==============================] - 14s 128ms/step - loss: 1.5107 - accuracy: 0.3181 - val_loss: 1.2494 - val_accuracy: 0.6326 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "100/100 [==============================] - 12s 123ms/step - loss: 1.4397 - accuracy: 0.4027 - val_loss: 1.1666 - val_accuracy: 0.6406 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "100/100 [==============================] - 12s 121ms/step - loss: 1.4177 - accuracy: 0.4362 - val_loss: 1.1236 - val_accuracy: 0.6799 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "100/100 [==============================] - 12s 121ms/step - loss: 1.3959 - accuracy: 0.4421 - val_loss: 1.1082 - val_accuracy: 0.6879 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "100/100 [==============================] - 12s 120ms/step - loss: 1.3582 - accuracy: 0.4702 - val_loss: 1.0198 - val_accuracy: 0.7097 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "100/100 [==============================] - 12s 119ms/step - loss: 1.3191 - accuracy: 0.5005 - val_loss: 1.0479 - val_accuracy: 0.6842 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "100/100 [==============================] - 12s 118ms/step - loss: 1.3021 - accuracy: 0.5130 - val_loss: 0.9792 - val_accuracy: 0.6890 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "100/100 [==============================] - 12s 119ms/step - loss: 1.2865 - accuracy: 0.5108 - val_loss: 0.9921 - val_accuracy: 0.6650 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "100/100 [==============================] - 12s 119ms/step - loss: 1.2721 - accuracy: 0.5194 - val_loss: 0.9530 - val_accuracy: 0.6839 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "100/100 [==============================] - 12s 120ms/step - loss: 1.2787 - accuracy: 0.5163 - val_loss: 1.0091 - val_accuracy: 0.6773 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "100/100 [==============================] - 12s 118ms/step - loss: 1.2688 - accuracy: 0.5250 - val_loss: 1.0093 - val_accuracy: 0.6624 - lr: 9.0000e-04\n",
      "Epoch 12/50\n",
      "100/100 [==============================] - 12s 120ms/step - loss: 1.2536 - accuracy: 0.5312 - val_loss: 0.9865 - val_accuracy: 0.6773 - lr: 9.0000e-04\n",
      "Epoch 13/50\n",
      "100/100 [==============================] - 12s 118ms/step - loss: 1.2569 - accuracy: 0.5249 - val_loss: 1.0103 - val_accuracy: 0.6672 - lr: 9.0000e-04\n",
      "Epoch 14/50\n",
      "100/100 [==============================] - 12s 118ms/step - loss: 1.2475 - accuracy: 0.5341 - val_loss: 0.9859 - val_accuracy: 0.6817 - lr: 9.0000e-04\n",
      "Epoch 15/50\n",
      "100/100 [==============================] - 12s 119ms/step - loss: 1.2489 - accuracy: 0.5249 - val_loss: 0.9677 - val_accuracy: 0.6868 - lr: 9.0000e-04\n",
      "Epoch 16/50\n",
      "100/100 [==============================] - 12s 118ms/step - loss: 1.2534 - accuracy: 0.5291 - val_loss: 0.9444 - val_accuracy: 0.6784 - lr: 9.0000e-04\n",
      "Epoch 17/50\n",
      "100/100 [==============================] - 12s 119ms/step - loss: 1.2314 - accuracy: 0.5393 - val_loss: 1.0182 - val_accuracy: 0.6559 - lr: 9.0000e-04\n",
      "Epoch 18/50\n",
      "100/100 [==============================] - 12s 118ms/step - loss: 1.2213 - accuracy: 0.5466 - val_loss: 1.0320 - val_accuracy: 0.6482 - lr: 9.0000e-04\n",
      "Epoch 19/50\n",
      "100/100 [==============================] - 12s 118ms/step - loss: 1.2285 - accuracy: 0.5392 - val_loss: 0.9943 - val_accuracy: 0.6661 - lr: 9.0000e-04\n",
      "Epoch 20/50\n",
      "100/100 [==============================] - 12s 119ms/step - loss: 1.2260 - accuracy: 0.5429 - val_loss: 0.9554 - val_accuracy: 0.6984 - lr: 9.0000e-04\n",
      "Epoch 21/50\n",
      "100/100 [==============================] - 12s 119ms/step - loss: 1.2136 - accuracy: 0.5426 - val_loss: 0.9880 - val_accuracy: 0.6672 - lr: 8.1000e-04\n",
      "Epoch 22/50\n",
      "100/100 [==============================] - 12s 120ms/step - loss: 1.2106 - accuracy: 0.5453 - val_loss: 0.9740 - val_accuracy: 0.6511 - lr: 8.1000e-04\n",
      "Epoch 23/50\n",
      "100/100 [==============================] - 12s 119ms/step - loss: 1.2217 - accuracy: 0.5451 - val_loss: 1.0681 - val_accuracy: 0.6406 - lr: 8.1000e-04\n",
      "Epoch 24/50\n",
      "100/100 [==============================] - 13s 125ms/step - loss: 1.2017 - accuracy: 0.5489 - val_loss: 0.9661 - val_accuracy: 0.6857 - lr: 8.1000e-04\n",
      "Epoch 25/50\n",
      "100/100 [==============================] - 12s 121ms/step - loss: 1.2034 - accuracy: 0.5420 - val_loss: 1.0353 - val_accuracy: 0.6461 - lr: 8.1000e-04\n",
      "Epoch 26/50\n",
      "100/100 [==============================] - 12s 121ms/step - loss: 1.2057 - accuracy: 0.5524 - val_loss: 0.9393 - val_accuracy: 0.6606 - lr: 8.1000e-04\n",
      "Epoch 27/50\n",
      "100/100 [==============================] - 12s 122ms/step - loss: 1.2060 - accuracy: 0.5500 - val_loss: 0.9911 - val_accuracy: 0.6712 - lr: 8.1000e-04\n",
      "Epoch 28/50\n",
      "100/100 [==============================] - 12s 120ms/step - loss: 1.2017 - accuracy: 0.5400 - val_loss: 0.9799 - val_accuracy: 0.6708 - lr: 8.1000e-04\n",
      "Epoch 29/50\n",
      "100/100 [==============================] - 12s 123ms/step - loss: 1.2079 - accuracy: 0.5480 - val_loss: 1.0226 - val_accuracy: 0.6188 - lr: 8.1000e-04\n",
      "Epoch 30/50\n",
      "100/100 [==============================] - 12s 122ms/step - loss: 1.1868 - accuracy: 0.5557 - val_loss: 1.0064 - val_accuracy: 0.6479 - lr: 8.1000e-04\n",
      "Epoch 31/50\n",
      "100/100 [==============================] - 12s 123ms/step - loss: 1.2007 - accuracy: 0.5470 - val_loss: 0.9933 - val_accuracy: 0.6533 - lr: 7.2900e-04\n",
      "Epoch 32/50\n",
      "100/100 [==============================] - 12s 121ms/step - loss: 1.1996 - accuracy: 0.5467 - val_loss: 0.9751 - val_accuracy: 0.6439 - lr: 7.2900e-04\n",
      "Epoch 33/50\n",
      "100/100 [==============================] - 12s 120ms/step - loss: 1.1837 - accuracy: 0.5594 - val_loss: 0.9381 - val_accuracy: 0.6810 - lr: 7.2900e-04\n",
      "Epoch 34/50\n",
      "100/100 [==============================] - 12s 122ms/step - loss: 1.1883 - accuracy: 0.5569 - val_loss: 0.9349 - val_accuracy: 0.6642 - lr: 7.2900e-04\n",
      "Epoch 35/50\n",
      "100/100 [==============================] - 12s 121ms/step - loss: 1.1943 - accuracy: 0.5502 - val_loss: 0.9378 - val_accuracy: 0.6755 - lr: 7.2900e-04\n",
      "Epoch 36/50\n",
      "100/100 [==============================] - 12s 124ms/step - loss: 1.1894 - accuracy: 0.5590 - val_loss: 0.9601 - val_accuracy: 0.6675 - lr: 7.2900e-04\n",
      "Epoch 37/50\n",
      "100/100 [==============================] - 12s 121ms/step - loss: 1.1865 - accuracy: 0.5561 - val_loss: 0.9206 - val_accuracy: 0.6748 - lr: 7.2900e-04\n",
      "Epoch 38/50\n",
      "100/100 [==============================] - 12s 122ms/step - loss: 1.1921 - accuracy: 0.5575 - val_loss: 0.9112 - val_accuracy: 0.6948 - lr: 7.2900e-04\n",
      "Epoch 39/50\n",
      "100/100 [==============================] - 12s 123ms/step - loss: 1.1845 - accuracy: 0.5564 - val_loss: 0.9442 - val_accuracy: 0.6682 - lr: 7.2900e-04\n",
      "Epoch 40/50\n",
      "100/100 [==============================] - 12s 122ms/step - loss: 1.1822 - accuracy: 0.5583 - val_loss: 0.9314 - val_accuracy: 0.6646 - lr: 7.2900e-04\n",
      "Epoch 41/50\n",
      "100/100 [==============================] - 12s 122ms/step - loss: 1.1712 - accuracy: 0.5610 - val_loss: 0.9643 - val_accuracy: 0.6621 - lr: 6.5610e-04\n",
      "Epoch 42/50\n",
      "100/100 [==============================] - 13s 126ms/step - loss: 1.1745 - accuracy: 0.5607 - val_loss: 0.9869 - val_accuracy: 0.6421 - lr: 6.5610e-04\n",
      "Epoch 43/50\n",
      "100/100 [==============================] - 12s 123ms/step - loss: 1.1808 - accuracy: 0.5568 - val_loss: 0.9265 - val_accuracy: 0.6813 - lr: 6.5610e-04\n",
      "Epoch 44/50\n",
      "100/100 [==============================] - 12s 122ms/step - loss: 1.1756 - accuracy: 0.5663 - val_loss: 0.9417 - val_accuracy: 0.6657 - lr: 6.5610e-04\n",
      "Epoch 45/50\n",
      "100/100 [==============================] - 12s 121ms/step - loss: 1.1800 - accuracy: 0.5602 - val_loss: 0.9254 - val_accuracy: 0.6744 - lr: 6.5610e-04\n",
      "Epoch 46/50\n",
      "100/100 [==============================] - 12s 120ms/step - loss: 1.1666 - accuracy: 0.5651 - val_loss: 0.9791 - val_accuracy: 0.6337 - lr: 6.5610e-04\n",
      "Epoch 47/50\n",
      "100/100 [==============================] - 12s 121ms/step - loss: 1.1750 - accuracy: 0.5668 - val_loss: 0.8882 - val_accuracy: 0.6861 - lr: 6.5610e-04\n",
      "Epoch 48/50\n",
      "100/100 [==============================] - 12s 117ms/step - loss: 1.1654 - accuracy: 0.5629 - val_loss: 0.9741 - val_accuracy: 0.6515 - lr: 6.5610e-04\n",
      "Epoch 49/50\n",
      "100/100 [==============================] - 12s 117ms/step - loss: 1.1607 - accuracy: 0.5641 - val_loss: 0.9598 - val_accuracy: 0.6646 - lr: 6.5610e-04\n",
      "Epoch 50/50\n",
      "100/100 [==============================] - 12s 117ms/step - loss: 1.1780 - accuracy: 0.5588 - val_loss: 0.9743 - val_accuracy: 0.6559 - lr: 6.5610e-04\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten, MaxPooling2D, BatchNormalization, Dropout, GlobalAveragePooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "\n",
    "def lr_scheduler(epoch, lr):\n",
    "    if epoch % 10 == 0 and epoch != 0:\n",
    "        lr = lr * 0.9  # Adjust the learning rate decay factor as needed\n",
    "    return lr\n",
    "\n",
    "def AdvancedCNN(num_classes, input_shape):\n",
    "    model = Sequential()\n",
    "\n",
    "    # C1 Convolutional Layer \n",
    "    model.add(Conv2D(filters=15, input_shape=input_shape, kernel_size=(5,5)))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    # C2 Convolutional Layer\n",
    "    model.add(Conv2D(filters=20, kernel_size=(5,5)))\n",
    "    model.add(Activation('relu'))\n",
    "    # Pooling\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "    # C3 Convolutional Layer\n",
    "    model.add(Conv2D(filters=30, kernel_size=(3,3)))\n",
    "    model.add(Activation('relu'))\n",
    "    # Pooling\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "    # Flatten\n",
    "    model.add(Flatten())\n",
    "\n",
    "\n",
    "    # D1 Dense Layer\n",
    "    model.add(Dense(128))\n",
    "    model.add(Activation('relu'))\n",
    "    # Dropout\n",
    "    model.add(Dropout(0.4))\n",
    "    # D2 Dense Layer\n",
    "    model.add(Dense(96))\n",
    "    model.add(Activation('relu'))\n",
    "    # Dropout\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    # Output Layer\n",
    "    model.add(Dense(num_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    # Compile the model\n",
    "    optimizer = Adam(learning_rate=0.001)  # Adjust learning rate as needed\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Print the model summary\n",
    "    model.summary()\n",
    "\n",
    "    return model\n",
    "\n",
    "# Data Augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=False,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Assuming you have 'train' and 'validation' directories for training and validation data\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    directory='train',\n",
    "    target_size=(96, 96),\n",
    "    color_mode='rgb',\n",
    "    batch_size=64,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    directory='test',\n",
    "    target_size=(96, 96),\n",
    "    batch_size=64,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Train the model using the generators with learning rate scheduler\n",
    "model = AdvancedCNN(num_classes, input_shape)\n",
    "lr_schedule = LearningRateScheduler(lr_scheduler)\n",
    "history = model.fit(train_generator, epochs=50, validation_data=validation_generator, callbacks=[lr_schedule])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment: CarRacing-v2\n",
      "Action space: Discrete(5)\n",
      "Observation space: Box(0, 255, (96, 96, 3), uint8)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "try:\n",
    "    import gymnasium as gym\n",
    "except ModuleNotFoundError:\n",
    "    print('gymnasium module not found. Try to install with')\n",
    "    print('pip install gymnasium[box2d]')\n",
    "    sys.exit(1)\n",
    "\n",
    "\n",
    "\n",
    "def play(env, model):\n",
    "\n",
    "    seed = 2000\n",
    "    obs, _ = env.reset(seed=seed)\n",
    "    \n",
    "    # drop initial frames\n",
    "    action0 = 0\n",
    "    for i in range(50):\n",
    "        obs,_,_,_,_ = env.step(action0)\n",
    "    \n",
    "    done = False\n",
    "    while not done:\n",
    "        p = model(np.expand_dims(obs, axis=0)) # reshape input data to have a batch dimension of size 1\n",
    "        action = np.argmax(p)  # adapt to your model\n",
    "        obs, _, terminated, truncated, _ = env.step(action)\n",
    "        done = terminated or truncated\n",
    "\n",
    "    env.close()\n",
    "\n",
    "\n",
    "env_arguments = {\n",
    "    'domain_randomize': False,\n",
    "    'continuous': False,\n",
    "    'render_mode': 'human'\n",
    "}\n",
    "\n",
    "env_name = 'CarRacing-v2'\n",
    "env = gym.make(env_name, **env_arguments)\n",
    "\n",
    "print(\"Environment:\", env_name)\n",
    "print(\"Action space:\", env.action_space)\n",
    "print(\"Observation space:\", env.observation_space)\n",
    "\n",
    "play(env, model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
