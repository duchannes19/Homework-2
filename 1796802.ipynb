{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Homework 2**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gdown\n",
    "import zipfile\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded.\n"
     ]
    }
   ],
   "source": [
    "#Check if files exists in data folder\n",
    "if os.path.exists('data/'):\n",
    "    print('Files already downloaded.')\n",
    "\n",
    "else:\n",
    "    output_path = 'data.zip'\n",
    "    file_id = '1KDN-rFCq9IDJ7_kNW5y5Co100KNpklz-'\n",
    "    url = f'https://drive.google.com/uc?id={file_id}'\n",
    "    # Download the zip file\n",
    "    gdown.download(url, output_path, quiet=False)\n",
    "\n",
    "    # Extract the contents of the zip file\n",
    "    with zipfile.ZipFile(output_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall('data')\n",
    "\n",
    "    # Remove the zip file\n",
    "    os.remove(output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already extracted\n"
     ]
    }
   ],
   "source": [
    "if(os.path.exists('test/') and os.path.exists('train')):\n",
    "    print('Files already extracted')\n",
    "else:\n",
    "    print('Extracting the test.zip and train.zip files...')\n",
    "    # Extract the test.zip file\n",
    "    with zipfile.ZipFile('data/public/test.zip', 'r') as zip_ref:\n",
    "        zip_ref.extractall()\n",
    "\n",
    "    # Extract the train.zip file\n",
    "    with zipfile.ZipFile('data/public/train.zip', 'r') as zip_ref:\n",
    "        zip_ref.extractall()\n",
    "\n",
    "    print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Iteration ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Check if GPU is available\n",
    "print('GPU is', 'available' if tf.config.list_physical_devices('GPU') else 'NOT AVAILABLE')\n",
    "\n",
    "# Enable GPU\n",
    "physical_devices = tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6369 images belonging to 5 classes.\n",
      "Found 2749 images belonging to 5 classes.\n",
      "Image height = 96, Image Width = 96\n",
      "Image input (96, 96, 3)\n",
      "Classes: ['0', '1', '2', '3', '4']\n",
      "Loaded 6369 training samples from  5 classes.\n",
      "Loaded 2749 test samples from 5 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Define the path to your training data\n",
    "trainingset = 'train/'\n",
    "validationset = 'test/'\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "# Define batch size and input shape\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    zoom_range=0.1,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=False,\n",
    ")\n",
    "\n",
    "# Augment training data\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    directory=trainingset,\n",
    "    target_size=(96, 96),\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=True,\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "# No augmentation for validation data\n",
    "validation_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    directory=validationset,\n",
    "    target_size=(96, 96),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    class_mode='categorical'\n",
    ")  # set as validation data\n",
    "\n",
    "num_samples = train_generator.n\n",
    "num_classes = train_generator.num_classes\n",
    "input_shape = train_generator.image_shape\n",
    "\n",
    "classnames = [k for k, v in train_generator.class_indices.items()]\n",
    "img_h = input_shape[0]\n",
    "img_w = input_shape[1]\n",
    "print(\"Image height = %d, Image Width = %d\" % (img_h, img_w))\n",
    "print(\"Image input %s\" % str(input_shape))\n",
    "print(\"Classes: %r\" % classnames)\n",
    "print('Loaded %d training samples from  %d classes.' % (num_samples, num_classes))\n",
    "print('Loaded %d test samples from %d classes.' % (validation_generator.n, validation_generator.num_classes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"MyOptimizedCNN\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 93, 93, 15)        735       \n",
      "                                                                 \n",
      " activation (Activation)     (None, 93, 93, 15)        0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 90, 90, 20)        4820      \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 90, 90, 20)        0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 45, 45, 20)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 42, 42, 30)        9630      \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 42, 42, 30)        0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 21, 21, 30)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 13230)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               1693568   \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 128)               0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 96)                12384     \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 96)                0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 96)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 5)                 485       \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 5)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,721,622\n",
      "Trainable params: 1,721,622\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\andri\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\rmsprop.py:140: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten,\\\n",
    "                         Conv2D, MaxPooling2D\n",
    "from keras import optimizers\n",
    "\n",
    "def MyCNN(input_shape, num_classes):\n",
    "    model = Sequential(name=\"MyOptimizedCNN\")\n",
    "\n",
    "    # C1 Convolutional Layer \n",
    "    model.add(Conv2D(filters=15, input_shape=input_shape, kernel_size=(4,4)))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    # C2 Convolutional Layer\n",
    "    model.add(Conv2D(filters=20, kernel_size=(4,4)))\n",
    "    model.add(Activation('relu'))\n",
    "    # Pooling\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "    # C3 Convolutional Layer\n",
    "    model.add(Conv2D(filters=30, kernel_size=(4,4)))\n",
    "    model.add(Activation('relu'))\n",
    "    # Pooling\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "    # Flatten\n",
    "    model.add(Flatten())\n",
    "\n",
    "    # D1 Dense Layer\n",
    "    model.add(Dense(128))\n",
    "    model.add(Activation('relu'))\n",
    "    # Dropout\n",
    "    model.add(Dropout(0.4))\n",
    "    # D2 Dense Layer\n",
    "    model.add(Dense(96))\n",
    "    model.add(Activation('relu'))\n",
    "    # Dropout\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    # Output Layer\n",
    "    model.add(Dense(num_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    # Compile\n",
    "\n",
    "    optimizer = optimizers.RMSprop(lr=0.0001)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "# create the model\n",
    "# Input shape is (3, 96, 96) for the RGB image\n",
    "model = MyCNN(input_shape, num_classes)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "100/100 [==============================] - 13s 118ms/step - loss: 1.5359 - accuracy: 0.3395 - val_loss: 1.2635 - val_accuracy: 0.6457 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "100/100 [==============================] - 11s 115ms/step - loss: 1.4276 - accuracy: 0.4242 - val_loss: 1.1915 - val_accuracy: 0.6672 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "100/100 [==============================] - 12s 120ms/step - loss: 1.3962 - accuracy: 0.4572 - val_loss: 1.0764 - val_accuracy: 0.6511 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "100/100 [==============================] - 12s 115ms/step - loss: 1.3302 - accuracy: 0.4966 - val_loss: 1.0959 - val_accuracy: 0.6562 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "100/100 [==============================] - 11s 114ms/step - loss: 1.3078 - accuracy: 0.5048 - val_loss: 1.0368 - val_accuracy: 0.6661 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "100/100 [==============================] - 11s 115ms/step - loss: 1.2912 - accuracy: 0.5109 - val_loss: 1.0576 - val_accuracy: 0.6468 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "100/100 [==============================] - 11s 114ms/step - loss: 1.2766 - accuracy: 0.5230 - val_loss: 1.0293 - val_accuracy: 0.6821 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 1.2657 - accuracy: 0.5216 - val_loss: 1.1287 - val_accuracy: 0.6366 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 1.2622 - accuracy: 0.5214 - val_loss: 1.0280 - val_accuracy: 0.6613 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 1.2421 - accuracy: 0.5368 - val_loss: 1.0388 - val_accuracy: 0.6377 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "100/100 [==============================] - 12s 119ms/step - loss: 1.2414 - accuracy: 0.5365 - val_loss: 0.9815 - val_accuracy: 0.6639 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 1.2346 - accuracy: 0.5400 - val_loss: 1.0404 - val_accuracy: 0.6588 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 1.2342 - accuracy: 0.5359 - val_loss: 0.9505 - val_accuracy: 0.6755 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 1.2315 - accuracy: 0.5459 - val_loss: 1.0182 - val_accuracy: 0.6591 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 1.2209 - accuracy: 0.5483 - val_loss: 1.0209 - val_accuracy: 0.6450 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 1.2108 - accuracy: 0.5499 - val_loss: 1.0687 - val_accuracy: 0.6471 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 1.1940 - accuracy: 0.5575 - val_loss: 0.9828 - val_accuracy: 0.6664 - lr: 2.0000e-04\n",
      "Epoch 18/50\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.1814 - accuracy: 0.5605Restoring model weights from the end of the best epoch: 13.\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 1.1814 - accuracy: 0.5605 - val_loss: 1.0243 - val_accuracy: 0.6450 - lr: 2.0000e-04\n",
      "Epoch 18: early stopping\n"
     ]
    }
   ],
   "source": [
    "from keras import callbacks\n",
    "\n",
    "# Define callbacks\n",
    "early_stopping = callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='auto', restore_best_weights=True)\n",
    "reduce_lr = callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-6)\n",
    "\n",
    "# Calculate steps per epoch and validation steps\n",
    "steps_per_epoch = len(train_generator)\n",
    "val_steps = len(validation_generator)\n",
    "\n",
    "try:\n",
    "    # Train the model with better training parameters\n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        epochs=50,\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=val_steps,\n",
    "        callbacks=[early_stopping, reduce_lr]\n",
    "    )\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model to disk\n",
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model = load_model('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andri\\AppData\\Local\\Temp\\ipykernel_13456\\989374102.py:2: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n",
      "  loss, acc = model.evaluate_generator(validation_generator,steps=val_steps)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.950330\n",
      "Test accuracy: 0.669698\n"
     ]
    }
   ],
   "source": [
    "val_steps=validation_generator.n//validation_generator.batch_size+1\n",
    "loss, acc = model.evaluate_generator(validation_generator,steps=val_steps)\n",
    "print('Test loss: %f' %loss)\n",
    "print('Test accuracy: %f' %acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 2s 99ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.500     0.075     0.131        53\n",
      "           1      0.287     0.509     0.367       110\n",
      "           2      0.417     0.512     0.460       162\n",
      "           3      0.810     0.736     0.771       758\n",
      "           4      0.000     0.000     0.000        15\n",
      "\n",
      "    accuracy                          0.638      1098\n",
      "   macro avg      0.403     0.367     0.346      1098\n",
      "weighted avg      0.674     0.638     0.643      1098\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    " \n",
    "preds = model.predict(validation_generator,steps=val_steps)\n",
    "\n",
    "Ypred = np.argmax(preds, axis=1)\n",
    "Ytest = validation_generator.classes  # shuffle=False in test_generator\n",
    "\n",
    "print(classification_report(Ytest, Ypred, labels=None, target_names=classnames, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 2s 99ms/step\n",
      "True                 Predicted         \terrors \terr % \n",
      "------------------------------------------------------------------\n",
      "3                ->  1                 \t107 \t9.74 % \n",
      "3                ->  2                 \t94 \t8.56 % \n",
      "2                ->  3                 \t58 \t5.28 % \n",
      "1                ->  3                 \t36 \t3.28 % \n",
      "0                ->  3                 \t27 \t2.46 % \n",
      "0                ->  1                 \t15 \t1.37 % \n",
      "2                ->  1                 \t15 \t1.37 % \n",
      "1                ->  2                 \t13 \t1.18 % \n",
      "4                ->  3                 \t9 \t0.82 % \n",
      "0                ->  2                 \t5 \t0.46 % \n",
      "2                ->  4                 \t3 \t0.27 % \n",
      "4                ->  1                 \t3 \t0.27 % \n",
      "4                ->  2                 \t2 \t0.18 % \n",
      "3                ->  4                 \t2 \t0.18 % \n",
      "2                ->  0                 \t1 \t0.09 % \n",
      "1                ->  0                 \t1 \t0.09 % \n",
      "3                ->  0                 \t1 \t0.09 % \n",
      "0                ->  4                 \t1 \t0.09 % \n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "preds = model.predict(validation_generator,verbose=1,steps=val_steps)\n",
    "\n",
    "Ypred = np.argmax(preds, axis=1)\n",
    "Ytest = validation_generator.classes  # shuffle=False in test_generator\n",
    "\n",
    "cm = confusion_matrix(Ytest, Ypred)\n",
    "\n",
    "conf = [] # data structure for confusions: list of (i,j,cm[i][j])\n",
    "for i in range(0,cm.shape[0]):\n",
    "  for j in range(0,cm.shape[1]):\n",
    "    if (i!=j and cm[i][j]>0):\n",
    "      conf.append([i,j,cm[i][j]])\n",
    "\n",
    "col=2\n",
    "conf = np.array(conf)\n",
    "conf = conf[np.argsort(-conf[:,col])]  # decreasing order by 3-rd column (i.e., cm[i][j])\n",
    "\n",
    "print('%-16s     %-16s  \\t%s \\t%s ' %('True','Predicted','errors','err %'))\n",
    "print('------------------------------------------------------------------')\n",
    "for k in conf:\n",
    "  print('%-16s ->  %-16s  \\t%d \\t%.2f %% ' %(classnames[k[0]],classnames[k[1]],k[2],k[2]*100.0/validation_generator.n))\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment: CarRacing-v2\n",
      "Action space: Discrete(5)\n",
      "Observation space: Box(0, 255, (96, 96, 3), uint8)\n",
      "Moviepy - Building video c:\\Users\\andri\\Documents\\GitHub\\Homework-2\\video_recordings\\rl-video-episode-0.mp4.\n",
      "Moviepy - Writing video c:\\Users\\andri\\Documents\\GitHub\\Homework-2\\video_recordings\\rl-video-episode-0.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready c:\\Users\\andri\\Documents\\GitHub\\Homework-2\\video_recordings\\rl-video-episode-0.mp4\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "\n",
    "try:\n",
    "    import gymnasium as gym\n",
    "except ModuleNotFoundError:\n",
    "    print('gymnasium module not found. Try to install with')\n",
    "    print('pip install gymnasium[box2d]')\n",
    "    sys.exit(1)\n",
    "\n",
    "from gymnasium.wrappers import RecordVideo   # Import the Monitor wrapper\n",
    "\n",
    "model = load_model('model.h5')\n",
    "\n",
    "def play(env, model):\n",
    "\n",
    "    seed = 2000\n",
    "    obs, _ = env.reset(seed=seed)\n",
    "    \n",
    "    # drop initial frames\n",
    "    action0 = 0\n",
    "    for i in range(50):\n",
    "        obs,_,_,_,_ = env.step(action0)\n",
    "    \n",
    "    done = False\n",
    "    while not done:\n",
    "        p = model(np.expand_dims(obs, axis=0)) # reshape input data to have a batch dimension of size 1\n",
    "        action = np.argmax(p)  # adapt to your model\n",
    "        obs, _, terminated, truncated, _ = env.step(action)\n",
    "        done = terminated or truncated\n",
    "\n",
    "    env.close()\n",
    "\n",
    "env_arguments = {\n",
    "    'domain_randomize': False,\n",
    "    'continuous': False,\n",
    "    'render_mode': 'rgb_array'\n",
    "}\n",
    "\n",
    "env_name = 'CarRacing-v2'\n",
    "env = gym.make(env_name, **env_arguments)\n",
    "\n",
    "# Wrap the environment with the Monitor wrapper to record videos\n",
    "video_dir = 'video_recordings'  # Specify the directory to save video recordings\n",
    "env = RecordVideo (env, video_dir)\n",
    "\n",
    "print(\"Environment:\", env_name)\n",
    "print(\"Action space:\", env.action_space)\n",
    "print(\"Observation space:\", env.observation_space)\n",
    "\n",
    "play(env, model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second Iteration ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6369 images belonging to 5 classes.\n",
      "Found 2749 images belonging to 5 classes.\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_9 (Conv2D)           (None, 92, 92, 15)        1140      \n",
      "                                                                 \n",
      " activation_18 (Activation)  (None, 92, 92, 15)        0         \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 88, 88, 20)        7520      \n",
      "                                                                 \n",
      " activation_19 (Activation)  (None, 88, 88, 20)        0         \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 44, 44, 20)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 42, 42, 30)        5430      \n",
      "                                                                 \n",
      " activation_20 (Activation)  (None, 42, 42, 30)        0         \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 21, 21, 30)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 13230)             0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 128)               1693568   \n",
      "                                                                 \n",
      " activation_21 (Activation)  (None, 128)               0         \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 96)                12384     \n",
      "                                                                 \n",
      " activation_22 (Activation)  (None, 96)                0         \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 96)                0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 5)                 485       \n",
      "                                                                 \n",
      " activation_23 (Activation)  (None, 5)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,720,527\n",
      "Trainable params: 1,720,527\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "100/100 [==============================] - 13s 128ms/step - loss: 1.5017 - accuracy: 0.3366 - val_loss: 1.2162 - val_accuracy: 0.6657 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 12s 123ms/step - loss: 1.4356 - accuracy: 0.4147 - val_loss: 1.1642 - val_accuracy: 0.6362 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 12s 124ms/step - loss: 1.3955 - accuracy: 0.4418 - val_loss: 1.1355 - val_accuracy: 0.6551 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 13s 125ms/step - loss: 1.3785 - accuracy: 0.4654 - val_loss: 1.0435 - val_accuracy: 0.7013 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 12s 122ms/step - loss: 1.3384 - accuracy: 0.4936 - val_loss: 0.9683 - val_accuracy: 0.7086 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 12s 121ms/step - loss: 1.3020 - accuracy: 0.5067 - val_loss: 1.0887 - val_accuracy: 0.6577 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 12s 117ms/step - loss: 1.3021 - accuracy: 0.5076 - val_loss: 1.0784 - val_accuracy: 0.6570 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 12s 123ms/step - loss: 1.2894 - accuracy: 0.5159 - val_loss: 1.1343 - val_accuracy: 0.6002 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 12s 121ms/step - loss: 1.2822 - accuracy: 0.5148 - val_loss: 1.1047 - val_accuracy: 0.6617 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 12s 117ms/step - loss: 1.2632 - accuracy: 0.5236 - val_loss: 1.0008 - val_accuracy: 0.6551 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 12s 116ms/step - loss: 1.2648 - accuracy: 0.5213 - val_loss: 0.9984 - val_accuracy: 0.6639 - lr: 9.0000e-04\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 12s 116ms/step - loss: 1.2579 - accuracy: 0.5320 - val_loss: 1.1244 - val_accuracy: 0.6049 - lr: 9.0000e-04\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 12s 115ms/step - loss: 1.2539 - accuracy: 0.5310 - val_loss: 1.0076 - val_accuracy: 0.6653 - lr: 9.0000e-04\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 12s 115ms/step - loss: 1.2491 - accuracy: 0.5296 - val_loss: 1.0144 - val_accuracy: 0.6464 - lr: 9.0000e-04\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 12s 115ms/step - loss: 1.2436 - accuracy: 0.5310 - val_loss: 1.0725 - val_accuracy: 0.6268 - lr: 9.0000e-04\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 12s 115ms/step - loss: 1.2320 - accuracy: 0.5298 - val_loss: 0.9952 - val_accuracy: 0.6504 - lr: 9.0000e-04\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 11s 115ms/step - loss: 1.2346 - accuracy: 0.5337 - val_loss: 1.0801 - val_accuracy: 0.6391 - lr: 9.0000e-04\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 12s 122ms/step - loss: 1.2248 - accuracy: 0.5420 - val_loss: 0.9494 - val_accuracy: 0.6621 - lr: 9.0000e-04\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 12s 124ms/step - loss: 1.2318 - accuracy: 0.5365 - val_loss: 0.9972 - val_accuracy: 0.6504 - lr: 9.0000e-04\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 13s 125ms/step - loss: 1.2322 - accuracy: 0.5349 - val_loss: 1.0293 - val_accuracy: 0.6406 - lr: 9.0000e-04\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 13s 127ms/step - loss: 1.2196 - accuracy: 0.5398 - val_loss: 0.9843 - val_accuracy: 0.6642 - lr: 8.1000e-04\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 13s 126ms/step - loss: 1.2167 - accuracy: 0.5412 - val_loss: 0.9939 - val_accuracy: 0.6588 - lr: 8.1000e-04\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 13s 125ms/step - loss: 1.2099 - accuracy: 0.5500 - val_loss: 0.9770 - val_accuracy: 0.6581 - lr: 8.1000e-04\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 12s 124ms/step - loss: 1.2145 - accuracy: 0.5404 - val_loss: 0.9809 - val_accuracy: 0.6588 - lr: 8.1000e-04\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 13s 125ms/step - loss: 1.2171 - accuracy: 0.5411 - val_loss: 1.0106 - val_accuracy: 0.6533 - lr: 8.1000e-04\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 12s 120ms/step - loss: 1.2078 - accuracy: 0.5514 - val_loss: 0.9864 - val_accuracy: 0.6555 - lr: 8.1000e-04\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 13s 125ms/step - loss: 1.2168 - accuracy: 0.5384 - val_loss: 1.0154 - val_accuracy: 0.6391 - lr: 8.1000e-04\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 12s 123ms/step - loss: 1.2132 - accuracy: 0.5395 - val_loss: 1.0013 - val_accuracy: 0.6402 - lr: 8.1000e-04\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 12s 123ms/step - loss: 1.2004 - accuracy: 0.5522 - val_loss: 1.0020 - val_accuracy: 0.6279 - lr: 8.1000e-04\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 12s 120ms/step - loss: 1.2049 - accuracy: 0.5475 - val_loss: 1.0246 - val_accuracy: 0.6461 - lr: 8.1000e-04\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 13s 128ms/step - loss: 1.1944 - accuracy: 0.5459 - val_loss: 1.0278 - val_accuracy: 0.6431 - lr: 7.2900e-04\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 12s 123ms/step - loss: 1.2003 - accuracy: 0.5502 - val_loss: 0.9782 - val_accuracy: 0.6497 - lr: 7.2900e-04\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 13s 127ms/step - loss: 1.1901 - accuracy: 0.5550 - val_loss: 1.0483 - val_accuracy: 0.6177 - lr: 7.2900e-04\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 12s 124ms/step - loss: 1.1934 - accuracy: 0.5544 - val_loss: 1.0232 - val_accuracy: 0.6337 - lr: 7.2900e-04\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 12s 124ms/step - loss: 1.1915 - accuracy: 0.5525 - val_loss: 0.9754 - val_accuracy: 0.6668 - lr: 7.2900e-04\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 12s 124ms/step - loss: 1.1922 - accuracy: 0.5502 - val_loss: 1.0127 - val_accuracy: 0.6519 - lr: 7.2900e-04\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 12s 124ms/step - loss: 1.1903 - accuracy: 0.5547 - val_loss: 0.9888 - val_accuracy: 0.6431 - lr: 7.2900e-04\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 12s 122ms/step - loss: 1.1899 - accuracy: 0.5516 - val_loss: 1.0081 - val_accuracy: 0.6290 - lr: 7.2900e-04\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 13s 125ms/step - loss: 1.1824 - accuracy: 0.5618 - val_loss: 1.0422 - val_accuracy: 0.6115 - lr: 7.2900e-04\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 12s 123ms/step - loss: 1.1798 - accuracy: 0.5528 - val_loss: 1.0048 - val_accuracy: 0.6366 - lr: 7.2900e-04\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 12s 124ms/step - loss: 1.1815 - accuracy: 0.5586 - val_loss: 1.0363 - val_accuracy: 0.6013 - lr: 6.5610e-04\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 12s 123ms/step - loss: 1.1855 - accuracy: 0.5544 - val_loss: 1.0281 - val_accuracy: 0.6068 - lr: 6.5610e-04\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 12s 123ms/step - loss: 1.1828 - accuracy: 0.5520 - val_loss: 0.9894 - val_accuracy: 0.6439 - lr: 6.5610e-04\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 12s 123ms/step - loss: 1.1754 - accuracy: 0.5601 - val_loss: 1.0047 - val_accuracy: 0.6504 - lr: 6.5610e-04\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 13s 125ms/step - loss: 1.1695 - accuracy: 0.5618 - val_loss: 0.9124 - val_accuracy: 0.6799 - lr: 6.5610e-04\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 12s 123ms/step - loss: 1.1775 - accuracy: 0.5615 - val_loss: 0.9682 - val_accuracy: 0.6519 - lr: 6.5610e-04\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 12s 124ms/step - loss: 1.1750 - accuracy: 0.5571 - val_loss: 0.9770 - val_accuracy: 0.6515 - lr: 6.5610e-04\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 12s 124ms/step - loss: 1.1668 - accuracy: 0.5612 - val_loss: 0.9960 - val_accuracy: 0.6446 - lr: 6.5610e-04\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 12s 124ms/step - loss: 1.1738 - accuracy: 0.5638 - val_loss: 1.0455 - val_accuracy: 0.6235 - lr: 6.5610e-04\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 12s 124ms/step - loss: 1.1717 - accuracy: 0.5588 - val_loss: 0.9820 - val_accuracy: 0.6431 - lr: 6.5610e-04\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 12s 124ms/step - loss: 1.1674 - accuracy: 0.5602 - val_loss: 0.9341 - val_accuracy: 0.6799 - lr: 5.9049e-04\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 12s 122ms/step - loss: 1.1605 - accuracy: 0.5561 - val_loss: 0.9837 - val_accuracy: 0.6391 - lr: 5.9049e-04\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 13s 127ms/step - loss: 1.1635 - accuracy: 0.5654 - val_loss: 0.9496 - val_accuracy: 0.6708 - lr: 5.9049e-04\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 12s 124ms/step - loss: 1.1637 - accuracy: 0.5635 - val_loss: 0.9557 - val_accuracy: 0.6690 - lr: 5.9049e-04\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 12s 123ms/step - loss: 1.1654 - accuracy: 0.5597 - val_loss: 0.9843 - val_accuracy: 0.6519 - lr: 5.9049e-04\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 13s 125ms/step - loss: 1.1679 - accuracy: 0.5585 - val_loss: 0.8868 - val_accuracy: 0.6821 - lr: 5.9049e-04\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 12s 123ms/step - loss: 1.1660 - accuracy: 0.5629 - val_loss: 0.9280 - val_accuracy: 0.6733 - lr: 5.9049e-04\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 12s 122ms/step - loss: 1.1502 - accuracy: 0.5715 - val_loss: 0.9049 - val_accuracy: 0.6912 - lr: 5.9049e-04\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 12s 124ms/step - loss: 1.1572 - accuracy: 0.5612 - val_loss: 0.9294 - val_accuracy: 0.6766 - lr: 5.9049e-04\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 12s 123ms/step - loss: 1.1596 - accuracy: 0.5723 - val_loss: 0.9797 - val_accuracy: 0.6573 - lr: 5.9049e-04\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 12s 124ms/step - loss: 1.1586 - accuracy: 0.5674 - val_loss: 0.9593 - val_accuracy: 0.6595 - lr: 5.3144e-04\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 12s 124ms/step - loss: 1.1562 - accuracy: 0.5690 - val_loss: 0.9595 - val_accuracy: 0.6566 - lr: 5.3144e-04\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 13s 126ms/step - loss: 1.1532 - accuracy: 0.5721 - val_loss: 0.9246 - val_accuracy: 0.6653 - lr: 5.3144e-04\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 13s 125ms/step - loss: 1.1549 - accuracy: 0.5681 - val_loss: 0.9290 - val_accuracy: 0.6726 - lr: 5.3144e-04\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 13s 127ms/step - loss: 1.1571 - accuracy: 0.5660 - val_loss: 0.9179 - val_accuracy: 0.6766 - lr: 5.3144e-04\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 12s 124ms/step - loss: 1.1525 - accuracy: 0.5660 - val_loss: 0.9862 - val_accuracy: 0.6457 - lr: 5.3144e-04\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 12s 124ms/step - loss: 1.1476 - accuracy: 0.5747 - val_loss: 0.9737 - val_accuracy: 0.6577 - lr: 5.3144e-04\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 12s 124ms/step - loss: 1.1479 - accuracy: 0.5731 - val_loss: 0.9450 - val_accuracy: 0.6661 - lr: 5.3144e-04\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 13s 125ms/step - loss: 1.1572 - accuracy: 0.5698 - val_loss: 0.9239 - val_accuracy: 0.6701 - lr: 5.3144e-04\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 12s 123ms/step - loss: 1.1565 - accuracy: 0.5688 - val_loss: 0.9309 - val_accuracy: 0.6744 - lr: 5.3144e-04\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 12s 124ms/step - loss: 1.1476 - accuracy: 0.5703 - val_loss: 0.9010 - val_accuracy: 0.6839 - lr: 4.7830e-04\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 12s 124ms/step - loss: 1.1474 - accuracy: 0.5674 - val_loss: 0.9526 - val_accuracy: 0.6599 - lr: 4.7830e-04\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 13s 127ms/step - loss: 1.1417 - accuracy: 0.5765 - val_loss: 0.9307 - val_accuracy: 0.6617 - lr: 4.7830e-04\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 12s 124ms/step - loss: 1.1405 - accuracy: 0.5787 - val_loss: 0.9170 - val_accuracy: 0.6679 - lr: 4.7830e-04\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 12s 124ms/step - loss: 1.1474 - accuracy: 0.5703 - val_loss: 0.9381 - val_accuracy: 0.6784 - lr: 4.7830e-04\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 12s 124ms/step - loss: 1.1423 - accuracy: 0.5701 - val_loss: 0.9241 - val_accuracy: 0.6781 - lr: 4.7830e-04\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 12s 123ms/step - loss: 1.1415 - accuracy: 0.5701 - val_loss: 0.9431 - val_accuracy: 0.6708 - lr: 4.7830e-04\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 12s 124ms/step - loss: 1.1360 - accuracy: 0.5742 - val_loss: 0.9689 - val_accuracy: 0.6577 - lr: 4.7830e-04\n",
      "Epoch 79/100\n",
      "100/100 [==============================] - 12s 123ms/step - loss: 1.1392 - accuracy: 0.5781 - val_loss: 0.9242 - val_accuracy: 0.6842 - lr: 4.7830e-04\n",
      "Epoch 80/100\n",
      "100/100 [==============================] - 13s 125ms/step - loss: 1.1362 - accuracy: 0.5710 - val_loss: 0.9720 - val_accuracy: 0.6548 - lr: 4.7830e-04\n",
      "Epoch 81/100\n",
      "100/100 [==============================] - 12s 124ms/step - loss: 1.1337 - accuracy: 0.5797 - val_loss: 0.9755 - val_accuracy: 0.6632 - lr: 4.3047e-04\n",
      "Epoch 82/100\n",
      "100/100 [==============================] - 12s 124ms/step - loss: 1.1340 - accuracy: 0.5736 - val_loss: 0.9381 - val_accuracy: 0.6817 - lr: 4.3047e-04\n",
      "Epoch 83/100\n",
      "100/100 [==============================] - 12s 124ms/step - loss: 1.1414 - accuracy: 0.5756 - val_loss: 0.9410 - val_accuracy: 0.6617 - lr: 4.3047e-04\n",
      "Epoch 84/100\n",
      "100/100 [==============================] - 12s 124ms/step - loss: 1.1448 - accuracy: 0.5712 - val_loss: 0.9931 - val_accuracy: 0.6530 - lr: 4.3047e-04\n",
      "Epoch 85/100\n",
      "100/100 [==============================] - 12s 123ms/step - loss: 1.1338 - accuracy: 0.5721 - val_loss: 0.9343 - val_accuracy: 0.6693 - lr: 4.3047e-04\n",
      "Epoch 86/100\n",
      "100/100 [==============================] - 12s 123ms/step - loss: 1.1303 - accuracy: 0.5764 - val_loss: 1.0027 - val_accuracy: 0.6544 - lr: 4.3047e-04\n",
      "Epoch 87/100\n",
      "100/100 [==============================] - 13s 125ms/step - loss: 1.1299 - accuracy: 0.5814 - val_loss: 0.9644 - val_accuracy: 0.6701 - lr: 4.3047e-04\n",
      "Epoch 88/100\n",
      "100/100 [==============================] - 12s 124ms/step - loss: 1.1409 - accuracy: 0.5753 - val_loss: 0.9706 - val_accuracy: 0.6464 - lr: 4.3047e-04\n",
      "Epoch 89/100\n",
      "100/100 [==============================] - 12s 125ms/step - loss: 1.1308 - accuracy: 0.5729 - val_loss: 0.9580 - val_accuracy: 0.6650 - lr: 4.3047e-04\n",
      "Epoch 90/100\n",
      "100/100 [==============================] - 13s 125ms/step - loss: 1.1445 - accuracy: 0.5761 - val_loss: 1.0152 - val_accuracy: 0.6286 - lr: 4.3047e-04\n",
      "Epoch 91/100\n",
      "100/100 [==============================] - 12s 124ms/step - loss: 1.1385 - accuracy: 0.5758 - val_loss: 0.9616 - val_accuracy: 0.6602 - lr: 3.8742e-04\n",
      "Epoch 92/100\n",
      "100/100 [==============================] - 13s 125ms/step - loss: 1.1263 - accuracy: 0.5794 - val_loss: 0.9735 - val_accuracy: 0.6704 - lr: 3.8742e-04\n",
      "Epoch 93/100\n",
      "100/100 [==============================] - 13s 126ms/step - loss: 1.1333 - accuracy: 0.5712 - val_loss: 0.9957 - val_accuracy: 0.6522 - lr: 3.8742e-04\n",
      "Epoch 94/100\n",
      "100/100 [==============================] - 12s 122ms/step - loss: 1.1274 - accuracy: 0.5809 - val_loss: 0.9971 - val_accuracy: 0.6482 - lr: 3.8742e-04\n",
      "Epoch 95/100\n",
      "100/100 [==============================] - 12s 123ms/step - loss: 1.1309 - accuracy: 0.5739 - val_loss: 0.9926 - val_accuracy: 0.6511 - lr: 3.8742e-04\n",
      "Epoch 96/100\n",
      "100/100 [==============================] - 12s 123ms/step - loss: 1.1298 - accuracy: 0.5762 - val_loss: 0.9720 - val_accuracy: 0.6402 - lr: 3.8742e-04\n",
      "Epoch 97/100\n",
      "100/100 [==============================] - 13s 126ms/step - loss: 1.1269 - accuracy: 0.5773 - val_loss: 1.0375 - val_accuracy: 0.6053 - lr: 3.8742e-04\n",
      "Epoch 98/100\n",
      "100/100 [==============================] - 13s 125ms/step - loss: 1.1329 - accuracy: 0.5690 - val_loss: 1.0277 - val_accuracy: 0.6177 - lr: 3.8742e-04\n",
      "Epoch 99/100\n",
      "100/100 [==============================] - 12s 123ms/step - loss: 1.1275 - accuracy: 0.5767 - val_loss: 0.9860 - val_accuracy: 0.6250 - lr: 3.8742e-04\n",
      "Epoch 100/100\n",
      "100/100 [==============================] - 12s 122ms/step - loss: 1.1292 - accuracy: 0.5820 - val_loss: 0.9503 - val_accuracy: 0.6697 - lr: 3.8742e-04\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten, MaxPooling2D, BatchNormalization, Dropout, GlobalAveragePooling2D, Activation\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "\n",
    "def lr_scheduler(epoch, lr):\n",
    "    if epoch % 10 == 0 and epoch != 0:\n",
    "        lr = lr * 0.9  \n",
    "    return lr\n",
    "\n",
    "def AdvancedCNN(num_classes, input_shape):\n",
    "    model = Sequential()\n",
    "\n",
    "    # C1 Convolutional Layer \n",
    "    model.add(Conv2D(filters=15, input_shape=input_shape, kernel_size=(5,5)))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    # C2 Convolutional Layer\n",
    "    model.add(Conv2D(filters=20, kernel_size=(5,5)))\n",
    "    model.add(Activation('relu'))\n",
    "    # Pooling\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "    # C3 Convolutional Layer\n",
    "    model.add(Conv2D(filters=30, kernel_size=(3,3)))\n",
    "    model.add(Activation('relu'))\n",
    "    # Pooling\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "    # Flatten\n",
    "    model.add(Flatten())\n",
    "\n",
    "    # D1 Dense Layer\n",
    "    model.add(Dense(128))\n",
    "    model.add(Activation('relu'))\n",
    "    # Dropout\n",
    "    model.add(Dropout(0.4))\n",
    "    # D2 Dense Layer\n",
    "    model.add(Dense(96))\n",
    "    model.add(Activation('relu'))\n",
    "    # Dropout\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    # Output Layer\n",
    "    model.add(Dense(num_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    # Compile the model\n",
    "    optimizer = Adam(learning_rate=0.001)  # Adjust learning rate as needed\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Print the model summary\n",
    "    model.summary()\n",
    "\n",
    "    return model\n",
    "\n",
    "# Data Augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=False,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Assuming you have 'train' and 'validation' directories for training and validation data\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    directory='train',\n",
    "    target_size=(96, 96),\n",
    "    color_mode='rgb',\n",
    "    batch_size=64,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    directory='test',\n",
    "    target_size=(96, 96),\n",
    "    batch_size=64,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "num_classes = train_generator.num_classes\n",
    "input_shape = train_generator.image_shape\n",
    "\n",
    "# Train the model using the generators with learning rate scheduler\n",
    "model = AdvancedCNN(num_classes, input_shape)\n",
    "lr_schedule = LearningRateScheduler(lr_scheduler)\n",
    "history = model.fit(train_generator, epochs=100, validation_data=validation_generator, callbacks=[lr_schedule])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save second model\n",
    "model.save('model2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 2s 36ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.400     0.241     0.300       133\n",
      "           1      0.361     0.604     0.452       275\n",
      "           2      0.484     0.724     0.580       406\n",
      "           3      0.846     0.711     0.773      1896\n",
      "           4      0.000     0.000     0.000        39\n",
      "\n",
      "    accuracy                          0.670      2749\n",
      "   macro avg      0.418     0.456     0.421      2749\n",
      "weighted avg      0.711     0.670     0.679      2749\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "try:\n",
    "    import gymnasium as gym\n",
    "except ModuleNotFoundError:\n",
    "    print('gymnasium module not found. Try to install with')\n",
    "    print('pip install gymnasium[box2d]')\n",
    "    sys.exit(1)\n",
    "\n",
    "model = load_model('model2.h5')\n",
    "\n",
    "# Classification report\n",
    " \n",
    "preds = model.predict(validation_generator,steps=val_steps)\n",
    "\n",
    "Ypred = np.argmax(preds, axis=1)\n",
    "Ytest = validation_generator.classes  # shuffle=False in test_generator\n",
    "\n",
    "print(classification_report(Ytest, Ypred, labels=None, target_names=classnames, digits=3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\andri\\miniconda3\\envs\\tf\\lib\\site-packages\\gymnasium\\wrappers\\record_video.py:94: UserWarning: \u001b[33mWARN: Overwriting existing videos at c:\\Users\\andri\\Documents\\GitHub\\Homework-2\\video_recordings folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment: CarRacing-v2\n",
      "Action space: Discrete(5)\n",
      "Observation space: Box(0, 255, (96, 96, 3), uint8)\n",
      "Moviepy - Building video c:\\Users\\andri\\Documents\\GitHub\\Homework-2\\video_recordings\\rl-video-episode-0.mp4.\n",
      "Moviepy - Writing video c:\\Users\\andri\\Documents\\GitHub\\Homework-2\\video_recordings\\rl-video-episode-0.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready c:\\Users\\andri\\Documents\\GitHub\\Homework-2\\video_recordings\\rl-video-episode-0.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "\n",
    "try:\n",
    "    import gymnasium as gym\n",
    "except ModuleNotFoundError:\n",
    "    print('gymnasium module not found. Try to install with')\n",
    "    print('pip install gymnasium[box2d]')\n",
    "    sys.exit(1)\n",
    "\n",
    "from gymnasium.wrappers import RecordVideo   # Import the Monitor wrapper\n",
    "\n",
    "model = load_model('model2.h5')\n",
    "\n",
    "def play(env, model):\n",
    "\n",
    "    seed = 2000\n",
    "    obs, _ = env.reset(seed=seed)\n",
    "    \n",
    "    # drop initial frames\n",
    "    action0 = 0\n",
    "    for i in range(50):\n",
    "        obs,_,_,_,_ = env.step(action0)\n",
    "    \n",
    "    done = False\n",
    "    while not done:\n",
    "        p = model(np.expand_dims(obs, axis=0)) # reshape input data to have a batch dimension of size 1\n",
    "        action = np.argmax(p)  # adapt to your model\n",
    "        obs, _, terminated, truncated, _ = env.step(action)\n",
    "        done = terminated or truncated\n",
    "\n",
    "    env.close()\n",
    "\n",
    "env_arguments = {\n",
    "    'domain_randomize': False,\n",
    "    'continuous': False,\n",
    "    'render_mode': 'rgb_array'\n",
    "}\n",
    "\n",
    "env_name = 'CarRacing-v2'\n",
    "env = gym.make(env_name, **env_arguments)\n",
    "\n",
    "# Wrap the environment with the Monitor wrapper to record videos\n",
    "video_dir = 'video_recordings'  # Specify the directory to save video recordings\n",
    "env = RecordVideo (env, video_dir)\n",
    "\n",
    "print(\"Environment:\", env_name)\n",
    "print(\"Action space:\", env.action_space)\n",
    "print(\"Observation space:\", env.observation_space)\n",
    "\n",
    "play(env, model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
