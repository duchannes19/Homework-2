{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Homework 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gdown\n",
    "import zipfile\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded.\n"
     ]
    }
   ],
   "source": [
    "#Check if files exists in data folder\n",
    "if os.path.exists('data/'):\n",
    "    print('Files already downloaded.')\n",
    "\n",
    "else:\n",
    "    output_path = 'data.zip'\n",
    "    file_id = '1KDN-rFCq9IDJ7_kNW5y5Co100KNpklz-'\n",
    "    url = f'https://drive.google.com/uc?id={file_id}'\n",
    "    # Download the zip file\n",
    "    gdown.download(url, output_path, quiet=False)\n",
    "\n",
    "    # Extract the contents of the zip file\n",
    "    with zipfile.ZipFile(output_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall('data')\n",
    "\n",
    "    # Remove the zip file\n",
    "    os.remove(output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already extracted\n"
     ]
    }
   ],
   "source": [
    "if(os.path.exists('test/') and os.path.exists('train')):\n",
    "    print('Files already extracted')\n",
    "else:\n",
    "    print('Extracting the test.zip and train.zip files...')\n",
    "    # Extract the test.zip file\n",
    "    with zipfile.ZipFile('data/public/test.zip', 'r') as zip_ref:\n",
    "        zip_ref.extractall()\n",
    "\n",
    "    # Extract the train.zip file\n",
    "    with zipfile.ZipFile('data/public/train.zip', 'r') as zip_ref:\n",
    "        zip_ref.extractall()\n",
    "\n",
    "    print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Approach: Deep Reinforcement Learning (DRL)\n",
    "\n",
    "In this approach, we will utilize Deep Reinforcement Learning (DRL) techniques to solve our problem. DRL combines the power of deep neural networks with reinforcement learning algorithms to learn optimal policies in complex environments.\n",
    "\n",
    "### Step 1: Environment Setup\n",
    "\n",
    "First, we need to define our environment. This includes selecting an appropriate gym environment or creating a custom environment that suits our problem. The environment should provide observations, actions, and rewards.\n",
    "\n",
    "### Step 2: Agent Design\n",
    "\n",
    "Next, we design our DRL agent. The agent consists of a deep neural network, often referred to as the Q-network, which takes observations as input and outputs action values for each possible action. We can use popular deep learning frameworks like PyTorch or TensorFlow to implement the Q-network.\n",
    "\n",
    "### Step 3: Training Loop\n",
    "\n",
    "The training loop involves the following steps:\n",
    "\n",
    "1. Initialize the Q-network with random weights.\n",
    "2. Observe the current state from the environment.\n",
    "3. Select an action using an exploration-exploitation strategy, such as epsilon-greedy or softmax.\n",
    "4. Execute the selected action in the environment and observe the next state and reward.\n",
    "5. Update the Q-network using the observed state, action, next state, and reward.\n",
    "6. Repeat steps 2-5 until convergence or a maximum number of iterations.\n",
    "\n",
    "During training, we can use techniques like experience replay and target networks to stabilize and improve the learning process.\n",
    "\n",
    "### Step 4: Evaluation\n",
    "\n",
    "After training, we evaluate the performance of our agent by running it in the environment and measuring its performance metrics, such as average reward or success rate. This helps us assess the effectiveness of our DRL approach.\n",
    "\n",
    "### Step 5: Fine-tuning and Optimization\n",
    "\n",
    "Based on the evaluation results, we can fine-tune and optimize our DRL approach. This may involve adjusting hyperparameters, modifying the network architecture, or trying different exploration-exploitation strategies.\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "Deep Reinforcement Learning (DRL) offers a powerful approach to solving complex problems by combining deep neural networks with reinforcement learning algorithms. By following the steps outlined above, we can develop and train a DRL agent to learn optimal policies in our environment. However, it is important to note that DRL can be computationally intensive and may require significant computational resources and time for training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second Approach\n",
    "\n",
    "For the second approach, we will use a different architecture to train our model. Instead of using a pre-trained ResNet18 model, we will use a custom convolutional neural network (CNN) architecture.\n",
    "\n",
    "### Step 1: Data Loading and Preprocessing\n",
    "\n",
    "Similar to the first approach, we will load and preprocess our dataset using the same transformations. We will also create data loaders for the training and validation sets.\n",
    "\n",
    "### Step 2: Model Architecture\n",
    "\n",
    "In this approach, we will define a custom CNN model. The model will consist of multiple convolutional layers followed by fully connected layers. We will use ReLU activation functions and dropout regularization to prevent overfitting.\n",
    "\n",
    "### Step 3: Training Loop\n",
    "\n",
    "We will train the model using a similar training loop as in the first approach. We will iterate over the training set, compute the loss, perform backpropagation, and update the model's weights.\n",
    "\n",
    "### Step 4: Model Evaluation\n",
    "\n",
    "After training, we will evaluate the model on the validation set. We will calculate the accuracy of the model by comparing the predicted labels with the ground truth labels.\n",
    "\n",
    "### Step 5: Save the Model\n",
    "\n",
    "Finally, we will save the trained model to a file for future use.\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "In this second approach, we used a custom CNN architecture to train our model. This approach allows us to have more control over the model's architecture and potentially achieve better performance. However, it requires more manual design and experimentation compared to using a pre-trained model like ResNet18.\n",
    "\n",
    "It is important to note that the choice of architecture depends on the specific problem and dataset. It is recommended to experiment with different architectures and hyperparameters to find the best model for your task.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image batch dimensions: torch.Size([64, 3, 96, 96])\n",
      "Image label dimensions: torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "# Step 1: Data Loading and Preprocessing\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(96),   # Randomly resize and crop the image\n",
    "    transforms.RandomHorizontalFlip(),  # Randomly flip the image horizontally\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),  # Adjust color\n",
    "    transforms.RandomRotation(30),       # Randomly rotate the image\n",
    "    transforms.ToTensor(),               # Convert the image to a PyTorch tensor\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Normalize the image\n",
    "])\n",
    "\n",
    "# Define data transformations for validation (you can modify these based on your needs)\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize(96),\n",
    "    transforms.CenterCrop(96),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "# Load your dataset (adjust this based on your dataset structure)\n",
    "train_dataset = ImageFolder(root='train', transform=train_transform)\n",
    "val_dataset = ImageFolder(root='test', transform=val_transform)\n",
    "\n",
    "num_workers = 2\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=num_workers)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "# Print shapes of one batch of training and validation data\n",
    "for images, labels in train_loader:\n",
    "    print('Image batch dimensions:', images.shape)\n",
    "    print('Image label dimensions:', labels.shape)\n",
    "    break\n",
    "\n",
    "# Get Input Shape from train_loader\n",
    "input_shape = next(iter(train_loader))[0].shape\n",
    "print('Input Shape:', input_shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "    def __init__(self, n_frames, n_actions, h_dimension):\n",
    "        super(DQN, self).__init__()\n",
    "\n",
    "        # CNN\n",
    "        self.layers_cnn = nn.Sequential(\n",
    "            nn.Conv2d(n_frames, 6, kernel_size=(7, 7), stride=3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2, 2)),\n",
    "            nn.Conv2d(6, 12, kernel_size=(4, 4)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2, 2)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(432, h_dimension),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(h_dimension, n_actions)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        o = self.layers_cnn(x)  # (BS, ACTIONS)\n",
    "        return o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from collections import deque\n",
    "import numpy as np\n",
    "\n",
    "class DQNAgent:\n",
    "    def __init__(self,\n",
    "                 action_space,\n",
    "                 epsilon=1.0,\n",
    "                 gamma=0.95,\n",
    "                 epsilon_min=0.1,\n",
    "                 epsilon_decay=0.9999,\n",
    "                 lr=1e-3,\n",
    "                 memory_len=5000,\n",
    "                 frames=3,\n",
    "                 hidden_dimension=None,\n",
    "                 device=None):\n",
    "\n",
    "        self.device = device\n",
    "        self.epsilon = epsilon\n",
    "        self.gamma = gamma\n",
    "        self.epsilon_min = epsilon_min\n",
    "        self.epsilon_decay = epsilon_decay\n",
    "        self.memory_len = memory_len\n",
    "        self.lr = lr\n",
    "        self.memory = deque(maxlen=self.memory_len)\n",
    "        self.action_space = action_space\n",
    "\n",
    "        self.target_model = DQN(frames, len(self.action_space), hidden_dimension).to(self.device)\n",
    "        self.model =        DQN(frames, len(self.action_space), hidden_dimension).to(self.device)\n",
    "\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=self.lr)\n",
    "\n",
    "    def update_target_model(self):\n",
    "        self.target_model.load_state_dict(self.model.state_dict())\n",
    "\n",
    "    def is_explore(self):\n",
    "        flip = np.random.rand() <= self.epsilon\n",
    "        return flip\n",
    "\n",
    "    def act(self, state, is_only_random=False, is_only_exploit=False):\n",
    "        if not is_only_exploit and self.is_explore() or is_only_random:\n",
    "            action_index = np.random.randint(len(self.action_space))\n",
    "            # print(action_index, self.ACTION_SPACE[action_index])\n",
    "        else:\n",
    "            q_values = self.target_model(state)[0]\n",
    "            action_index = torch.argmax(q_values)\n",
    "            # print(\"predicted action\", action_index)\n",
    "        return self.action_space[action_index]\n",
    "\n",
    "    def memorize(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, self.action_space.index(action), reward, next_state, done))\n",
    "\n",
    "    def replay(self, batch_size):\n",
    "        minibatch = random.sample(self.memory, batch_size)\n",
    "        train_state = []\n",
    "        train_target = []\n",
    "\n",
    "        for state, action_index, reward, next_state, done in minibatch:\n",
    "            # state = torch.Tensor(state)\n",
    "            target = self.model(state)[0]\n",
    "            train_state.append(target)\n",
    "\n",
    "            target_copy = target.detach().clone().to(self.device)\n",
    "            if done:\n",
    "                target_copy[action_index] = reward\n",
    "            else:\n",
    "                t = self.target_model(next_state)[0]\n",
    "                target_copy[action_index] = reward + self.gamma * torch.max(t)\n",
    "            train_target.append(target_copy)\n",
    "\n",
    "        # Actual training\n",
    "        criterion = nn.MSELoss()\n",
    "        pred, tru = torch.stack(train_state), torch.stack(train_target)\n",
    "        loss = criterion(pred, tru)\n",
    "\n",
    "        # Optimize the model\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "\n",
    "    def load_model(self, name):\n",
    "        self.model = torch.load(name)\n",
    "        self.target_model = torch.load(name)\n",
    "        self.model.eval()\n",
    "\n",
    "    def save_model(self, name):\n",
    "        torch.save(self.target_model, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "\n",
    "    SEED = 1\n",
    "\n",
    "    STARTING_EPISODE_TRAIN = 0\n",
    "    ENDING_EPISODE_TRAIN = STARTING_EPISODE_TRAIN + 1000\n",
    "\n",
    "    STARTING_EPISODE_TEST = ENDING_EPISODE_TRAIN + 1\n",
    "    ENDING_EPISODE_TEST = STARTING_EPISODE_TEST + 100\n",
    "\n",
    "    SKIP_FRAMES = 2\n",
    "    TRAINING_BATCH_SIZE = 64\n",
    "    UPDATE_TARGET_MODEL_FREQUENCY = 5\n",
    "    N_FRAMES = 3\n",
    "    HIDDEN_DIMENSION_FC = 150\n",
    "\n",
    "    GAS_WEIGHT = 1.3\n",
    "\n",
    "    ACTION_SPACE = [\n",
    "        (-1, 1, 0.2), (0, 1, 0.2), (1, 1, 0.2),  # .  Action Space Structure\n",
    "        (-1, 1, 0), (0, 1, 0), (1, 1, 0),        # (Steering Wheel, Gas, Break)\n",
    "        (-1, 0, 0.2), (0, 0, 0.2), (1, 0, 0.2),  # .  -1~1     0~1        0~1\n",
    "        (-1, 0, 0), (0, 0, 0), (1, 0, 0)\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "from datetime import datetime\n",
    "import cv2\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import json\n",
    "\n",
    "\n",
    "def write_json_to_file(data, file_path):\n",
    "    \"\"\"\n",
    "    Write JSON data to a file.\n",
    "\n",
    "    Parameters:\n",
    "    - data: A dictionary representing the JSON data.\n",
    "    - file_path: The path where the JSON file will be written.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'w') as json_file:\n",
    "            json.dump(data, json_file, indent=4)\n",
    "        print(f\"JSON data successfully written to {file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error writing JSON data to {file_path}: {e}\")\n",
    "\n",
    "\n",
    "def read_json_from_file(file_path):\n",
    "    \"\"\"\n",
    "    Read JSON data from a file.\n",
    "\n",
    "    Parameters:\n",
    "    - file_path: The path of the JSON file to be read.\n",
    "\n",
    "    Returns:\n",
    "    - A dictionary representing the JSON data.\n",
    "    - If there is an error reading the file, returns None.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r') as json_file:\n",
    "            data = json.load(json_file)\n",
    "        print(f\"JSON data successfully read from {file_path}\")\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading JSON data from {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def make_all_paths(is_dynamic_root=True, dir_name=\"rl_class\"):\n",
    "    ROOT = \"data\"\n",
    "\n",
    "    if is_dynamic_root:\n",
    "        date_str = datetime.now().strftime(\"%m-%d-%Y_%H-%M-%S\")\n",
    "        dir_name = \"rl_class_{}\".format(date_str)\n",
    "    else:\n",
    "        dir_name = dir_name\n",
    "\n",
    "    path_root = ROOT + \"/\" + dir_name + \"/\"\n",
    "    dirs = [\"models\", \"plots\", \"videos\"]\n",
    "    for d in dirs:\n",
    "        path = path_root + d\n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path)\n",
    "        print(\">> Created dir\", path)\n",
    "    return path_root\n",
    "\n",
    "\n",
    "def plot_state_car(data, title=None):\n",
    "    assert len(data.shape) == 3, \"Can only handle 3D mats.\"\n",
    "    assert data.shape[0] < 10, \"Too many states to plot. Adjust the plots position first.\"\n",
    "\n",
    "    # Create a figure with three subplots\n",
    "    fig, axs = plt.subplots(1, data.shape[0], figsize=(10, 4))\n",
    "\n",
    "    # Plot each image using imshow()\n",
    "    for i in range(data.shape[0]):\n",
    "        axs[i].imshow(data[i], cmap='gray')  # You can adjust the colormap if needed\n",
    "        axs[i].axis('off')                   # Turn off axis labels\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_frame_car(data, title=None):\n",
    "    plt.imshow(data, cmap=\"gray\")  # You can adjust the colormap if needed\n",
    "    plt.axis('off')  # Turn off axis labels\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def preprocess_frame_car(frame):\n",
    "    def crop(frame):\n",
    "        # Crop to 84x84\n",
    "        return frame[:-12, 6:-6]\n",
    "\n",
    "    def make_img_gray(frame):\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        return frame\n",
    "\n",
    "    def normalize(frame):\n",
    "        return frame / 255.0\n",
    "\n",
    "    # frame = crop(frame)\n",
    "    frame = make_img_gray(frame)\n",
    "    frame = frame.astype(float)\n",
    "    frame = normalize(frame)\n",
    "    # frame = frame * 2 - 1   # maps [0,1] to [-1,1]\n",
    "    return frame\n",
    "\n",
    "\n",
    "def seed_everything(seed=42):\n",
    "    # Set seed for Python random module\n",
    "    random.seed(seed)\n",
    "\n",
    "    # Set seed for NumPy\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # Set seed for PyTorch\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False  # disable if deterministic mode is desired\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#import cv2   # open cv\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "import gymnasium as gym\n",
    "from collections import deque\n",
    "import numpy as np\n",
    "from gymnasium.wrappers import RecordVideo\n",
    "\n",
    "\n",
    "def train_car_racing():\n",
    "    seed_everything(seed=Config.SEED)\n",
    "    PATH_ROOT = make_all_paths(is_dynamic_root=True)\n",
    "    write_json_to_file(dict(Config.__dict__), file_path=PATH_ROOT + \"config.json\")\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print('>> Using device:', device)\n",
    "\n",
    "    agent = DQNAgent(frames=Config.N_FRAMES, action_space=Config.ACTION_SPACE, device=device,\n",
    "                     hidden_dimension=Config.HIDDEN_DIMENSION_FC)\n",
    "\n",
    "    # https://www.gymlibrary.dev/environments/box2d/car_racing/\n",
    "    env = gym.make('CarRacing-v2', render_mode=\"rgb_array\")  # , render_mode='human')\n",
    "    env = RecordVideo(env, PATH_ROOT + 'videos', episode_trigger=lambda x: x % Config.UPDATE_TARGET_MODEL_FREQUENCY == 0)\n",
    "\n",
    "    epi_total_rewards = []\n",
    "    for e in range(Config.STARTING_EPISODE_TRAIN, Config.ENDING_EPISODE_TRAIN + 1):\n",
    "        env.episode_id = e\n",
    "\n",
    "        epi_total_reward = 0\n",
    "        epi_negative_reward_counter = 0\n",
    "        epi_time_frame_counter = 1\n",
    "        epi_done = False\n",
    "\n",
    "        init_state = env.reset(seed=e)[0]  # 96, 96, 3 pixels image RGB\n",
    "        init_state = preprocess_frame_car(init_state)  # 96, 96 pixels image GRAY\n",
    "\n",
    "        # (1) EVALUATE STATE: S\n",
    "        state_queue = deque([init_state] * Config.N_FRAMES, maxlen=Config.N_FRAMES)\n",
    "        # plot_state_car(np.array(state_queue))  # visualize S0\n",
    "\n",
    "        while True:\n",
    "            state_tensor = torch.Tensor(np.array(state_queue)).unsqueeze(0).to(device)\n",
    "            action = agent.act(state_tensor)\n",
    "\n",
    "            # (2) EXECUTE ACTION (for several steps)\n",
    "            # (3) EVALUATE S' STATE, REWARD\n",
    "            reward = 0\n",
    "            for _ in range(Config.SKIP_FRAMES):\n",
    "                # execute action\n",
    "                next_state, r, epi_done, _, _ = env.step(action)\n",
    "                # plot_frame_car(next_state)\n",
    "                reward += r\n",
    "                if epi_done:\n",
    "                    break\n",
    "\n",
    "            # (4) ADJUST REWARD\n",
    "            # if getting negative reward 10 times after the tolerance steps, terminate this episode\n",
    "            if epi_time_frame_counter > 100 and reward < 0:\n",
    "                epi_negative_reward_counter += 1\n",
    "            else:\n",
    "                epi_negative_reward_counter = 0\n",
    "\n",
    "            # extra bonus for the model if it uses full gas\n",
    "            if action[1] == 1 and action[2] == 0:\n",
    "                reward *= Config.GAS_WEIGHT\n",
    "\n",
    "            epi_total_reward += reward\n",
    "\n",
    "            # plot_state_car(np.array(state_queue), title=\"STATE 0\")\n",
    "            # process state S'\n",
    "            next_state = preprocess_frame_car(next_state)\n",
    "            next_state_queue = deque([frame for frame in state_queue], maxlen=Config.N_FRAMES)\n",
    "            next_state_queue.append(next_state)\n",
    "            # plot_state_car(np.array(next_state_queue), title=\"STATE 1\")\n",
    "\n",
    "            next_state_tensor = torch.Tensor(np.array(next_state_queue)).unsqueeze(0).to(device)\n",
    "\n",
    "            # (5) STORE OBSERVATIONS\n",
    "            # Memorizing saving state, action reward tuples\n",
    "            agent.memorize(state_tensor, action, reward, next_state_tensor, epi_done)\n",
    "\n",
    "            # S = S'\n",
    "            state_queue = next_state_queue\n",
    "\n",
    "            # early stop if the number of\n",
    "            if epi_negative_reward_counter >= 25 or epi_total_reward < 0:\n",
    "                break\n",
    "\n",
    "            # (6) TRAIN ON BATCHES OF OBSERVATIONS\n",
    "            # train the model with tuple, if there are enough tuples\n",
    "            if len(agent.memory) > Config.TRAINING_BATCH_SIZE:\n",
    "                agent.replay(Config.TRAINING_BATCH_SIZE)\n",
    "\n",
    "            epi_time_frame_counter += 1\n",
    "        epi_total_rewards += [epi_total_reward]\n",
    "\n",
    "        # >>> ON EPISODE END\n",
    "        # print stats\n",
    "        stats_string = 'Episode: {}/{}, Scores(Time Frames): {}, Total Rewards: {:.2}, Epsilon: {:.2}'\n",
    "        print(stats_string.format(\n",
    "            e,\n",
    "            Config.ENDING_EPISODE_TRAIN,\n",
    "            epi_time_frame_counter,\n",
    "            float(epi_total_reward),\n",
    "            float(agent.epsilon))\n",
    "        )\n",
    "\n",
    "        if e % Config.UPDATE_TARGET_MODEL_FREQUENCY == 0:\n",
    "            # plot rewards stats\n",
    "            plt.plot(epi_total_rewards, label=\"cum rew\", color=\"blue\")\n",
    "            plt.title(\"Rewards during episode episode\")\n",
    "            plt.savefig(PATH_ROOT + 'plots/reward_{}.pdf'.format(e))\n",
    "\n",
    "            # save model frequently\n",
    "            agent.save_model(PATH_ROOT + 'models/trial_{}.h5'.format(e))\n",
    "\n",
    "            # swap model\n",
    "            agent.update_target_model()\n",
    "            write_json_to_file({\"CUM_REW\": epi_total_rewards}, PATH_ROOT + \"/stats.json\")\n",
    "\n",
    "    env.close()\n",
    "\n",
    "\n",
    "#train_car_racing()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second Approach ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, input_shape, num_classes):\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Conv2d(3, 15, kernel_size=(5, 5)),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(15, 20, kernel_size=(5, 5)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2, 2)),\n",
    "            nn.Conv2d(20, 30, kernel_size=(3, 3)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2, 2)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(30 * ((input_shape[0] - 12) // 4) * ((input_shape[1] - 12) // 4), 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(128, 96),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(96, num_classes),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\andri\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\andri\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Import ResNet18 model\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "# Load pre-trained ResNet18 model and extract features\n",
    "resnet_model = resnet18(pretrained=True)\n",
    "resnet_features = nn.Sequential(*list(resnet_model.children())[:-1])\n",
    "\n",
    "# Create your model instance\n",
    "model = CNN(resnet_features)\n",
    "\n",
    "# Example forward pass\n",
    "image_batch = torch.randn(64, 3, 96, 96)  # Example image batch\n",
    "label_batch = torch.randint(5, (64,))  # Example label batch\n",
    "output = model(image_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Use GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "criterion.to(device)\n",
    "\n",
    "# Optimizer and Scheduler\n",
    "optimizer = optim.RMSprop(model.parameters(), lr=0.0001)\n",
    "scheduler = StepLR(optimizer, step_size=5, gamma=0.1)  # Optional learning rate scheduler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Loss: 1.5102678549289703\n",
      "Epoch 2/50, Loss: 1.4958185875415801\n",
      "Epoch 3/50, Loss: 1.4893801987171174\n",
      "Epoch 4/50, Loss: 1.4854220819473267\n",
      "Epoch 5/50, Loss: 1.4866083586215972\n",
      "Epoch 6/50, Loss: 1.4780626440048217\n",
      "Epoch 7/50, Loss: 1.4749259889125823\n",
      "Epoch 8/50, Loss: 1.4737242865562439\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Step 3: Training loop\n",
    "num_epochs = 50\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, labels in train_loader:  # Assuming you have a DataLoader for your training set\n",
    "        optimizer.zero_grad()  # Zero the gradients\n",
    "        outputs = model(images)  # Forward pass\n",
    "        loss = criterion(outputs, labels)  # Compute the loss\n",
    "        loss.backward()  # Backward pass\n",
    "        optimizer.step()  # Update weights\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # Print the average loss for the epoch\n",
    "    average_loss = running_loss / len(train_loader)\n",
    "    print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {average_loss}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6569661695161877\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# After training, you can evaluate the model on your validation set\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:  # Assuming you have a DataLoader for your validation set\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = correct / total\n",
    "print(f'Validation Accuracy: {accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'MyCNN.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6711531465987632\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 5: Model Evaluation\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in val_loader:\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = correct / total\n",
    "print(f'Validation Accuracy: {accuracy}')\n",
    "\n",
    "\n",
    "# Repeat steps 2-5 with a different architecture for Approach B\n",
    "# ...\n",
    "\n",
    "# Provide analysis and comments\n",
    "# ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
