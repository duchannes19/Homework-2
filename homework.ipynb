{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Homework 2**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Iteration ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Check if GPU is available\n",
    "print('GPU is', 'available' if tf.config.list_physical_devices('GPU') else 'NOT AVAILABLE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Import Libraries\n",
    "import numpy as np\n",
    "import sys\n",
    "import gymnasium as gym\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import (\n",
    "    Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D, BatchNormalization\n",
    ")\n",
    "from tensorflow.keras import optimizers, callbacks\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from gymnasium.wrappers import RecordVideo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6369 images belonging to 5 classes.\n",
      "Found 2749 images belonging to 5 classes.\n",
      "Image height = 96, Image Width = 96, Channels = 3\n",
      "Image input shape: (96, 96, 3)\n",
      "Classes: ['0', '1', '2', '3', '4']\n",
      "Loaded 6369 training samples from 5 classes.\n",
      "Loaded 2749 validation samples from 5 classes.\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Data Preparation\n",
    "# Define the paths to your training and validation data\n",
    "trainingset = 'train/'\n",
    "validationset = 'test/'\n",
    "\n",
    "batch_size = 64\n",
    "target_size = (96, 96)  # Adjust based on your dataset\n",
    "\n",
    "# Training data augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0 / 255,\n",
    "    zoom_range=0.1,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=False,\n",
    "    rotation_range=20,\n",
    "    shear_range=0.1,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Validation data should not be augmented\n",
    "validation_datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
    "\n",
    "# Create generators\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    directory=trainingset,\n",
    "    target_size=target_size,\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    directory=validationset,\n",
    "    target_size=target_size,\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Gather dataset information\n",
    "num_samples = train_generator.n\n",
    "num_classes = train_generator.num_classes\n",
    "input_shape = train_generator.image_shape\n",
    "\n",
    "classnames = list(train_generator.class_indices.keys())\n",
    "img_h, img_w, img_channels = input_shape\n",
    "print(f\"Image height = {img_h}, Image Width = {img_w}, Channels = {img_channels}\")\n",
    "print(f\"Image input shape: {input_shape}\")\n",
    "print(f\"Classes: {classnames}\")\n",
    "print(f\"Loaded {num_samples} training samples from {num_classes} classes.\")\n",
    "print(f\"Loaded {validation_generator.n} validation samples from {validation_generator.num_classes} classes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cell X: Analyze Class Distribution\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Count of samples per class\n",
    "class_counts = train_generator.classes\n",
    "class_names = list(train_generator.class_indices.keys())\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.bar(class_names, [np.sum(class_counts == i) for i in range(len(class_names))], color='skyblue')\n",
    "plt.xlabel('Classes')\n",
    "plt.ylabel('Number of Samples')\n",
    "plt.title('Class Distribution in Training Set')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1000 images belonging to 1 classes.\n",
      "Found 369 images belonging to 1 classes.\n",
      "Number of augmented generators: 2\n"
     ]
    }
   ],
   "source": [
    "# Cell 12: Create Separate Generators for Minority Classes\n",
    "import os\n",
    "\n",
    "# Define the target size and batch size\n",
    "target_size = (96, 96)\n",
    "batch_size = 64\n",
    "\n",
    "# Initialize data augmentation for minority classes\n",
    "minority_datagen = ImageDataGenerator(\n",
    "    rescale=1.0 / 255,\n",
    "    zoom_range=0.2,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    rotation_range=30,\n",
    "    shear_range=0.2,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Paths to minority class directories\n",
    "minority_classes = ['0', '4']\n",
    "train_dir = 'train/'\n",
    "\n",
    "augmented_generators = []\n",
    "\n",
    "for cls in minority_classes:\n",
    "    class_dir = os.path.join(train_dir, cls)\n",
    "    if not os.path.isdir(class_dir):\n",
    "        print(f\"Directory for class {cls} not found. Skipping augmentation.\")\n",
    "        continue\n",
    "    generator = minority_datagen.flow_from_directory(\n",
    "        directory=train_dir,\n",
    "        target_size=target_size,\n",
    "        color_mode=\"rgb\",\n",
    "        batch_size=batch_size,\n",
    "        class_mode=\"categorical\",\n",
    "        classes=[cls],  # Only target the minority class\n",
    "        shuffle=True\n",
    "    )\n",
    "    augmented_generators.append(generator)\n",
    "\n",
    "print(f\"Number of augmented generators: {len(augmented_generators)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Weights: {0: 1.2738, 1: 0.8492, 2: 0.8492, 3: 0.6369, 4: 3.4520325203252034}\n"
     ]
    }
   ],
   "source": [
    "# Cell Y: Compute Class Weights\n",
    "from sklearn.utils import class_weight\n",
    "import numpy as np\n",
    "\n",
    "# Compute class weights\n",
    "class_weights = class_weight.compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(train_generator.classes),\n",
    "    y=train_generator.classes\n",
    ")\n",
    "\n",
    "# Convert to a dictionary\n",
    "class_weights_dict = {i: weight for i, weight in enumerate(class_weights)}\n",
    "print(\"Class Weights:\", class_weights_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 13: Combine Original and Augmented Generators\n",
    "import itertools\n",
    "\n",
    "# Create a combined generator\n",
    "train_combined = itertools.chain(\n",
    "    train_generator,\n",
    "    *augmented_generators\n",
    ")\n",
    "\n",
    "# Define a generator that yields data from the combined generator\n",
    "def combined_generator(combined):\n",
    "    for data in combined:\n",
    "        yield data\n",
    "\n",
    "# Reset the iterator\n",
    "train_combined = combined_generator(train_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"DeepCNN\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 96, 96, 32)        896       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 96, 96, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 48, 48, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 48, 48, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 48, 48, 64)        18496     \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 48, 48, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 24, 24, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 24, 24, 64)        0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 24, 24, 128)       73856     \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 24, 24, 128)       147584    \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 12, 12, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 12, 12, 128)       0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 18432)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               9437696   \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 5)                 2565      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,727,269\n",
      "Trainable params: 9,727,269\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Deeper CNN with Different Activation\n",
    "def DeepCNN(input_shape, num_classes):\n",
    "    model = Sequential(name=\"DeepCNN\")\n",
    "\n",
    "    # First Convolutional Block\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=input_shape))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    # Second Convolutional Block\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    # Third Convolutional Block\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    # Flatten and Dense Layers\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    # Output Layer\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    # Compile the model with RMSprop optimizer\n",
    "    optimizer = optimizers.RMSprop(learning_rate=0.001)\n",
    "\n",
    "    model.compile(\n",
    "        loss='categorical_crossentropy',\n",
    "        optimizer=optimizer,\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# Instantiate and summarize the model\n",
    "model_deep = DeepCNN(input_shape, num_classes)\n",
    "model_deep.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"ImprovedDeepCNN\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_6 (Conv2D)           (None, 96, 96, 32)        896       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 96, 96, 32)       128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " leaky_re_lu (LeakyReLU)     (None, 96, 96, 32)        0         \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 96, 96, 32)        9248      \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 96, 96, 32)       128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 96, 96, 32)        0         \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 48, 48, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 48, 48, 32)        0         \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 48, 48, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 48, 48, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_2 (LeakyReLU)   (None, 48, 48, 64)        0         \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 48, 48, 64)        36928     \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 48, 48, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_3 (LeakyReLU)   (None, 48, 48, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 24, 24, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 24, 24, 64)        0         \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 24, 24, 128)       73856     \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 24, 24, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_4 (LeakyReLU)   (None, 24, 24, 128)       0         \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 24, 24, 128)       147584    \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 24, 24, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_5 (LeakyReLU)   (None, 24, 24, 128)       0         \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 12, 12, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 12, 12, 128)       0         \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 128)              0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 512)               66048     \n",
      "                                                                 \n",
      " leaky_re_lu_6 (LeakyReLU)   (None, 512)               0         \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 5)                 2565      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 357,413\n",
      "Trainable params: 356,517\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers, regularizers\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "\n",
    "def ImprovedDeepCNN(input_shape, num_classes):\n",
    "    model = models.Sequential(name=\"ImprovedDeepCNN\")\n",
    "    \n",
    "    # First Convolutional Block\n",
    "    model.add(layers.Conv2D(32, (3, 3), padding='same', input_shape=input_shape))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(layers.Conv2D(32, (3, 3), padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    \n",
    "    # Second Convolutional Block\n",
    "    model.add(layers.Conv2D(64, (3, 3), padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(layers.Conv2D(64, (3, 3), padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    \n",
    "    # Third Convolutional Block\n",
    "    model.add(layers.Conv2D(128, (3, 3), padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(layers.Conv2D(128, (3, 3), padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Dropout(0.4))\n",
    "    \n",
    "    # Global Average Pooling and Dense Layers\n",
    "    model.add(layers.GlobalAveragePooling2D())\n",
    "    model.add(layers.Dense(512, kernel_regularizer=regularizers.l2(0.001)))\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    \n",
    "    # Output Layer\n",
    "    model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    # Compile the model with Adam optimizer\n",
    "    optimizer = optimizers.Adam(learning_rate=0.0001)\n",
    "    \n",
    "    model.compile(\n",
    "        loss='categorical_crossentropy',\n",
    "        optimizer=optimizer,\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# Instantiate and summarize the improved model\n",
    "model_improved = ImprovedDeepCNN(input_shape, num_classes)\n",
    "model_improved.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Select Model\n",
    "# Choose one of the models defined above\n",
    "model = model_improved  # Replace with model_deep or model_improved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Define Callbacks\n",
    "early_stopping = callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,  # Increased patience for potentially longer training\n",
    "    verbose=1,\n",
    "    mode='auto',\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "reduce_lr = callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.2,\n",
    "    patience=3,  # Increased patience\n",
    "    verbose=1,\n",
    "    min_lr=1e-6\n",
    ")\n",
    "\n",
    "# Optionally, add ModelCheckpoint to save the best model\n",
    "checkpoint = callbacks.ModelCheckpoint(\n",
    "    'models/best_model.keras',\n",
    "    monitor='val_accuracy',\n",
    "    save_best_only=True,\n",
    "    mode='max'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "100/100 [==============================] - 15s 139ms/step - loss: 1.8600 - accuracy: 0.2233 - val_loss: 1.7217 - val_accuracy: 0.6897 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 12s 125ms/step - loss: 1.8071 - accuracy: 0.2751 - val_loss: 1.5859 - val_accuracy: 0.6897 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 13s 127ms/step - loss: 1.7733 - accuracy: 0.3085 - val_loss: 1.5594 - val_accuracy: 0.6897 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 13s 126ms/step - loss: 1.7805 - accuracy: 0.3135 - val_loss: 1.5363 - val_accuracy: 0.6890 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 12s 125ms/step - loss: 1.7460 - accuracy: 0.3537 - val_loss: 1.5765 - val_accuracy: 0.5882 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 13s 128ms/step - loss: 1.7442 - accuracy: 0.3632 - val_loss: 1.5315 - val_accuracy: 0.5860 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 12s 125ms/step - loss: 1.7161 - accuracy: 0.3658 - val_loss: 1.5507 - val_accuracy: 0.6079 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 13s 126ms/step - loss: 1.7383 - accuracy: 0.3709 - val_loss: 1.5072 - val_accuracy: 0.6020 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 13s 127ms/step - loss: 1.7180 - accuracy: 0.3793 - val_loss: 1.5421 - val_accuracy: 0.6046 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 13s 126ms/step - loss: 1.7234 - accuracy: 0.3778 - val_loss: 1.4475 - val_accuracy: 0.6184 - lr: 1.0000e-04\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 13s 128ms/step - loss: 1.6946 - accuracy: 0.3932 - val_loss: 1.6022 - val_accuracy: 0.5664 - lr: 1.0000e-04\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 13s 127ms/step - loss: 1.7140 - accuracy: 0.3842 - val_loss: 1.5314 - val_accuracy: 0.6220 - lr: 1.0000e-04\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.6794 - accuracy: 0.3979\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n",
      "100/100 [==============================] - 13s 130ms/step - loss: 1.6794 - accuracy: 0.3979 - val_loss: 1.6655 - val_accuracy: 0.3550 - lr: 1.0000e-04\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 13s 129ms/step - loss: 1.6927 - accuracy: 0.3932 - val_loss: 1.6422 - val_accuracy: 0.3652 - lr: 2.0000e-05\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 13s 131ms/step - loss: 1.6739 - accuracy: 0.3936 - val_loss: 1.5829 - val_accuracy: 0.5336 - lr: 2.0000e-05\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.6784 - accuracy: 0.4120\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 3.999999898951501e-06.\n",
      "100/100 [==============================] - 13s 128ms/step - loss: 1.6784 - accuracy: 0.4120 - val_loss: 1.6499 - val_accuracy: 0.4431 - lr: 2.0000e-05\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 13s 127ms/step - loss: 1.6867 - accuracy: 0.4114 - val_loss: 1.6366 - val_accuracy: 0.4325 - lr: 4.0000e-06\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 13s 130ms/step - loss: 1.6884 - accuracy: 0.4035 - val_loss: 1.6235 - val_accuracy: 0.4456 - lr: 4.0000e-06\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.6692 - accuracy: 0.4109\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "100/100 [==============================] - 13s 129ms/step - loss: 1.6692 - accuracy: 0.4109 - val_loss: 1.6317 - val_accuracy: 0.4511 - lr: 4.0000e-06\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.6681 - accuracy: 0.4128Restoring model weights from the end of the best epoch: 10.\n",
      "100/100 [==============================] - 13s 129ms/step - loss: 1.6681 - accuracy: 0.4128 - val_loss: 1.6264 - val_accuracy: 0.4565 - lr: 1.0000e-06\n",
      "Epoch 20: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Cell 9: Train the Model\n",
    "# Calculate steps per epoch and validation steps\n",
    "steps_per_epoch = int(np.ceil(train_generator.n / batch_size))\n",
    "val_steps = int(np.ceil(validation_generator.n / batch_size))\n",
    "\n",
    "try:\n",
    "    history = model.fit(\n",
    "        train_combined,\n",
    "        epochs=100,\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=val_steps,\n",
    "        callbacks=[early_stopping, reduce_lr, checkpoint],\n",
    "        class_weight=class_weights_dict,\n",
    "        verbose=1\n",
    "    )\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Training interrupted.\")\n",
    "\n",
    "# Save the final model based if you chose deep or improved model\n",
    "if model == model_deep:\n",
    "    model.save('models/final_model_deep.keras')\n",
    "else:\n",
    "    model.save('models/final_model_improved.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 2s 31ms/step - loss: 1.3432 - accuracy: 0.6904\n",
      "Validation Accuracy: 0.6904\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, Average\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model_deep = load_model('models/final_model_deep.keras')\n",
    "model_improved = load_model('models/final_model_improved.keras')\n",
    "\n",
    "input_shape_deep = model_deep.input_shape[1:]  # Exclude batch size\n",
    "input_shape_improved = model_improved.input_shape[1:]\n",
    "\n",
    "assert input_shape_deep == input_shape_improved, \"Input shapes of both models must be the same.\"\n",
    "\n",
    "# Create an input layer that matches the input shape\n",
    "input_layer = Input(shape=input_shape_deep)\n",
    "\n",
    "# Get predictions from both models\n",
    "preds_deep = model_deep(input_layer)\n",
    "preds_improved = model_improved(input_layer)\n",
    "\n",
    "# Average the outputs\n",
    "averaged_preds = Average()([preds_deep, preds_improved])\n",
    "\n",
    "# Create the combined model\n",
    "combined_model = Model(inputs=input_layer, outputs=averaged_preds)\n",
    "\n",
    "# Compile the combined model\n",
    "combined_model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=optimizers.Adam(learning_rate=0.0001),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Save the combined model\n",
    "combined_model.save('models/combined_model.keras')\n",
    "\n",
    "# Cell 11: Evaluate the Model\n",
    "# Load the combined model\n",
    "combined_model = load_model('models/combined_model.keras')\n",
    "\n",
    "# Evaluate the model on the validation set\n",
    "val_loss, val_acc = combined_model.evaluate(validation_generator, verbose=1)\n",
    "print(f\"Validation Accuracy: {val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 2s 31ms/step - loss: 1.3432 - accuracy: 0.6904\n",
      "Loss: 1.3432\n",
      "Accuracy: 0.6904\n"
     ]
    }
   ],
   "source": [
    "# Cell 10: Evaluate the Model\n",
    "# Load the best saved model\n",
    "best_model = load_model('models/combined_model.keras')\n",
    "\n",
    "# Evaluate on validation data\n",
    "val_steps = int(np.ceil(validation_generator.n / batch_size))\n",
    "loss, acc = best_model.evaluate(validation_generator, steps=val_steps, verbose=1)\n",
    "print(f'Loss: {loss:.4f}')\n",
    "print(f'Accuracy: {acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.286     0.165     0.210       133\n",
      "           1      0.442     0.404     0.422       275\n",
      "           2      0.516     0.490     0.503       406\n",
      "           3      0.809     0.822     0.815      1896\n",
      "           4      0.073     0.205     0.107        39\n",
      "\n",
      "    accuracy                          0.690      2749\n",
      "   macro avg      0.425     0.417     0.411      2749\n",
      "weighted avg      0.693     0.690     0.691      2749\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cell 11: Classification Report\n",
    "preds = best_model.predict(validation_generator, steps=val_steps, verbose=0)\n",
    "Ypred = np.argmax(preds, axis=1)\n",
    "Ytest = validation_generator.classes  # Ensure shuffle=False in validation_generator\n",
    "\n",
    "print(classification_report(Ytest, Ypred, target_names=classnames, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cell 12: Confusion Matrix\n",
    "cm = confusion_matrix(Ytest, Ypred)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', xticklabels=classnames, yticklabels=classnames, cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True             Predicted        Errors     Error %   \n",
      "------------------------------------------------------------\n",
      "3                -> 2                162        5.89%\n",
      "1                -> 3                137        4.98%\n",
      "2                -> 3                131        4.77%\n",
      "3                -> 1                112        4.07%\n",
      "0                -> 3                75         2.73%\n",
      "2                -> 4                45         1.64%\n",
      "3                -> 4                41         1.49%\n",
      "2                -> 0                27         0.98%\n",
      "4                -> 3                24         0.87%\n",
      "3                -> 0                23         0.84%\n",
      "0                -> 1                23         0.84%\n",
      "1                -> 2                13         0.47%\n",
      "1                -> 4                10         0.36%\n",
      "0                -> 2                7          0.25%\n",
      "0                -> 4                6          0.22%\n",
      "4                -> 2                5          0.18%\n",
      "1                -> 0                4          0.15%\n",
      "2                -> 1                4          0.15%\n",
      "4                -> 0                1          0.04%\n",
      "4                -> 1                1          0.04%\n"
     ]
    }
   ],
   "source": [
    "# Cell 13: Text-Based Confusion Matrix\n",
    "conf = []\n",
    "for i in range(cm.shape[0]):\n",
    "    for j in range(cm.shape[1]):\n",
    "        if i != j and cm[i][j] > 0:\n",
    "            conf.append([i, j, cm[i][j]])\n",
    "\n",
    "conf = np.array(conf)\n",
    "conf = conf[np.argsort(-conf[:, 2])]  # Sort by descending error count\n",
    "\n",
    "print(f'{\"True\":<16} {\"Predicted\":<16} {\"Errors\":<10} {\"Error %\":<10}')\n",
    "print('-' * 60)\n",
    "for k in conf:\n",
    "    true_class = classnames[int(k[0])]\n",
    "    pred_class = classnames[int(k[1])]\n",
    "    errors = int(k[2])\n",
    "    error_pct = (errors / validation_generator.n) * 100\n",
    "    print(f'{true_class:<16} -> {pred_class:<16} {errors:<10} {error_pct:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\andri\\miniconda3\\envs\\tf\\lib\\site-packages\\gymnasium\\wrappers\\rendering.py:283: UserWarning: \u001b[33mWARN: Overwriting existing videos at c:\\Users\\andri\\Documents\\GitHub\\Homework-2\\video_recordings folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment: CarRacing-v3\n",
      "Action space: Box([-1.  0.  0.], 1.0, (3,), float32)\n",
      "Observation space: Box(0, 255, (96, 96, 3), uint8)\n",
      "1/1 [==============================] - 1s 630ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n"
     ]
    }
   ],
   "source": [
    "# Cell 9: Model Deployment with Gymnasium (Final Revised for Continuous Actions)\n",
    "import numpy as np\n",
    "from gymnasium.wrappers import RecordVideo\n",
    "\n",
    "def play(env, model, predefined_actions):\n",
    "    seed = 2000\n",
    "    obs, _ = env.reset(seed=seed)\n",
    "\n",
    "    # Drop initial frames with no action\n",
    "    no_action = predefined_actions[0]  # [0.0, 0.0, 0.0]\n",
    "    for _ in range(50):\n",
    "        obs, _, _, _, _ = env.step(no_action)\n",
    "\n",
    "    done = False\n",
    "    while not done:\n",
    "        # Preprocess the observation\n",
    "        img = preprocess_observation(obs, target_size)\n",
    "        p = model.predict(np.expand_dims(img, axis=0))  # Shape: (1, 5)\n",
    "        predicted_class = np.argmax(p)  # Integer 0-4\n",
    "\n",
    "        # Map the predicted class to a predefined action\n",
    "        action = predefined_actions.get(predicted_class, predefined_actions[0])  # Array\n",
    "\n",
    "        # Ensure the action is a float32 NumPy array\n",
    "        action = action.astype(np.float32)\n",
    "\n",
    "        # Step the environment with the action\n",
    "        obs, _, terminated, truncated, _ = env.step(action)\n",
    "        done = terminated or truncated\n",
    "\n",
    "    env.close()\n",
    "\n",
    "def preprocess_observation(obs, target_size):\n",
    "    from tensorflow.keras.preprocessing.image import img_to_array, array_to_img\n",
    "\n",
    "    # Convert observation to PIL Image\n",
    "    img = array_to_img(obs)\n",
    "    # Resize image\n",
    "    img = img.resize(target_size)\n",
    "    # Convert to array and normalize\n",
    "    img = img_to_array(img) / 255.0\n",
    "    return img\n",
    "\n",
    "# Define predefined actions (Continuous)\n",
    "predefined_actions = {\n",
    "    0: np.array([0.0, 0.0, 0.0], dtype=np.float32),  # No Action\n",
    "    1: np.array([-1.0, 0.0, 0.0], dtype=np.float32), # Steer Left\n",
    "    2: np.array([1.0, 0.0, 0.0], dtype=np.float32),  # Steer Right\n",
    "    3: np.array([0.0, 1.0, 0.0], dtype=np.float32),  # Accelerate (Gas)\n",
    "    4: np.array([0.0, 0.0, 1.0], dtype=np.float32),  # Brake\n",
    "    # Add more actions as needed\n",
    "}\n",
    "\n",
    "# Initialize the environment without 'continuous' parameter\n",
    "env_arguments = {\n",
    "    'domain_randomize': False,\n",
    "    'render_mode': 'rgb_array'\n",
    "}\n",
    "\n",
    "env_name = 'CarRacing-v3'\n",
    "env = gym.make(env_name, **env_arguments)\n",
    "\n",
    "# Wrap the environment to record videos\n",
    "video_dir = 'video_recordings'  # Specify the directory to save video recordings\n",
    "env = RecordVideo(env, video_dir)\n",
    "\n",
    "print(\"Environment:\", env_name)\n",
    "print(\"Action space:\", env.action_space)\n",
    "print(\"Observation space:\", env.observation_space)\n",
    "\n",
    "# Play the game using the trained model\n",
    "play(env, best_model, predefined_actions)\n",
    "#play(env, best_model_regression, predefined_actions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (Optional Approach) Deep Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Shape: (84, 84, 4)\n",
      "Episode 1/1000 - Total Reward: 1099.00 - Epsilon: 0.9990\n",
      "Episode 2/1000 - Total Reward: 1099.00 - Epsilon: 0.9980\n",
      "Episode 3/1000 - Total Reward: 1099.00 - Epsilon: 0.9970\n",
      "Episode 4/1000 - Total Reward: 1099.00 - Epsilon: 0.9960\n",
      "Episode 5/1000 - Total Reward: 1099.00 - Epsilon: 0.9950\n",
      "Episode 6/1000 - Total Reward: 1099.00 - Epsilon: 0.9940\n",
      "Episode 7/1000 - Total Reward: 1099.00 - Epsilon: 0.9930\n",
      "Episode 8/1000 - Total Reward: 1099.00 - Epsilon: 0.9920\n",
      "Episode 9/1000 - Total Reward: 1099.00 - Epsilon: 0.9910\n",
      "Episode 10/1000 - Total Reward: 1099.00 - Epsilon: 0.9900\n",
      "Episode 11/1000 - Total Reward: 1099.00 - Epsilon: 0.9890\n",
      "Episode 12/1000 - Total Reward: 1099.00 - Epsilon: 0.9880\n",
      "Episode 13/1000 - Total Reward: 1099.00 - Epsilon: 0.9870\n",
      "Episode 14/1000 - Total Reward: 1099.00 - Epsilon: 0.9860\n",
      "Episode 15/1000 - Total Reward: 1099.00 - Epsilon: 0.9850\n",
      "Episode 16/1000 - Total Reward: 1099.00 - Epsilon: 0.9840\n",
      "Episode 17/1000 - Total Reward: 1099.00 - Epsilon: 0.9830\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 385\u001b[0m\n\u001b[0;32m    371\u001b[0m agent \u001b[38;5;241m=\u001b[39m DQNAgent(\n\u001b[0;32m    372\u001b[0m     input_shape\u001b[38;5;241m=\u001b[39minput_shape,\n\u001b[0;32m    373\u001b[0m     num_actions\u001b[38;5;241m=\u001b[39mnum_actions,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    381\u001b[0m     target_update_freq\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m\n\u001b[0;32m    382\u001b[0m )\n\u001b[0;32m    384\u001b[0m \u001b[38;5;66;03m# Train the Agent\u001b[39;00m\n\u001b[1;32m--> 385\u001b[0m \u001b[43mtrain_dqn\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43magent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_episodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_every\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdqn_final_model.h5\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    387\u001b[0m \u001b[38;5;66;03m# Evaluate the Trained Agent\u001b[39;00m\n\u001b[0;32m    388\u001b[0m evaluate_agent(env, agent, num_episodes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, max_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m)\n",
      "Cell \u001b[1;32mIn[5], line 311\u001b[0m, in \u001b[0;36mtrain_dqn\u001b[1;34m(env, agent, num_episodes, max_steps, save_every, save_path)\u001b[0m\n\u001b[0;32m    308\u001b[0m total_reward \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m reward\n\u001b[0;32m    310\u001b[0m agent\u001b[38;5;241m.\u001b[39mstore_experience(state, action, reward, next_state, done)\n\u001b[1;32m--> 311\u001b[0m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    313\u001b[0m state \u001b[38;5;241m=\u001b[39m next_state\n\u001b[0;32m    315\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m done:\n",
      "Cell \u001b[1;32mIn[5], line 259\u001b[0m, in \u001b[0;36mDQNAgent.train_step\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    256\u001b[0m states, actions, rewards, next_states, dones \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmap\u001b[39m(np\u001b[38;5;241m.\u001b[39marray, \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))\n\u001b[0;32m    258\u001b[0m \u001b[38;5;66;03m# Predict Q-values for next states using target network\u001b[39;00m\n\u001b[1;32m--> 259\u001b[0m target_q \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnext_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    260\u001b[0m max_target_q \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmax(target_q, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    262\u001b[0m \u001b[38;5;66;03m# Compute target values\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\andri\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\andri\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py:2220\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   2211\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[0;32m   2212\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   2213\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing Model.predict with MultiWorkerMirroredStrategy \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2214\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor TPUStrategy and AutoShardPolicy.FILE might lead to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2217\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m   2218\u001b[0m         )\n\u001b[1;32m-> 2220\u001b[0m data_handler \u001b[38;5;241m=\u001b[39m \u001b[43mdata_adapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_data_handler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2223\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2224\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2225\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2226\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2227\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2228\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2229\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2230\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_execution\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_steps_per_execution\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2231\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2233\u001b[0m \u001b[38;5;66;03m# Container that configures and calls `tf.keras.Callback`s.\u001b[39;00m\n\u001b[0;32m   2234\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(callbacks, callbacks_module\u001b[38;5;241m.\u001b[39mCallbackList):\n",
      "File \u001b[1;32mc:\\Users\\andri\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\data_adapter.py:1582\u001b[0m, in \u001b[0;36mget_data_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1580\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_cluster_coordinator\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1581\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _ClusterCoordinatorDataHandler(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m-> 1582\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DataHandler(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\andri\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\data_adapter.py:1262\u001b[0m, in \u001b[0;36mDataHandler.__init__\u001b[1;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute)\u001b[0m\n\u001b[0;32m   1259\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_steps_per_execution \u001b[38;5;241m=\u001b[39m steps_per_execution\n\u001b[0;32m   1261\u001b[0m adapter_cls \u001b[38;5;241m=\u001b[39m select_data_adapter(x, y)\n\u001b[1;32m-> 1262\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_adapter \u001b[38;5;241m=\u001b[39m \u001b[43madapter_cls\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1263\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1264\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1265\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1266\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1268\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1272\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdistribution_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistribute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_strategy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1274\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1277\u001b[0m strategy \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mget_strategy()\n\u001b[0;32m   1279\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\andri\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\data_adapter.py:349\u001b[0m, in \u001b[0;36mTensorLikeDataAdapter.__init__\u001b[1;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[0;32m    345\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m flat_dataset\n\u001b[0;32m    347\u001b[0m indices_dataset \u001b[38;5;241m=\u001b[39m indices_dataset\u001b[38;5;241m.\u001b[39mflat_map(slice_batch_indices)\n\u001b[1;32m--> 349\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mslice_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindices_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    351\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shuffle \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    353\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mshuffle_batch\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch):\n",
      "File \u001b[1;32mc:\\Users\\andri\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\data_adapter.py:390\u001b[0m, in \u001b[0;36mTensorLikeDataAdapter.slice_inputs\u001b[1;34m(self, indices_dataset, inputs)\u001b[0m\n\u001b[0;32m    385\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgrab_batch\u001b[39m(i, data):\n\u001b[0;32m    386\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mmap_structure(\n\u001b[0;32m    387\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m d: tf\u001b[38;5;241m.\u001b[39mgather(d, i, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m), data\n\u001b[0;32m    388\u001b[0m     )\n\u001b[1;32m--> 390\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrab_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_parallel_calls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAUTOTUNE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    392\u001b[0m \u001b[38;5;66;03m# Default optimizations are disabled to avoid the overhead of\u001b[39;00m\n\u001b[0;32m    393\u001b[0m \u001b[38;5;66;03m# (unnecessary) input pipeline graph serialization and deserialization\u001b[39;00m\n\u001b[0;32m    394\u001b[0m options \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mOptions()\n",
      "File \u001b[1;32mc:\\Users\\andri\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:2204\u001b[0m, in \u001b[0;36mDatasetV2.map\u001b[1;34m(self, map_func, num_parallel_calls, deterministic, name)\u001b[0m\n\u001b[0;32m   2202\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m MapDataset(\u001b[38;5;28mself\u001b[39m, map_func, preserve_cardinality\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, name\u001b[38;5;241m=\u001b[39mname)\n\u001b[0;32m   2203\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2204\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mParallelMapDataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2205\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2206\u001b[0m \u001b[43m      \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2207\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_parallel_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2208\u001b[0m \u001b[43m      \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2209\u001b[0m \u001b[43m      \u001b[49m\u001b[43mpreserve_cardinality\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   2210\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\andri\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:5456\u001b[0m, in \u001b[0;36mParallelMapDataset.__init__\u001b[1;34m(self, input_dataset, map_func, num_parallel_calls, deterministic, use_inter_op_parallelism, preserve_cardinality, use_legacy_function, name)\u001b[0m\n\u001b[0;32m   5453\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_parallel_calls \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mconvert_to_tensor(\n\u001b[0;32m   5454\u001b[0m     num_parallel_calls, dtype\u001b[38;5;241m=\u001b[39mdtypes\u001b[38;5;241m.\u001b[39mint64, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_parallel_calls\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   5455\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name \u001b[38;5;241m=\u001b[39m name\n\u001b[1;32m-> 5456\u001b[0m variant_tensor \u001b[38;5;241m=\u001b[39m gen_dataset_ops\u001b[38;5;241m.\u001b[39mparallel_map_dataset_v2(\n\u001b[0;32m   5457\u001b[0m     input_dataset\u001b[38;5;241m.\u001b[39m_variant_tensor,  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   5458\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_map_func\u001b[38;5;241m.\u001b[39mfunction\u001b[38;5;241m.\u001b[39mcaptured_inputs,\n\u001b[0;32m   5459\u001b[0m     f\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_map_func\u001b[38;5;241m.\u001b[39mfunction,\n\u001b[0;32m   5460\u001b[0m     num_parallel_calls\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_parallel_calls,\n\u001b[0;32m   5461\u001b[0m     deterministic\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_deterministic,\n\u001b[0;32m   5462\u001b[0m     use_inter_op_parallelism\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_use_inter_op_parallelism,\n\u001b[0;32m   5463\u001b[0m     preserve_cardinality\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_preserve_cardinality,\n\u001b[0;32m   5464\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_common_args)\n\u001b[0;32m   5465\u001b[0m \u001b[38;5;28msuper\u001b[39m(ParallelMapDataset, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(input_dataset, variant_tensor)\n",
      "File \u001b[1;32mc:\\Users\\andri\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py:6023\u001b[0m, in \u001b[0;36mparallel_map_dataset_v2\u001b[1;34m(input_dataset, other_arguments, num_parallel_calls, f, output_types, output_shapes, use_inter_op_parallelism, deterministic, preserve_cardinality, metadata, name)\u001b[0m\n\u001b[0;32m   6021\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n\u001b[0;32m   6022\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 6023\u001b[0m     _result \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_FastPathExecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   6024\u001b[0m \u001b[43m      \u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mParallelMapDatasetV2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother_arguments\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   6025\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_parallel_calls\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moutput_types\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   6026\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moutput_shapes\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_shapes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muse_inter_op_parallelism\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   6027\u001b[0m \u001b[43m      \u001b[49m\u001b[43muse_inter_op_parallelism\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdeterministic\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   6028\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpreserve_cardinality\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreserve_cardinality\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6029\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[0;32m   6030\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers, regularizers\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "import random\n",
    "from collections import deque\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "# Suppress TensorFlow warnings for cleaner output\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "\n",
    "# =========================\n",
    "# 1. Define Predefined Actions\n",
    "# =========================\n",
    "predefined_actions = {\n",
    "    0: np.array([0.0, 0.0, 0.0], dtype=np.float32),  # No Action\n",
    "    1: np.array([-1.0, 0.0, 0.0], dtype=np.float32), # Steer Left\n",
    "    2: np.array([1.0, 0.0, 0.0], dtype=np.float32),  # Steer Right\n",
    "    3: np.array([0.0, 1.0, 0.0], dtype=np.float32),  # Accelerate (Gas)\n",
    "    4: np.array([0.0, 0.0, 1.0], dtype=np.float32),  # Brake\n",
    "}\n",
    "\n",
    "# =========================\n",
    "# 2. Define the Gym Environment\n",
    "# =========================\n",
    "class CarDrivingEnv(gym.Env):\n",
    "    \"\"\"\n",
    "    Custom Gymnasium Environment for Car Driving.\n",
    "    Replace the placeholder methods with your actual environment logic.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(CarDrivingEnv, self).__init__()\n",
    "        # Define action space\n",
    "        self.action_space = spaces.Discrete(len(predefined_actions))\n",
    "        # Define observation space for preprocessed frames (grayscale)\n",
    "        self.observation_space = spaces.Box(low=0.0, high=1.0, shape=(84, 84, 1), dtype=np.float32)\n",
    "        self.max_steps = 1000\n",
    "        self.current_step = 0\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"\n",
    "        Reset the environment to an initial state and return the initial observation.\n",
    "        \"\"\"\n",
    "        self.current_step = 0\n",
    "        initial_observation = self._get_initial_observation()\n",
    "        preprocessed = preprocess_observation(initial_observation)\n",
    "        return preprocessed\n",
    "\n",
    "    def step(self, action):\n",
    "        \"\"\"\n",
    "        Apply the action to the environment and return the next observation, reward, done, and info.\n",
    "        \"\"\"\n",
    "        action_vector = predefined_actions[action]\n",
    "        next_observation, raw_reward, done, info = self._apply_action(action_vector)\n",
    "        preprocessed = preprocess_observation(next_observation)\n",
    "        self.current_step += 1\n",
    "\n",
    "        # Example termination conditions\n",
    "        if self.current_step >= self.max_steps:\n",
    "            done = True\n",
    "\n",
    "        # Compute the reward\n",
    "        reward = compute_reward(info, done)\n",
    "\n",
    "        return preprocessed, reward, done, info\n",
    "\n",
    "    def render(self, mode='human'):\n",
    "        \"\"\"\n",
    "        Render the environment to the screen.\n",
    "        \"\"\"\n",
    "        pass  # Implement rendering logic if needed\n",
    "\n",
    "    def _get_initial_observation(self):\n",
    "        \"\"\"\n",
    "        Return the initial observation.\n",
    "        Replace this with your environment's initial state.\n",
    "        \"\"\"\n",
    "        # Placeholder: return a dummy image\n",
    "        return np.zeros((240, 320, 3), dtype=np.uint8)\n",
    "\n",
    "    def _apply_action(self, action_vector):\n",
    "        \"\"\"\n",
    "        Apply the action to the environment.\n",
    "        Replace this with your environment's action application logic.\n",
    "        \"\"\"\n",
    "        # Placeholder: return a dummy next state, reward, done, and info\n",
    "        next_observation = np.zeros((240, 320, 3), dtype=np.uint8)\n",
    "        raw_reward = 1.0  # Placeholder reward\n",
    "        done = False\n",
    "        info = {\n",
    "            'collision': False,\n",
    "            'off_track': False,\n",
    "            'speed': 0.0\n",
    "        }\n",
    "        return next_observation, raw_reward, done, info\n",
    "\n",
    "# =========================\n",
    "# 3. Preprocessing Functions\n",
    "# =========================\n",
    "def preprocess_observation(observation):\n",
    "    \"\"\"\n",
    "    Preprocess the observation by converting to grayscale, resizing, and normalizing.\n",
    "    \"\"\"\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(observation, cv2.COLOR_RGB2GRAY)\n",
    "    # Resize to 84x84\n",
    "    resized = cv2.resize(gray, (84, 84), interpolation=cv2.INTER_AREA)\n",
    "    # Normalize pixel values\n",
    "    normalized = resized / 255.0\n",
    "    # Expand dimensions to add channel axis\n",
    "    return np.expand_dims(normalized, axis=2)  # Shape: (84, 84, 1)\n",
    "\n",
    "def compute_reward(info, done):\n",
    "    \"\"\"\n",
    "    Compute the reward based on the current state.\n",
    "    \"\"\"\n",
    "    if done:\n",
    "        if info.get('collision', False):\n",
    "            return -100.0  # Collision penalty\n",
    "        elif info.get('off_track', False):\n",
    "            return -100.0  # Off track penalty\n",
    "        else:\n",
    "            return 100.0  # Success reward\n",
    "    else:\n",
    "        reward = 1.0  # Reward for staying on track\n",
    "        # Optionally, add more components (e.g., speed)\n",
    "        reward += info.get('speed', 0.0) * 0.1\n",
    "        return reward\n",
    "\n",
    "# =========================\n",
    "# 4. Frame Stacking Wrapper\n",
    "# =========================\n",
    "class FrameStackEnv(gym.Wrapper):\n",
    "    \"\"\"\n",
    "    Gymnasium environment wrapper to stack consecutive frames.\n",
    "    \"\"\"\n",
    "    def __init__(self, env, stack_size=4):\n",
    "        super(FrameStackEnv, self).__init__(env)\n",
    "        self.stack_size = stack_size\n",
    "        self.frames = deque(maxlen=stack_size)\n",
    "        # Update the observation space to reflect stacked frames\n",
    "        low = np.repeat(env.observation_space.low, stack_size, axis=2)\n",
    "        high = np.repeat(env.observation_space.high, stack_size, axis=2)\n",
    "        self.observation_space = spaces.Box(low=0.0, high=1.0, \n",
    "                                            shape=(env.observation_space.shape[0], \n",
    "                                                   env.observation_space.shape[1], \n",
    "                                                   env.observation_space.shape[2] * stack_size), \n",
    "                                            dtype=np.float32)\n",
    "\n",
    "    def reset(self):\n",
    "        observation = self.env.reset()\n",
    "        for _ in range(self.stack_size):\n",
    "            self.frames.append(observation)\n",
    "        return self._get_observation()\n",
    "\n",
    "    def step(self, action):\n",
    "        observation, reward, done, info = self.env.step(action)\n",
    "        self.frames.append(observation)\n",
    "        return self._get_observation(), reward, done, info\n",
    "\n",
    "    def _get_observation(self):\n",
    "        return np.concatenate(list(self.frames), axis=2)\n",
    "\n",
    "# =========================\n",
    "# 5. Replay Buffer\n",
    "# =========================\n",
    "class ReplayBuffer:\n",
    "    def __init__(self, max_size=100000):\n",
    "        self.buffer = deque(maxlen=max_size)\n",
    "\n",
    "    def add(self, experience):\n",
    "        self.buffer.append(experience)\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.buffer, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.buffer)\n",
    "\n",
    "# =========================\n",
    "# 6. DQN Model Architecture\n",
    "# =========================\n",
    "def build_dqn_model(input_shape, num_actions):\n",
    "    \"\"\"\n",
    "    Build a Convolutional Neural Network for the DQN agent.\n",
    "    \"\"\"\n",
    "    model = models.Sequential(name=\"DQN_Model\")\n",
    "    \n",
    "    # Convolutional Layers\n",
    "    model.add(layers.Conv2D(32, (8, 8), strides=4, activation='relu', input_shape=input_shape))\n",
    "    model.add(layers.Conv2D(64, (4, 4), strides=2, activation='relu'))\n",
    "    model.add(layers.Conv2D(64, (3, 3), strides=1, activation='relu'))\n",
    "    \n",
    "    # Flatten and Dense Layers\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(512, activation='relu'))\n",
    "    \n",
    "    # Output Layer\n",
    "    model.add(layers.Dense(num_actions, activation='linear'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "# =========================\n",
    "# 7. DQN Agent\n",
    "# =========================\n",
    "class DQNAgent:\n",
    "    def __init__(self, input_shape, num_actions, learning_rate=1e-4, gamma=0.99,\n",
    "                 epsilon=1.0, epsilon_min=0.1, epsilon_decay=1e-6, batch_size=32,\n",
    "                 replay_buffer_size=100000, target_update_freq=1000):\n",
    "        \n",
    "        self.num_actions = num_actions\n",
    "        self.gamma = gamma\n",
    "        self.epsilon = epsilon\n",
    "        self.epsilon_min = epsilon_min\n",
    "        self.epsilon_decay = epsilon_decay\n",
    "        self.batch_size = batch_size\n",
    "        self.target_update_freq = target_update_freq\n",
    "        self.learn_step_counter = 0\n",
    "        \n",
    "        # Main and Target Networks\n",
    "        self.model = build_dqn_model(input_shape, num_actions)\n",
    "        self.target_model = build_dqn_model(input_shape, num_actions)\n",
    "        self.target_model.set_weights(self.model.get_weights())\n",
    "        \n",
    "        # Optimizer and Loss Function\n",
    "        self.optimizer = optimizers.Adam(learning_rate=learning_rate)\n",
    "        self.loss_function = tf.keras.losses.Huber()\n",
    "        \n",
    "        # Replay Buffer\n",
    "        self.replay_buffer = ReplayBuffer(max_size=replay_buffer_size)\n",
    "    \n",
    "    def select_action(self, state):\n",
    "        if np.random.rand() < self.epsilon:\n",
    "            return np.random.randint(self.num_actions)\n",
    "        state = np.expand_dims(state, axis=0)  # Add batch dimension\n",
    "        q_values = self.model.predict(state, verbose=0)\n",
    "        return np.argmax(q_values[0])\n",
    "    \n",
    "    def store_experience(self, state, action, reward, next_state, done):\n",
    "        self.replay_buffer.add((state, action, reward, next_state, done))\n",
    "    \n",
    "    def update_epsilon(self):\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon -= self.epsilon_decay\n",
    "        else:\n",
    "            self.epsilon = self.epsilon_min\n",
    "    \n",
    "    def train_step(self):\n",
    "        if len(self.replay_buffer) < self.batch_size:\n",
    "            return\n",
    "        \n",
    "        batch = self.replay_buffer.sample(self.batch_size)\n",
    "        states, actions, rewards, next_states, dones = map(np.array, zip(*batch))\n",
    "        \n",
    "        # Predict Q-values for next states using target network\n",
    "        target_q = self.target_model.predict(next_states, verbose=0)\n",
    "        max_target_q = np.max(target_q, axis=1)\n",
    "        \n",
    "        # Compute target values\n",
    "        targets = rewards + (1 - dones) * self.gamma * max_target_q\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            q_values = self.model(states, training=True)\n",
    "            # Gather the Q-values for the taken actions\n",
    "            action_masks = tf.one_hot(actions, self.num_actions)\n",
    "            q_action = tf.reduce_sum(q_values * action_masks, axis=1)\n",
    "            loss = self.loss_function(targets, q_action)\n",
    "        \n",
    "        # Backpropagation\n",
    "        grads = tape.gradient(loss, self.model.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.model.trainable_variables))\n",
    "        \n",
    "        # Update epsilon\n",
    "        self.update_epsilon()\n",
    "        \n",
    "        # Update target network\n",
    "        self.learn_step_counter += 1\n",
    "        if self.learn_step_counter % self.target_update_freq == 0:\n",
    "            self.target_model.set_weights(self.model.get_weights())\n",
    "    \n",
    "    def save_model(self, path):\n",
    "        self.model.save_weights(path)\n",
    "        print(f\"Model weights saved to {path}\")\n",
    "    \n",
    "    def load_model(self, path):\n",
    "        self.model.load_weights(path)\n",
    "        self.target_model.set_weights(self.model.get_weights())\n",
    "        print(f\"Model weights loaded from {path}\")\n",
    "\n",
    "# =========================\n",
    "# 8. Training and Evaluation Functions\n",
    "# =========================\n",
    "def train_dqn(env, agent, num_episodes=1000, max_steps=1000, save_every=100, save_path='dqn_final_model.h5'):\n",
    "    \"\"\"\n",
    "    Train the DQN agent in the given environment.\n",
    "    \"\"\"\n",
    "    for episode in range(1, num_episodes + 1):\n",
    "        state = env.reset()\n",
    "        total_reward = 0\n",
    "        done = False\n",
    "        \n",
    "        for step in range(max_steps):\n",
    "            action = agent.select_action(state)\n",
    "            next_state, reward, done, info = env.step(action)\n",
    "            total_reward += reward\n",
    "            \n",
    "            agent.store_experience(state, action, reward, next_state, done)\n",
    "            agent.train_step()\n",
    "            \n",
    "            state = next_state\n",
    "            \n",
    "            if done:\n",
    "                break\n",
    "        \n",
    "        print(f\"Episode {episode}/{num_episodes} - Total Reward: {total_reward:.2f} - Epsilon: {agent.epsilon:.4f}\")\n",
    "        \n",
    "        # Save the model at regular intervals\n",
    "        if episode % save_every == 0:\n",
    "            agent.save_model(f'dqn_model_episode_{episode}.h5')\n",
    "    \n",
    "    # Save the final model\n",
    "    agent.save_model(save_path)\n",
    "\n",
    "def evaluate_agent(env, agent, num_episodes=10, max_steps=1000):\n",
    "    \"\"\"\n",
    "    Evaluate the trained DQN agent without exploration.\n",
    "    \"\"\"\n",
    "    total_rewards = []\n",
    "    original_epsilon = agent.epsilon\n",
    "    agent.epsilon = 0.0  # Disable exploration\n",
    "    \n",
    "    for episode in range(1, num_episodes + 1):\n",
    "        state = env.reset()\n",
    "        total_reward = 0\n",
    "        done = False\n",
    "        \n",
    "        for step in range(max_steps):\n",
    "            action = agent.select_action(state)\n",
    "            next_state, reward, done, info = env.step(action)\n",
    "            total_reward += reward\n",
    "            state = next_state\n",
    "            if done:\n",
    "                break\n",
    "        \n",
    "        total_rewards.append(total_reward)\n",
    "        print(f\"Evaluation Episode {episode}/{num_episodes} - Total Reward: {total_reward:.2f}\")\n",
    "    \n",
    "    agent.epsilon = original_epsilon  # Restore original epsilon\n",
    "    avg_reward = np.mean(total_rewards)\n",
    "    print(f\"Average Evaluation Reward over {num_episodes} episodes: {avg_reward:.2f}\")\n",
    "    return avg_reward\n",
    "\n",
    "# =========================\n",
    "# 9. Main Execution\n",
    "# =========================\n",
    "\n",
    "# Initialize Environment and Wrap with FrameStack\n",
    "env = CarDrivingEnv()\n",
    "env = FrameStackEnv(env, stack_size=4)\n",
    "\n",
    "# Define Input Shape and Number of Actions\n",
    "input_shape = env.observation_space.shape  # Should be (84, 84, 4)\n",
    "num_actions = env.action_space.n  # 5\n",
    "\n",
    "print(f\"Input Shape: {input_shape}\")  # For debugging\n",
    "\n",
    "# Initialize DQN Agent\n",
    "agent = DQNAgent(\n",
    "    input_shape=input_shape,\n",
    "    num_actions=num_actions,\n",
    "    learning_rate=1e-4,\n",
    "    gamma=0.99,\n",
    "    epsilon=1.0,\n",
    "    epsilon_min=0.1,\n",
    "    epsilon_decay=1e-6,\n",
    "    batch_size=32,\n",
    "    replay_buffer_size=100000,\n",
    "    target_update_freq=1000\n",
    ")\n",
    "\n",
    "# Train the Agent\n",
    "train_dqn(env, agent, num_episodes=1000, max_steps=1000, save_every=100, save_path='dqn_final_model.h5')\n",
    "\n",
    "# Evaluate the Trained Agent\n",
    "evaluate_agent(env, agent, num_episodes=10, max_steps=1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
