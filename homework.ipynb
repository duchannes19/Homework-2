{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Homework 2**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Iteration ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Check if GPU is available\n",
    "print('GPU is', 'available' if tf.config.list_physical_devices('GPU') else 'NOT AVAILABLE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Import Libraries\n",
    "import numpy as np\n",
    "import sys\n",
    "import gymnasium as gym\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import (\n",
    "    Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D, BatchNormalization\n",
    ")\n",
    "from tensorflow.keras import optimizers, callbacks\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from gymnasium.wrappers import RecordVideo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6369 images belonging to 5 classes.\n",
      "Found 2749 images belonging to 5 classes.\n",
      "Image height = 96, Image Width = 96, Channels = 3\n",
      "Image input shape: (96, 96, 3)\n",
      "Classes: ['0', '1', '2', '3', '4']\n",
      "Loaded 6369 training samples from 5 classes.\n",
      "Loaded 2749 validation samples from 5 classes.\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Data Preparation\n",
    "# Define the paths to your training and validation data\n",
    "trainingset = 'train/'\n",
    "validationset = 'test/'\n",
    "\n",
    "batch_size = 64\n",
    "target_size = (96, 96)  # Adjust based on your dataset\n",
    "\n",
    "# Training data augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0 / 255,\n",
    "    zoom_range=0.1,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=False,\n",
    "    rotation_range=20,\n",
    "    shear_range=0.1,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Validation data should not be augmented\n",
    "validation_datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
    "\n",
    "# Create generators\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    directory=trainingset,\n",
    "    target_size=target_size,\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    directory=validationset,\n",
    "    target_size=target_size,\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Gather dataset information\n",
    "num_samples = train_generator.n\n",
    "num_classes = train_generator.num_classes\n",
    "input_shape = train_generator.image_shape\n",
    "\n",
    "classnames = list(train_generator.class_indices.keys())\n",
    "img_h, img_w, img_channels = input_shape\n",
    "print(f\"Image height = {img_h}, Image Width = {img_w}, Channels = {img_channels}\")\n",
    "print(f\"Image input shape: {input_shape}\")\n",
    "print(f\"Classes: {classnames}\")\n",
    "print(f\"Loaded {num_samples} training samples from {num_classes} classes.\")\n",
    "print(f\"Loaded {validation_generator.n} validation samples from {validation_generator.num_classes} classes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"BasicCNN\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 96, 96, 32)        896       \n",
      "                                                                 \n",
      " activation (Activation)     (None, 96, 96, 32)        0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 48, 48, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 48, 48, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 48, 48, 64)        18496     \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 48, 48, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 24, 24, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 24, 24, 64)        0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 36864)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               4718720   \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 128)               0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 5)                 645       \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 5)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,738,757\n",
      "Trainable params: 4,738,757\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Model Variation 1 - Basic CNN\n",
    "def BasicCNN(input_shape, num_classes):\n",
    "    model = Sequential(name=\"BasicCNN\")\n",
    "\n",
    "    # Convolutional Layers\n",
    "    model.add(Conv2D(filters=32, kernel_size=(3, 3), padding='same', input_shape=input_shape))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(filters=64, kernel_size=(3, 3), padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    # Flatten and Dense Layers\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    # Output Layer\n",
    "    model.add(Dense(num_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    # Compile the model\n",
    "    optimizer = optimizers.Adam(learning_rate=0.001)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "# Instantiate and summarize the model\n",
    "model_basic = BasicCNN(input_shape, num_classes)\n",
    "model_basic.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"CNNWithBatchNorm\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2 (Conv2D)           (None, 96, 96, 32)        896       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 96, 96, 32)       128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 96, 96, 32)        0         \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 48, 48, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 48, 48, 32)        0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 48, 48, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 48, 48, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 48, 48, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 24, 24, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 24, 24, 64)        0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 24, 24, 128)       73856     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 24, 24, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_6 (Activation)   (None, 24, 24, 128)       0         \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 12, 12, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 12, 12, 128)       0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 18432)             0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 256)               4718848   \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 256)              1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_7 (Activation)   (None, 256)               0         \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 5)                 1285      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,815,301\n",
      "Trainable params: 4,814,341\n",
      "Non-trainable params: 960\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Model Variation 2 - CNN with Batch Normalization\n",
    "def CNNWithBatchNorm(input_shape, num_classes):\n",
    "    model = Sequential(name=\"CNNWithBatchNorm\")\n",
    "\n",
    "    # First Convolutional Block\n",
    "    model.add(Conv2D(32, (3, 3), padding='same', input_shape=input_shape))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    # Second Convolutional Block\n",
    "    model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    # Third Convolutional Block\n",
    "    model.add(Conv2D(128, (3, 3), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    # Flatten and Dense Layers\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    # Output Layer\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    # Compile the model\n",
    "    optimizer = optimizers.Adam(learning_rate=0.0005)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "# Instantiate and summarize the model\n",
    "model_batchnorm = CNNWithBatchNorm(input_shape, num_classes)\n",
    "model_batchnorm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"DeepCNN\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_5 (Conv2D)           (None, 96, 96, 32)        896       \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 96, 96, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 48, 48, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 48, 48, 32)        0         \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 48, 48, 64)        18496     \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 48, 48, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 24, 24, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 24, 24, 64)        0         \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 24, 24, 128)       73856     \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 24, 24, 128)       147584    \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 12, 12, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 12, 12, 128)       0         \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 18432)             0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 512)               9437696   \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 5)                 2565      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,727,269\n",
      "Trainable params: 9,727,269\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Model Variation 3 - Deeper CNN with Different Activation\n",
    "def DeepCNN(input_shape, num_classes):\n",
    "    model = Sequential(name=\"DeepCNN\")\n",
    "\n",
    "    # First Convolutional Block\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=input_shape))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    # Second Convolutional Block\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    # Third Convolutional Block\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    # Flatten and Dense Layers\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    # Output Layer\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    # Compile the model\n",
    "    optimizer = optimizers.Adam(learning_rate=0.0001)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "# Instantiate and summarize the model\n",
    "model_deep = DeepCNN(input_shape, num_classes)\n",
    "model_deep.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"CNNWithGAP\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_11 (Conv2D)          (None, 96, 96, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPooling  (None, 48, 48, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 48, 48, 32)        0         \n",
      "                                                                 \n",
      " conv2d_12 (Conv2D)          (None, 48, 48, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPooling  (None, 24, 24, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 24, 24, 64)        0         \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 24, 24, 128)       73856     \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 128)              0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 256)               33024     \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 5)                 1285      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 127,557\n",
      "Trainable params: 127,557\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Cell AH: Regression-Based Model\n",
    "def RegressionCNN(input_shape, num_outputs=3):\n",
    "    model = Sequential(name=\"RegressionCNN\")\n",
    "\n",
    "    # Convolutional Layers\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=input_shape))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    # Flatten and Dense Layers\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    # Output Layer for regression\n",
    "    model.add(Dense(num_outputs, activation='tanh'))  # tanh to bound outputs between -1 and 1\n",
    "\n",
    "    # Compile the model with regression loss\n",
    "    optimizer = optimizers.Adam(learning_rate=0.0001)\n",
    "    model.compile(loss='mse', optimizer=optimizer, metrics=['mae'])\n",
    "\n",
    "    return model\n",
    "\n",
    "# Instantiate and summarize the regression model\n",
    "model_regression = RegressionCNN(input_shape, num_outputs=3)\n",
    "model_regression.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Select Model\n",
    "# Choose one of the models defined above\n",
    "model = model_regression  # Replace with model_basic, model_deep, or model_regression as desired"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Define Callbacks\n",
    "early_stopping = callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,  # Increased patience for potentially longer training\n",
    "    verbose=1,\n",
    "    mode='auto',\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "reduce_lr = callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.2,\n",
    "    patience=5,  # Increased patience\n",
    "    verbose=1,\n",
    "    min_lr=1e-6\n",
    ")\n",
    "\n",
    "# Optionally, add ModelCheckpoint to save the best model\n",
    "checkpoint = callbacks.ModelCheckpoint(\n",
    "    'models/best_model.keras',\n",
    "    monitor='val_accuracy',\n",
    "    save_best_only=True,\n",
    "    mode='max'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "100/100 [==============================] - 19s 141ms/step - loss: 1.5132 - accuracy: 0.3029 - val_loss: 1.5116 - val_accuracy: 0.6042 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 13s 131ms/step - loss: 1.4979 - accuracy: 0.3271 - val_loss: 1.4057 - val_accuracy: 0.6952 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 13s 128ms/step - loss: 1.4390 - accuracy: 0.4081 - val_loss: 1.3865 - val_accuracy: 0.6057 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 13s 131ms/step - loss: 1.3985 - accuracy: 0.4363 - val_loss: 1.3014 - val_accuracy: 0.6282 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 13s 128ms/step - loss: 1.3808 - accuracy: 0.4362 - val_loss: 1.3088 - val_accuracy: 0.6115 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 14s 136ms/step - loss: 1.3722 - accuracy: 0.4536 - val_loss: 1.2010 - val_accuracy: 0.6693 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 13s 135ms/step - loss: 1.3646 - accuracy: 0.4585 - val_loss: 1.1845 - val_accuracy: 0.6490 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 13s 130ms/step - loss: 1.3371 - accuracy: 0.4866 - val_loss: 1.1916 - val_accuracy: 0.6450 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 13s 126ms/step - loss: 1.3028 - accuracy: 0.4990 - val_loss: 1.1137 - val_accuracy: 0.6355 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 13s 127ms/step - loss: 1.2796 - accuracy: 0.5131 - val_loss: 1.0698 - val_accuracy: 0.6381 - lr: 1.0000e-04\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 13s 125ms/step - loss: 1.2671 - accuracy: 0.5205 - val_loss: 1.0937 - val_accuracy: 0.6551 - lr: 1.0000e-04\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 13s 125ms/step - loss: 1.2544 - accuracy: 0.5216 - val_loss: 1.1216 - val_accuracy: 0.6279 - lr: 1.0000e-04\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 12s 124ms/step - loss: 1.2420 - accuracy: 0.5312 - val_loss: 1.1225 - val_accuracy: 0.6119 - lr: 1.0000e-04\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 12s 124ms/step - loss: 1.2421 - accuracy: 0.5354 - val_loss: 1.1038 - val_accuracy: 0.6333 - lr: 1.0000e-04\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.2328 - accuracy: 0.5385\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n",
      "100/100 [==============================] - 13s 126ms/step - loss: 1.2328 - accuracy: 0.5385 - val_loss: 1.1165 - val_accuracy: 0.6133 - lr: 1.0000e-04\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 14s 136ms/step - loss: 1.2253 - accuracy: 0.5436 - val_loss: 1.0890 - val_accuracy: 0.6253 - lr: 2.0000e-05\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 14s 139ms/step - loss: 1.2171 - accuracy: 0.5481 - val_loss: 1.0745 - val_accuracy: 0.6370 - lr: 2.0000e-05\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 15s 152ms/step - loss: 1.2177 - accuracy: 0.5445 - val_loss: 1.1036 - val_accuracy: 0.6126 - lr: 2.0000e-05\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 15s 150ms/step - loss: 1.2072 - accuracy: 0.5455 - val_loss: 1.1216 - val_accuracy: 0.6046 - lr: 2.0000e-05\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 14s 142ms/step - loss: 1.2076 - accuracy: 0.5577 - val_loss: 1.0388 - val_accuracy: 0.6450 - lr: 2.0000e-05\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 14s 140ms/step - loss: 1.2034 - accuracy: 0.5494 - val_loss: 1.1036 - val_accuracy: 0.6188 - lr: 2.0000e-05\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 14s 137ms/step - loss: 1.2086 - accuracy: 0.5503 - val_loss: 1.0421 - val_accuracy: 0.6428 - lr: 2.0000e-05\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 14s 139ms/step - loss: 1.2022 - accuracy: 0.5475 - val_loss: 1.0958 - val_accuracy: 0.6268 - lr: 2.0000e-05\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 15s 147ms/step - loss: 1.1970 - accuracy: 0.5553 - val_loss: 1.0746 - val_accuracy: 0.6362 - lr: 2.0000e-05\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.1920 - accuracy: 0.5555\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 3.999999898951501e-06.\n",
      "100/100 [==============================] - 14s 144ms/step - loss: 1.1920 - accuracy: 0.5555 - val_loss: 1.0756 - val_accuracy: 0.6253 - lr: 2.0000e-05\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 14s 144ms/step - loss: 1.1932 - accuracy: 0.5525 - val_loss: 1.0937 - val_accuracy: 0.6224 - lr: 4.0000e-06\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 15s 148ms/step - loss: 1.1937 - accuracy: 0.5519 - val_loss: 1.0863 - val_accuracy: 0.6242 - lr: 4.0000e-06\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 14s 144ms/step - loss: 1.2037 - accuracy: 0.5511 - val_loss: 1.0840 - val_accuracy: 0.6224 - lr: 4.0000e-06\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 15s 147ms/step - loss: 1.2034 - accuracy: 0.5473 - val_loss: 1.1014 - val_accuracy: 0.6155 - lr: 4.0000e-06\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.1922 - accuracy: 0.5472Restoring model weights from the end of the best epoch: 20.\n",
      "\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "100/100 [==============================] - 15s 149ms/step - loss: 1.1922 - accuracy: 0.5472 - val_loss: 1.0873 - val_accuracy: 0.6220 - lr: 4.0000e-06\n",
      "Epoch 30: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Cell 9: Train the Model\n",
    "# Calculate steps per epoch and validation steps\n",
    "steps_per_epoch = int(np.ceil(train_generator.n / batch_size))\n",
    "val_steps = int(np.ceil(validation_generator.n / batch_size))\n",
    "\n",
    "\n",
    "try:\n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        epochs=100,\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=val_steps,\n",
    "        callbacks=[early_stopping, reduce_lr, checkpoint],\n",
    "        verbose=1\n",
    "    )\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Training interrupted.\")\n",
    "\n",
    "# Save the final model\n",
    "model.save('models/model_final.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 2s 28ms/step - loss: 1.4057 - accuracy: 0.6952\n",
      "Loss: 1.4057\n",
      "Accuracy: 0.6952\n"
     ]
    }
   ],
   "source": [
    "# Cell 10: Evaluate the Model\n",
    "# Load the best saved model\n",
    "best_model = load_model('models/best_model.keras')\n",
    "\n",
    "# Evaluate on validation data\n",
    "val_steps = int(np.ceil(validation_generator.n / batch_size))\n",
    "loss, acc = best_model.evaluate(validation_generator, steps=val_steps, verbose=1)\n",
    "print(f'Loss: {loss:.4f}')\n",
    "print(f'Accuracy: {acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.000     0.000     0.000       133\n",
      "           1      0.000     0.000     0.000       275\n",
      "           2      0.379     0.424     0.400       406\n",
      "           3      0.758     0.917     0.830      1896\n",
      "           4      0.000     0.000     0.000        39\n",
      "\n",
      "    accuracy                          0.695      2749\n",
      "   macro avg      0.227     0.268     0.246      2749\n",
      "weighted avg      0.579     0.695     0.631      2749\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\andri\\miniconda3\\envs\\cv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\andri\\miniconda3\\envs\\cv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\andri\\miniconda3\\envs\\cv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Cell 11: Classification Report\n",
    "preds = best_model.predict(validation_generator, steps=val_steps, verbose=0)\n",
    "Ypred = np.argmax(preds, axis=1)\n",
    "Ytest = validation_generator.classes  # Ensure shuffle=False in validation_generator\n",
    "\n",
    "print(classification_report(Ytest, Ypred, target_names=classnames, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cell 12: Confusion Matrix\n",
    "cm = confusion_matrix(Ytest, Ypred)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', xticklabels=classnames, yticklabels=classnames, cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True             Predicted        Errors     Error %   \n",
      "------------------------------------------------------------\n",
      "2                -> 3                234        8.51%\n",
      "1                -> 3                198        7.20%\n",
      "3                -> 2                157        5.71%\n",
      "0                -> 3                98         3.56%\n",
      "1                -> 2                77         2.80%\n",
      "0                -> 2                35         1.27%\n",
      "4                -> 3                26         0.95%\n",
      "4                -> 2                13         0.47%\n"
     ]
    }
   ],
   "source": [
    "# Cell 13: Text-Based Confusion Matrix\n",
    "conf = []\n",
    "for i in range(cm.shape[0]):\n",
    "    for j in range(cm.shape[1]):\n",
    "        if i != j and cm[i][j] > 0:\n",
    "            conf.append([i, j, cm[i][j]])\n",
    "\n",
    "conf = np.array(conf)\n",
    "conf = conf[np.argsort(-conf[:, 2])]  # Sort by descending error count\n",
    "\n",
    "print(f'{\"True\":<16} {\"Predicted\":<16} {\"Errors\":<10} {\"Error %\":<10}')\n",
    "print('-' * 60)\n",
    "for k in conf:\n",
    "    true_class = classnames[int(k[0])]\n",
    "    pred_class = classnames[int(k[1])]\n",
    "    errors = int(k[2])\n",
    "    error_pct = (errors / validation_generator.n) * 100\n",
    "    print(f'{true_class:<16} -> {pred_class:<16} {errors:<10} {error_pct:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment: CarRacing-v3\n",
      "Action space: Box([-1.  0.  0.], 1.0, (3,), float32)\n",
      "Observation space: Box(0, 255, (96, 96, 3), uint8)\n",
      "1/1 [==============================] - 0s 420ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n"
     ]
    }
   ],
   "source": [
    "# Cell 9: Model Deployment with Gymnasium (Final Revised for Continuous Actions)\n",
    "import numpy as np\n",
    "from gymnasium.wrappers import RecordVideo\n",
    "\n",
    "def play(env, model, predefined_actions):\n",
    "    seed = 2000\n",
    "    obs, _ = env.reset(seed=seed)\n",
    "\n",
    "    # Drop initial frames with no action\n",
    "    no_action = predefined_actions[0]  # [0.0, 0.0, 0.0]\n",
    "    for _ in range(50):\n",
    "        obs, _, _, _, _ = env.step(no_action)\n",
    "\n",
    "    done = False\n",
    "    while not done:\n",
    "        # Preprocess the observation\n",
    "        img = preprocess_observation(obs, target_size)\n",
    "        p = model.predict(np.expand_dims(img, axis=0))  # Shape: (1, 5)\n",
    "        predicted_class = np.argmax(p)  # Integer 0-4\n",
    "\n",
    "        # Map the predicted class to a predefined action\n",
    "        action = predefined_actions.get(predicted_class, predefined_actions[0])  # Array\n",
    "\n",
    "        # Ensure the action is a float32 NumPy array\n",
    "        action = action.astype(np.float32)\n",
    "\n",
    "        # Step the environment with the action\n",
    "        obs, _, terminated, truncated, _ = env.step(action)\n",
    "        done = terminated or truncated\n",
    "\n",
    "    env.close()\n",
    "\n",
    "def preprocess_observation(obs, target_size):\n",
    "    from tensorflow.keras.preprocessing.image import img_to_array, array_to_img\n",
    "\n",
    "    # Convert observation to PIL Image\n",
    "    img = array_to_img(obs)\n",
    "    # Resize image\n",
    "    img = img.resize(target_size)\n",
    "    # Convert to array and normalize\n",
    "    img = img_to_array(img) / 255.0\n",
    "    return img\n",
    "\n",
    "# Define predefined actions (Continuous)\n",
    "predefined_actions = {\n",
    "    0: np.array([0.0, 0.0, 0.0], dtype=np.float32),  # No Action\n",
    "    1: np.array([-1.0, 0.0, 0.0], dtype=np.float32), # Steer Left\n",
    "    2: np.array([1.0, 0.0, 0.0], dtype=np.float32),  # Steer Right\n",
    "    3: np.array([0.0, 1.0, 0.0], dtype=np.float32),  # Accelerate (Gas)\n",
    "    4: np.array([0.0, 0.0, 1.0], dtype=np.float32),  # Brake\n",
    "    # Add more actions as needed\n",
    "}\n",
    "\n",
    "# Initialize the environment without 'continuous' parameter\n",
    "env_arguments = {\n",
    "    'domain_randomize': False,\n",
    "    'render_mode': 'rgb_array'\n",
    "}\n",
    "\n",
    "env_name = 'CarRacing-v3'\n",
    "env = gym.make(env_name, **env_arguments)\n",
    "\n",
    "# Wrap the environment to record videos\n",
    "video_dir = 'video_recordings'  # Specify the directory to save video recordings\n",
    "env = RecordVideo(env, video_dir)\n",
    "\n",
    "print(\"Environment:\", env_name)\n",
    "print(\"Action space:\", env.action_space)\n",
    "print(\"Observation space:\", env.observation_space)\n",
    "\n",
    "best_model = load_model('models/best_model.keras')\n",
    "\n",
    "# Play the game using the trained model\n",
    "play(env, best_model, predefined_actions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
