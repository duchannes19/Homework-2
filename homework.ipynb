{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Homework 2**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Iteration ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Check if GPU is available\n",
    "print('GPU is', 'available' if tf.config.list_physical_devices('GPU') else 'NOT AVAILABLE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Import Libraries\n",
    "import numpy as np\n",
    "import sys\n",
    "import gymnasium as gym\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import (\n",
    "    Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D, BatchNormalization\n",
    ")\n",
    "from tensorflow.keras import optimizers, callbacks\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from gymnasium.wrappers import RecordVideo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Data Preparation\n",
    "# Define the paths to your training and validation data\n",
    "trainingset = 'train/'\n",
    "validationset = 'test/'\n",
    "\n",
    "batch_size = 64\n",
    "target_size = (96, 96)  # Adjust based on your dataset\n",
    "\n",
    "# Training data augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0 / 255,\n",
    "    zoom_range=0.1,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=False,\n",
    "    rotation_range=20,\n",
    "    shear_range=0.1,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Validation data should not be augmented\n",
    "validation_datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
    "\n",
    "# Create generators\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    directory=trainingset,\n",
    "    target_size=target_size,\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    directory=validationset,\n",
    "    target_size=target_size,\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Gather dataset information\n",
    "num_samples = train_generator.n\n",
    "num_classes = train_generator.num_classes\n",
    "input_shape = train_generator.image_shape\n",
    "\n",
    "classnames = list(train_generator.class_indices.keys())\n",
    "img_h, img_w, img_channels = input_shape\n",
    "print(f\"Image height = {img_h}, Image Width = {img_w}, Channels = {img_channels}\")\n",
    "print(f\"Image input shape: {input_shape}\")\n",
    "print(f\"Classes: {classnames}\")\n",
    "print(f\"Loaded {num_samples} training samples from {num_classes} classes.\")\n",
    "print(f\"Loaded {validation_generator.n} validation samples from {validation_generator.num_classes} classes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell X: Analyze Class Distribution\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Count of samples per class\n",
    "class_counts = train_generator.classes\n",
    "class_names = list(train_generator.class_indices.keys())\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.bar(class_names, [np.sum(class_counts == i) for i in range(len(class_names))], color='skyblue')\n",
    "plt.xlabel('Classes')\n",
    "plt.ylabel('Number of Samples')\n",
    "plt.title('Class Distribution in Training Set')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 12: Create Separate Generators for Minority Classes\n",
    "import os\n",
    "\n",
    "# Define the target size and batch size\n",
    "target_size = (96, 96)\n",
    "batch_size = 64\n",
    "\n",
    "# Initialize data augmentation for minority classes\n",
    "minority_datagen = ImageDataGenerator(\n",
    "    rescale=1.0 / 255,\n",
    "    zoom_range=0.2,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    rotation_range=30,\n",
    "    shear_range=0.2,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Paths to minority class directories\n",
    "minority_classes = ['0', '4']\n",
    "train_dir = 'train/'\n",
    "\n",
    "augmented_generators = []\n",
    "\n",
    "for cls in minority_classes:\n",
    "    class_dir = os.path.join(train_dir, cls)\n",
    "    if not os.path.isdir(class_dir):\n",
    "        print(f\"Directory for class {cls} not found. Skipping augmentation.\")\n",
    "        continue\n",
    "    generator = minority_datagen.flow_from_directory(\n",
    "        directory=train_dir,\n",
    "        target_size=target_size,\n",
    "        color_mode=\"rgb\",\n",
    "        batch_size=batch_size,\n",
    "        class_mode=\"categorical\",\n",
    "        classes=[cls],  # Only target the minority class\n",
    "        shuffle=True\n",
    "    )\n",
    "    augmented_generators.append(generator)\n",
    "\n",
    "print(f\"Number of augmented generators: {len(augmented_generators)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell Y: Compute Class Weights\n",
    "from sklearn.utils import class_weight\n",
    "import numpy as np\n",
    "\n",
    "# Compute class weights\n",
    "class_weights = class_weight.compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(train_generator.classes),\n",
    "    y=train_generator.classes\n",
    ")\n",
    "\n",
    "# Convert to a dictionary\n",
    "class_weights_dict = {i: weight for i, weight in enumerate(class_weights)}\n",
    "print(\"Class Weights:\", class_weights_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 13: Combine Original and Augmented Generators\n",
    "import itertools\n",
    "\n",
    "# Create a combined generator\n",
    "train_combined = itertools.chain(\n",
    "    train_generator,\n",
    "    *augmented_generators\n",
    ")\n",
    "\n",
    "# Define a generator that yields data from the combined generator\n",
    "def combined_generator(combined):\n",
    "    for data in combined:\n",
    "        yield data\n",
    "\n",
    "# Reset the iterator\n",
    "train_combined = combined_generator(train_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Deeper CNN with Different Activation\n",
    "def DeepCNN(input_shape, num_classes):\n",
    "    model = Sequential(name=\"DeepCNN\")\n",
    "\n",
    "    # First Convolutional Block\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=input_shape))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    # Second Convolutional Block\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    # Third Convolutional Block\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    # Flatten and Dense Layers\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    # Output Layer\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    # Compile the model with RMSprop optimizer\n",
    "    optimizer = optimizers.RMSprop(learning_rate=0.001)\n",
    "\n",
    "    model.compile(\n",
    "        loss='categorical_crossentropy',\n",
    "        optimizer=optimizer,\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# Instantiate and summarize the model\n",
    "model_deep = DeepCNN(input_shape, num_classes)\n",
    "model_deep.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers, regularizers\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "\n",
    "def ImprovedDeepCNN(input_shape, num_classes):\n",
    "    model = models.Sequential(name=\"ImprovedDeepCNN\")\n",
    "    \n",
    "    # First Convolutional Block\n",
    "    model.add(layers.Conv2D(32, (3, 3), padding='same', input_shape=input_shape))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(layers.Conv2D(32, (3, 3), padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    \n",
    "    # Second Convolutional Block\n",
    "    model.add(layers.Conv2D(64, (3, 3), padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(layers.Conv2D(64, (3, 3), padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    \n",
    "    # Third Convolutional Block\n",
    "    model.add(layers.Conv2D(128, (3, 3), padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(layers.Conv2D(128, (3, 3), padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Dropout(0.4))\n",
    "    \n",
    "    # Global Average Pooling and Dense Layers\n",
    "    model.add(layers.GlobalAveragePooling2D())\n",
    "    model.add(layers.Dense(512, kernel_regularizer=regularizers.l2(0.001)))\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    \n",
    "    # Output Layer\n",
    "    model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    # Compile the model with Adam optimizer\n",
    "    optimizer = optimizers.Adam(learning_rate=0.0001)\n",
    "    \n",
    "    model.compile(\n",
    "        loss='categorical_crossentropy',\n",
    "        optimizer=optimizer,\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# Instantiate and summarize the improved model\n",
    "model_improved = ImprovedDeepCNN(input_shape, num_classes)\n",
    "model_improved.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Select Model\n",
    "# Choose one of the models defined above\n",
    "model = model_improved  # Replace with model_deep or model_improved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Define Callbacks\n",
    "early_stopping = callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,  # Increased patience for potentially longer training\n",
    "    verbose=1,\n",
    "    mode='auto',\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "reduce_lr = callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.2,\n",
    "    patience=3,  # Increased patience\n",
    "    verbose=1,\n",
    "    min_lr=1e-6\n",
    ")\n",
    "\n",
    "# Optionally, add ModelCheckpoint to save the best model\n",
    "checkpoint = callbacks.ModelCheckpoint(\n",
    "    'models/best_model.keras',\n",
    "    monitor='val_accuracy',\n",
    "    save_best_only=True,\n",
    "    mode='max'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Train the Model\n",
    "# Calculate steps per epoch and validation steps\n",
    "steps_per_epoch = int(np.ceil(train_generator.n / batch_size))\n",
    "val_steps = int(np.ceil(validation_generator.n / batch_size))\n",
    "\n",
    "try:\n",
    "    history = model.fit(\n",
    "        train_combined,\n",
    "        epochs=100,\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=val_steps,\n",
    "        callbacks=[early_stopping, reduce_lr, checkpoint],\n",
    "        class_weight=class_weights_dict,\n",
    "        verbose=1\n",
    "    )\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Training interrupted.\")\n",
    "\n",
    "# Save the final model based if you chose deep or improved model\n",
    "if model == model_deep:\n",
    "    model.save('models/final_model_deep.keras')\n",
    "else:\n",
    "    model.save('models/final_model_improved.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Average\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model_deep = load_model('models/final_model_deep.keras')\n",
    "model_improved = load_model('models/final_model_improved.keras')\n",
    "\n",
    "input_shape_deep = model_deep.input_shape[1:]  # Exclude batch size\n",
    "input_shape_improved = model_improved.input_shape[1:]\n",
    "\n",
    "assert input_shape_deep == input_shape_improved, \"Input shapes of both models must be the same.\"\n",
    "\n",
    "# Create an input layer that matches the input shape\n",
    "input_layer = Input(shape=input_shape_deep)\n",
    "\n",
    "# Get predictions from both models\n",
    "preds_deep = model_deep(input_layer)\n",
    "preds_improved = model_improved(input_layer)\n",
    "\n",
    "# Average the outputs\n",
    "averaged_preds = Average()([preds_deep, preds_improved])\n",
    "\n",
    "# Create the combined model\n",
    "combined_model = Model(inputs=input_layer, outputs=averaged_preds)\n",
    "\n",
    "# Compile the combined model\n",
    "combined_model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=optimizers.Adam(learning_rate=0.0001),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Save the combined model\n",
    "combined_model.save('models/combined_model.keras')\n",
    "\n",
    "# Cell 11: Evaluate the Model\n",
    "# Load the combined model\n",
    "combined_model = load_model('models/combined_model.keras')\n",
    "\n",
    "# Evaluate the model on the validation set\n",
    "val_loss, val_acc = combined_model.evaluate(validation_generator, verbose=1)\n",
    "print(f\"Validation Accuracy: {val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: Evaluate the Model\n",
    "# Load the best saved model\n",
    "best_model = load_model('models/combined_model.keras')\n",
    "\n",
    "# Evaluate on validation data\n",
    "val_steps = int(np.ceil(validation_generator.n / batch_size))\n",
    "loss, acc = best_model.evaluate(validation_generator, steps=val_steps, verbose=1)\n",
    "print(f'Loss: {loss:.4f}')\n",
    "print(f'Accuracy: {acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11: Classification Report\n",
    "preds = best_model.predict(validation_generator, steps=val_steps, verbose=0)\n",
    "Ypred = np.argmax(preds, axis=1)\n",
    "Ytest = validation_generator.classes  # Ensure shuffle=False in validation_generator\n",
    "\n",
    "print(classification_report(Ytest, Ypred, target_names=classnames, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 12: Confusion Matrix\n",
    "cm = confusion_matrix(Ytest, Ypred)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', xticklabels=classnames, yticklabels=classnames, cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 13: Text-Based Confusion Matrix\n",
    "conf = []\n",
    "for i in range(cm.shape[0]):\n",
    "    for j in range(cm.shape[1]):\n",
    "        if i != j and cm[i][j] > 0:\n",
    "            conf.append([i, j, cm[i][j]])\n",
    "\n",
    "conf = np.array(conf)\n",
    "conf = conf[np.argsort(-conf[:, 2])]  # Sort by descending error count\n",
    "\n",
    "print(f'{\"True\":<16} {\"Predicted\":<16} {\"Errors\":<10} {\"Error %\":<10}')\n",
    "print('-' * 60)\n",
    "for k in conf:\n",
    "    true_class = classnames[int(k[0])]\n",
    "    pred_class = classnames[int(k[1])]\n",
    "    errors = int(k[2])\n",
    "    error_pct = (errors / validation_generator.n) * 100\n",
    "    print(f'{true_class:<16} -> {pred_class:<16} {errors:<10} {error_pct:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Model Deployment with Gymnasium (Final Revised for Continuous Actions)\n",
    "import numpy as np\n",
    "from gymnasium.wrappers import RecordVideo\n",
    "\n",
    "def play(env, model, predefined_actions):\n",
    "    seed = 2000\n",
    "    obs, _ = env.reset(seed=seed)\n",
    "\n",
    "    # Drop initial frames with no action\n",
    "    no_action = predefined_actions[0]  # [0.0, 0.0, 0.0]\n",
    "    for _ in range(50):\n",
    "        obs, _, _, _, _ = env.step(no_action)\n",
    "\n",
    "    done = False\n",
    "    while not done:\n",
    "        # Preprocess the observation\n",
    "        img = preprocess_observation(obs, target_size)\n",
    "        p = model.predict(np.expand_dims(img, axis=0))  # Shape: (1, 5)\n",
    "        predicted_class = np.argmax(p)  # Integer 0-4\n",
    "\n",
    "        # Map the predicted class to a predefined action\n",
    "        action = predefined_actions.get(predicted_class, predefined_actions[0])  # Array\n",
    "\n",
    "        # Ensure the action is a float32 NumPy array\n",
    "        action = np.array(action, dtype=np.float32)\n",
    "\n",
    "        # Step the environment with the action\n",
    "        obs, _, terminated, truncated, _ = env.step(action)\n",
    "        done = terminated or truncated\n",
    "\n",
    "    env.close()\n",
    "\n",
    "def preprocess_observation(obs, target_size):\n",
    "    from tensorflow.keras.preprocessing.image import img_to_array, array_to_img\n",
    "\n",
    "    # Convert observation to PIL Image\n",
    "    img = array_to_img(obs)\n",
    "    # Resize image\n",
    "    img = img.resize(target_size)\n",
    "    # Convert to array and normalize\n",
    "    img = img_to_array(img) / 255.0\n",
    "    return img\n",
    "\n",
    "# Define predefined actions (Continuous)\n",
    "predefined_actions = {\n",
    "    0: np.array([0.0, 0.0, 0.0], dtype=np.float32),  # No Action\n",
    "    1: np.array([-1.0, 0.0, 0.0], dtype=np.float32), # Steer Left\n",
    "    2: np.array([1.0, 0.0, 0.0], dtype=np.float32),  # Steer Right\n",
    "    3: np.array([0.0, 1.0, 0.0], dtype=np.float32),  # Accelerate (Gas)\n",
    "    4: np.array([0.0, 0.0, 1.0], dtype=np.float32),  # Brake\n",
    "    # Add more actions as needed\n",
    "}\n",
    "\n",
    "# Initialize the environment without 'continuous' parameter\n",
    "env_arguments = {\n",
    "    'domain_randomize': False,\n",
    "    'render_mode': 'rgb_array'\n",
    "}\n",
    "\n",
    "env_name = 'CarRacing-v3'\n",
    "env = gym.make(env_name, **env_arguments)\n",
    "\n",
    "# Wrap the environment to record videos\n",
    "video_dir = 'video_recordings'  # Specify the directory to save video recordings\n",
    "env = RecordVideo(env, video_dir)\n",
    "\n",
    "print(\"Environment:\", env_name)\n",
    "print(\"Action space:\", env.action_space)\n",
    "print(\"Observation space:\", env.observation_space)\n",
    "\n",
    "# Play the game using the trained model\n",
    "play(env, best_model, predefined_actions)\n",
    "#play(env, best_model_regression, predefined_actions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (Optional Approach) Reinforcement Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Everything loaded!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import cv2\n",
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "import random\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import deque\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers, losses\n",
    "\n",
    "# Set channels_first to match the PyTorch-like input (batch, channels, height, width)\n",
    "# Usually TensorFlow defaults to channels_last, but we can specify data_format per layer.\n",
    "# Another approach is to rearrange inputs to channels_last before passing to the model.\n",
    "# Here, we will specify data_format='channels_first' for our convolutional layers.\n",
    "tf.keras.backend.set_image_data_format('channels_first')\n",
    "\n",
    "\n",
    "############################################\n",
    "# UTIL FUNCTIONS\n",
    "############################################\n",
    "\n",
    "def write_json_to_file(data, file_path):\n",
    "    try:\n",
    "        with open(file_path, 'w') as json_file:\n",
    "            json.dump(data, json_file, indent=4)\n",
    "        print(f\"JSON data successfully written to {file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error writing JSON data to {file_path}: {e}\")\n",
    "\n",
    "\n",
    "def read_json_from_file(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'r') as json_file:\n",
    "            data = json.load(json_file)\n",
    "        print(f\"JSON data successfully read from {file_path}\")\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading JSON data from {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def make_all_paths(is_dynamic_root=True, dir_name=\"rl_class\"):\n",
    "    ROOT = \"reinforcement_learning\"\n",
    "    if is_dynamic_root:\n",
    "        # Create a dynamic directory name based on index number\n",
    "        dir_name = dir_name + \"_\" + str(datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\"))\n",
    "    else:\n",
    "        dir_name = dir_name\n",
    "\n",
    "    path_root = ROOT + \"/\" + dir_name + \"/\"\n",
    "    dirs = [\"models\", \"plots\", \"videos\"]\n",
    "    for d in dirs:\n",
    "        path = path_root + d\n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path)\n",
    "        print(\">> Created dir\", path)\n",
    "    return path_root\n",
    "\n",
    "\n",
    "def plot_state_car(data, title=None):\n",
    "    assert len(data.shape) == 3, \"Can only handle 3D mats.\"\n",
    "    fig, axs = plt.subplots(1, data.shape[0], figsize=(10, 4))\n",
    "    for i in range(data.shape[0]):\n",
    "        axs[i].imshow(data[i], cmap='gray')\n",
    "        axs[i].axis('off')\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_frame_car(data, title=None):\n",
    "    plt.imshow(data, cmap=\"gray\")\n",
    "    plt.axis('off')\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def preprocess_frame_car(frame):\n",
    "    # frame is RGB image\n",
    "    # Convert to grayscale\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    frame = cv2.resize(frame, (96, 96))\n",
    "    return frame\n",
    "\n",
    "\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "\n",
    "\n",
    "############################################\n",
    "# CONFIG\n",
    "############################################\n",
    "\n",
    "class Config:\n",
    "    SEED = random.randint(0, 1000)\n",
    "\n",
    "    STARTING_EPISODE_TRAIN = 0\n",
    "    ENDING_EPISODE_TRAIN = STARTING_EPISODE_TRAIN + 30\n",
    "\n",
    "    STARTING_EPISODE_TEST = ENDING_EPISODE_TRAIN + 1\n",
    "    ENDING_EPISODE_TEST = STARTING_EPISODE_TEST + 30\n",
    "\n",
    "    SKIP_FRAMES = 2\n",
    "    TRAINING_BATCH_SIZE = 32\n",
    "    UPDATE_TARGET_MODEL_FREQUENCY = 5\n",
    "    N_FRAMES = 3\n",
    "    HIDDEN_DIMENSION_FC = 150\n",
    "\n",
    "    GAS_WEIGHT = 1.3\n",
    "\n",
    "    ACTION_SPACE = [\n",
    "        (-1, 1, 0.2), (0, 1, 0.2), (1, 1, 0.2),\n",
    "        (-1, 1, 0), (0, 1, 0), (1, 1, 0),\n",
    "        (-1, 0, 0.2), (0, 0, 0.2), (1, 0, 0.2),\n",
    "        (-1, 0, 0), (0, 0, 0), (1, 0, 0)\n",
    "    ]\n",
    "\n",
    "\n",
    "############################################\n",
    "# DQN MODEL IN TENSORFLOW\n",
    "############################################\n",
    "\n",
    "class DQN(tf.keras.Model):\n",
    "    def __init__(self, n_frames, n_actions, h_dimension):\n",
    "        super(DQN, self).__init__()\n",
    "        # We will assume input shape: (batch, n_frames, 96, 96)\n",
    "        # Layers\n",
    "        self.conv1 = layers.Conv2D(6, kernel_size=(7, 7), strides=(3, 3), activation='relu', data_format='channels_first')\n",
    "        self.pool1 = layers.MaxPooling2D(pool_size=(2, 2), data_format='channels_first')\n",
    "        self.conv2 = layers.Conv2D(12, kernel_size=(4, 4), activation='relu', data_format='channels_first')\n",
    "        self.pool2 = layers.MaxPooling2D(pool_size=(2, 2), data_format='channels_first')\n",
    "        self.flatten = layers.Flatten()\n",
    "        self.fc1 = layers.Dense(h_dimension, activation='relu')\n",
    "        self.fc2 = layers.Dense(n_actions)\n",
    "\n",
    "        # To build the model and check shapes, we could run a dummy call once if needed:\n",
    "        # self.build((None, n_frames, 96, 96))\n",
    "\n",
    "    def call(self, x):\n",
    "        # x: (batch_size, n_frames, 96, 96)\n",
    "        x = self.conv1(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x  # (BS, ACTIONS)\n",
    "\n",
    "\n",
    "############################################\n",
    "# DQN AGENT\n",
    "############################################\n",
    "\n",
    "class DQNAgent:\n",
    "    def __init__(self,\n",
    "                 action_space,\n",
    "                 epsilon=1.0,\n",
    "                 gamma=0.95,\n",
    "                 epsilon_min=0.1,\n",
    "                 epsilon_decay=0.9999,\n",
    "                 lr=1e-3,\n",
    "                 memory_len=5000,\n",
    "                 frames=3,\n",
    "                 hidden_dimension=None):\n",
    "        self.epsilon = epsilon\n",
    "        self.gamma = gamma\n",
    "        self.epsilon_min = epsilon_min\n",
    "        self.epsilon_decay = epsilon_decay\n",
    "        self.memory_len = memory_len\n",
    "        self.lr = lr\n",
    "        self.memory = deque(maxlen=self.memory_len)\n",
    "        self.action_space = action_space\n",
    "\n",
    "        self.n_actions = len(self.action_space)\n",
    "        self.target_model = DQN(frames, self.n_actions, hidden_dimension)\n",
    "        self.model = DQN(frames, self.n_actions, hidden_dimension)\n",
    "\n",
    "        # Initialize by calling model once with dummy input\n",
    "        dummy_state = tf.random.uniform((1, frames, 96, 96), dtype=tf.float32)\n",
    "        self.model(dummy_state)\n",
    "        self.target_model(dummy_state)\n",
    "\n",
    "        self.optimizer = optimizers.Adam(learning_rate=self.lr)\n",
    "        self.loss_fn = losses.MeanSquaredError()\n",
    "\n",
    "    def update_target_model(self):\n",
    "        self.target_model.set_weights(self.model.get_weights())\n",
    "\n",
    "    def is_explore(self):\n",
    "        return np.random.rand() <= self.epsilon\n",
    "\n",
    "    def act(self, state, is_only_random=False, is_only_exploit=False):\n",
    "        # state: tensor shape (1, frames, 96, 96)\n",
    "        if (not is_only_exploit and self.is_explore()) or is_only_random:\n",
    "            action_index = np.random.randint(self.n_actions)\n",
    "        else:\n",
    "            q_values = self.target_model(state, training=False)[0]\n",
    "            action_index = tf.argmax(q_values).numpy()\n",
    "        return self.action_space[action_index]\n",
    "\n",
    "    def memorize(self, state, action, reward, next_state, done):\n",
    "        # state, next_state are tf Tensors\n",
    "        # action is tuple from action_space; we store index instead of action\n",
    "        action_index = self.action_space.index(action)\n",
    "        self.memory.append((state, action_index, reward, next_state, done))\n",
    "\n",
    "    def replay(self, batch_size):\n",
    "        minibatch = random.sample(self.memory, batch_size)\n",
    "        # Extract batch\n",
    "        states = []\n",
    "        actions = []\n",
    "        rewards = []\n",
    "        next_states = []\n",
    "        dones = []\n",
    "\n",
    "        for state, a_idx, r, n_s, d in minibatch:\n",
    "            states.append(state[0].numpy())     # state shape: (1, frames, h, w), take [0] to get (frames, h, w)\n",
    "            next_states.append(n_s[0].numpy())  # same for next_state\n",
    "            actions.append(a_idx)\n",
    "            rewards.append(r)\n",
    "            dones.append(d)\n",
    "\n",
    "        states = tf.convert_to_tensor(states, dtype=tf.float32)\n",
    "        next_states = tf.convert_to_tensor(next_states, dtype=tf.float32)\n",
    "        # Reshape states to (batch, frames, 96, 96)\n",
    "        # Already in that shape if each state was (frames, h, w)\n",
    "        states = tf.reshape(states, (batch_size, -1, 96, 96))\n",
    "        next_states = tf.reshape(next_states, (batch_size, -1, 96, 96))\n",
    "        actions = tf.convert_to_tensor(actions, dtype=tf.int32)\n",
    "        rewards = tf.convert_to_tensor(rewards, dtype=tf.float32)\n",
    "        dones = tf.convert_to_tensor(dones, dtype=tf.float32)\n",
    "\n",
    "        # Compute target\n",
    "        # Q(s,a) and Q'(s', a')\n",
    "        q_values = self.model(states, training=False)\n",
    "        q_next = self.target_model(next_states, training=False)\n",
    "        max_q_next = tf.reduce_max(q_next, axis=1)\n",
    "        # target for actions taken\n",
    "        # if done: target = reward\n",
    "        # else: target = reward + gamma * max_q_next\n",
    "        target_values = rewards + (1.0 - dones) * self.gamma * max_q_next\n",
    "\n",
    "        # Now we need to apply these target values only to the chosen actions\n",
    "        # Q-update: only update the chosen actions\n",
    "        action_one_hot = tf.one_hot(actions, self.n_actions, dtype=tf.float32)\n",
    "        q_selected = tf.reduce_sum(q_values * action_one_hot, axis=1)\n",
    "        # We want to minimize MSE between q_selected and target_values\n",
    "        with tf.GradientTape() as tape:\n",
    "            q_values_pred = self.model(states, training=True)\n",
    "            q_selected_pred = tf.reduce_sum(q_values_pred * action_one_hot, axis=1)\n",
    "            loss = self.loss_fn(target_values, q_selected_pred)\n",
    "        grads = tape.gradient(loss, self.model.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.model.trainable_variables))\n",
    "\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "\n",
    "    def load_model(self, name):\n",
    "        # Load the model from the SavedModel directory\n",
    "        self.target_model = tf.keras.models.load_model(name)\n",
    "        self.model = tf.keras.models.load_model(name)\n",
    "\n",
    "    def save_model(self, name):\n",
    "        self.target_model.save(name, save_format=\"tf\")\n",
    "\n",
    "\n",
    "############################################\n",
    "# MAIN TRAINING LOOP\n",
    "############################################\n",
    "\n",
    "def train_car_racing():\n",
    "    seed_everything(seed=Config.SEED)\n",
    "    PATH_ROOT = make_all_paths(is_dynamic_root=True)\n",
    "    util_config = {k: v for k, v in Config.__dict__.items() if not k.startswith('__')}\n",
    "    write_json_to_file(util_config, file_path=PATH_ROOT + \"config.json\")\n",
    "\n",
    "    device = \"GPU\" if len(tf.config.list_physical_devices('GPU')) > 0 else \"CPU\"\n",
    "    print('>> Using device:', device)\n",
    "\n",
    "    agent = DQNAgent(frames=Config.N_FRAMES, action_space=Config.ACTION_SPACE,\n",
    "                     hidden_dimension=Config.HIDDEN_DIMENSION_FC)\n",
    "\n",
    "    env = gym.make('CarRacing-v3', render_mode=\"rgb_array\")\n",
    "    from gymnasium.wrappers import RecordVideo\n",
    "    env = RecordVideo(env, os.path.join(PATH_ROOT, 'videos'),\n",
    "                      episode_trigger=lambda x: x % Config.UPDATE_TARGET_MODEL_FREQUENCY == 0)\n",
    "\n",
    "    epi_total_rewards = []\n",
    "    for e in range(Config.STARTING_EPISODE_TRAIN, Config.ENDING_EPISODE_TRAIN + 1):\n",
    "        env.episode_id = e\n",
    "        epi_total_reward = 0\n",
    "        epi_negative_reward_counter = 0\n",
    "        epi_time_frame_counter = 1\n",
    "        epi_done = False\n",
    "\n",
    "        init_state = env.reset(seed=e)[0]\n",
    "        init_state = preprocess_frame_car(init_state)\n",
    "\n",
    "        # State queue [S0, S0, S0] initially\n",
    "        state_queue = deque([init_state] * Config.N_FRAMES, maxlen=Config.N_FRAMES)\n",
    "\n",
    "        while True:\n",
    "            state_array = np.array(state_queue)  # shape (frames, 96, 96)\n",
    "            state_tensor = tf.convert_to_tensor(state_array, dtype=tf.float32)[tf.newaxis, ...]\n",
    "\n",
    "            action = agent.act(state_tensor)\n",
    "\n",
    "            reward = 0\n",
    "            for _ in range(Config.SKIP_FRAMES):\n",
    "                next_state, r, done, _, _ = env.step(action)\n",
    "                reward += r\n",
    "                if done:\n",
    "                    break\n",
    "\n",
    "            if epi_time_frame_counter > 100 and reward < 0:\n",
    "                epi_negative_reward_counter += 1\n",
    "            else:\n",
    "                epi_negative_reward_counter = 0\n",
    "\n",
    "            if action[1] == 1 and action[2] == 0:\n",
    "                reward *= Config.GAS_WEIGHT\n",
    "\n",
    "            epi_total_reward += reward\n",
    "\n",
    "            next_state = preprocess_frame_car(next_state)\n",
    "            next_state_queue = deque([frame for frame in state_queue], maxlen=Config.N_FRAMES)\n",
    "            next_state_queue.append(next_state)\n",
    "\n",
    "            next_state_array = np.array(next_state_queue)\n",
    "            next_state_tensor = tf.convert_to_tensor(next_state_array, dtype=tf.float32)[tf.newaxis, ...]\n",
    "\n",
    "            # Memorize\n",
    "            agent.memorize(state_tensor, action, reward, next_state_tensor, done)\n",
    "\n",
    "            state_queue = next_state_queue\n",
    "\n",
    "            if epi_negative_reward_counter >= 25 or epi_total_reward < 0:\n",
    "                break\n",
    "\n",
    "            if len(agent.memory) > Config.TRAINING_BATCH_SIZE:\n",
    "                agent.replay(Config.TRAINING_BATCH_SIZE)\n",
    "\n",
    "            epi_time_frame_counter += 1\n",
    "\n",
    "        epi_total_rewards.append(epi_total_reward)\n",
    "        stats_string = 'Episode: {}/{}, Scores(Time Frames): {}, Total Rewards: {:.2f}, Epsilon: {:.2f}'\n",
    "        print(stats_string.format(\n",
    "            e,\n",
    "            Config.ENDING_EPISODE_TRAIN,\n",
    "            epi_time_frame_counter,\n",
    "            float(epi_total_reward),\n",
    "            float(agent.epsilon))\n",
    "        )\n",
    "\n",
    "        if e % Config.UPDATE_TARGET_MODEL_FREQUENCY == 0:\n",
    "            plt.figure()\n",
    "            plt.plot(epi_total_rewards, label=\"cum rew\", color=\"blue\")\n",
    "            plt.title(\"Rewards during training episodes\")\n",
    "            plt.savefig(os.path.join(PATH_ROOT, 'plots', f'reward_{e}.pdf'))\n",
    "            plt.close()\n",
    "\n",
    "            # Save the model in SavedModel format (no .h5 extension)\n",
    "            agent.save_model(os.path.join(PATH_ROOT, \"models\", f\"model_{e}\"))\n",
    "            agent.update_target_model()\n",
    "            write_json_to_file({\"CUM_REW\": epi_total_rewards}, os.path.join(PATH_ROOT, \"stats.json\"))\n",
    "\n",
    "    env.close()\n",
    "\n",
    "\n",
    "############################################\n",
    "# TEST FUNCTION\n",
    "############################################\n",
    "\n",
    "def test_car_racing(model_to_load):\n",
    "    device = \"GPU\" if len(tf.config.list_physical_devices('GPU')) > 0 else \"CPU\"\n",
    "    print('>> Using device:', device)\n",
    "\n",
    "    env = gym.make('CarRacing-v2', render_mode=\"human\")\n",
    "    seed_everything(seed=Config.SEED)\n",
    "\n",
    "    agent = DQNAgent(frames=Config.N_FRAMES, action_space=Config.ACTION_SPACE,\n",
    "                     hidden_dimension=Config.HIDDEN_DIMENSION_FC)\n",
    "    agent.load_model(model_to_load)\n",
    "\n",
    "    PICKED_EPISODES = [1]\n",
    "    for e in PICKED_EPISODES:\n",
    "        env.episode_id = e\n",
    "        init_state = env.reset(seed=e)[0]\n",
    "        init_state = preprocess_frame_car(init_state)\n",
    "\n",
    "        state_queue = deque([init_state] * Config.N_FRAMES, maxlen=Config.N_FRAMES)\n",
    "        epi_n_neg_rew = 0\n",
    "\n",
    "        while True:\n",
    "            state_array = np.array(state_queue)\n",
    "            state_tensor = tf.convert_to_tensor(state_array, dtype=tf.float32)[tf.newaxis, ...]\n",
    "            action = agent.act(state_tensor, is_only_exploit=True)\n",
    "\n",
    "            reward = 0\n",
    "            for _ in range(Config.SKIP_FRAMES):\n",
    "                next_state, r, epi_done, _, _ = env.step(action)\n",
    "                reward += r\n",
    "                if epi_done:\n",
    "                    break\n",
    "\n",
    "            epi_n_neg_rew = epi_n_neg_rew + 1 if reward <= 0 else 0\n",
    "            if epi_n_neg_rew >= 100:\n",
    "                break\n",
    "\n",
    "            next_state = preprocess_frame_car(next_state)\n",
    "            next_state_queue = deque([frame for frame in state_queue], maxlen=Config.N_FRAMES)\n",
    "            next_state_queue.append(next_state)\n",
    "            state_queue = next_state_queue\n",
    "    env.close()\n",
    "    \n",
    "print(\"Everything loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Created dir reinforcement_learning/rl_class_20241210_114018/models\n",
      ">> Created dir reinforcement_learning/rl_class_20241210_114018/plots\n",
      ">> Created dir reinforcement_learning/rl_class_20241210_114018/videos\n",
      "JSON data successfully written to reinforcement_learning/rl_class_20241210_114018/config.json\n",
      ">> Using device: GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\andri\\miniconda3\\envs\\tf\\lib\\site-packages\\gymnasium\\wrappers\\rendering.py:283: UserWarning: \u001b[33mWARN: Overwriting existing videos at c:\\Users\\andri\\Documents\\GitHub\\Homework-2\\reinforcement_learning\\rl_class_20241210_114018\\videos folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 0/100, Scores(Time Frames): 133, Total Rewards: 12.44, Epsilon: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: reinforcement_learning/rl_class_20241210_114018/models\\model_0\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: reinforcement_learning/rl_class_20241210_114018/models\\model_0\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON data successfully written to reinforcement_learning/rl_class_20241210_114018/stats.json\n",
      "Episode: 1/100, Scores(Time Frames): 184, Total Rewards: 18.99, Epsilon: 0.97\n",
      "Episode: 2/100, Scores(Time Frames): 100, Total Rewards: -0.01, Epsilon: 0.96\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 6\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m############################################\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# MAIN EXECUTION\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m############################################\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# To train:\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[43mtrain_car_racing\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# To test:\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# args = parse_args()\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# test_car_racing(model_to_load=args['mod'])\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[4], line 347\u001b[0m, in \u001b[0;36mtrain_car_racing\u001b[1;34m()\u001b[0m\n\u001b[0;32m    344\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    346\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(agent\u001b[38;5;241m.\u001b[39mmemory) \u001b[38;5;241m>\u001b[39m Config\u001b[38;5;241m.\u001b[39mTRAINING_BATCH_SIZE:\n\u001b[1;32m--> 347\u001b[0m         \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplay\u001b[49m\u001b[43m(\u001b[49m\u001b[43mConfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTRAINING_BATCH_SIZE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    349\u001b[0m     epi_time_frame_counter \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    351\u001b[0m epi_total_rewards\u001b[38;5;241m.\u001b[39mappend(epi_total_reward)\n",
      "Cell \u001b[1;32mIn[4], line 233\u001b[0m, in \u001b[0;36mDQNAgent.replay\u001b[1;34m(self, batch_size)\u001b[0m\n\u001b[0;32m    230\u001b[0m next_states \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconvert_to_tensor(next_states, dtype\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m    231\u001b[0m \u001b[38;5;66;03m# Reshape states to (batch, frames, 96, 96)\u001b[39;00m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;66;03m# Already in that shape if each state was (frames, h, w)\u001b[39;00m\n\u001b[1;32m--> 233\u001b[0m states \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m96\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m96\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    234\u001b[0m next_states \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mreshape(next_states, (batch_size, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m96\u001b[39m, \u001b[38;5;241m96\u001b[39m))\n\u001b[0;32m    235\u001b[0m actions \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconvert_to_tensor(actions, dtype\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mint32)\n",
      "File \u001b[1;32mc:\\Users\\andri\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\andri\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1176\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1174\u001b[0m \u001b[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[0;32m   1175\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1176\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m dispatch_target(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1177\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[0;32m   1178\u001b[0m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m   1179\u001b[0m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m   1180\u001b[0m   result \u001b[38;5;241m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[1;32mc:\\Users\\andri\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:199\u001b[0m, in \u001b[0;36mreshape\u001b[1;34m(tensor, shape, name)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreshape\u001b[39m\u001b[38;5;124m\"\u001b[39m, v1\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreshape\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmanip.reshape\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     64\u001b[0m \u001b[38;5;129m@dispatch\u001b[39m\u001b[38;5;241m.\u001b[39madd_dispatch_support\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreshape\u001b[39m(tensor, shape, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):  \u001b[38;5;66;03m# pylint: disable=redefined-outer-name\u001b[39;00m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Reshapes a tensor.\u001b[39;00m\n\u001b[0;32m     67\u001b[0m \n\u001b[0;32m     68\u001b[0m \u001b[38;5;124;03m  Given `tensor`, this operation returns a new `tf.Tensor` that has the same\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    197\u001b[0m \u001b[38;5;124;03m    A `Tensor`. Has the same type as `tensor`.\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 199\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[43mgen_array_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    200\u001b[0m   tensor_util\u001b[38;5;241m.\u001b[39mmaybe_set_static_shape(result, shape)\n\u001b[0;32m    201\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\andri\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py:8545\u001b[0m, in \u001b[0;36mreshape\u001b[1;34m(tensor, shape, name)\u001b[0m\n\u001b[0;32m   8543\u001b[0m   \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m   8544\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 8545\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mreshape_eager_fallback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   8546\u001b[0m \u001b[43m      \u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_ctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   8547\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_SymbolicException:\n\u001b[0;32m   8548\u001b[0m   \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# Add nodes to the TensorFlow graph.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\andri\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py:8570\u001b[0m, in \u001b[0;36mreshape_eager_fallback\u001b[1;34m(tensor, shape, name, ctx)\u001b[0m\n\u001b[0;32m   8568\u001b[0m _inputs_flat \u001b[38;5;241m=\u001b[39m [tensor, shape]\n\u001b[0;32m   8569\u001b[0m _attrs \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mT\u001b[39m\u001b[38;5;124m\"\u001b[39m, _attr_T, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTshape\u001b[39m\u001b[38;5;124m\"\u001b[39m, _attr_Tshape)\n\u001b[1;32m-> 8570\u001b[0m _result \u001b[38;5;241m=\u001b[39m \u001b[43m_execute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mReshape\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_inputs_flat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_attrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   8571\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   8572\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _execute\u001b[38;5;241m.\u001b[39mmust_record_gradient():\n\u001b[0;32m   8573\u001b[0m   _execute\u001b[38;5;241m.\u001b[39mrecord_gradient(\n\u001b[0;32m   8574\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReshape\u001b[39m\u001b[38;5;124m\"\u001b[39m, _inputs_flat, _attrs, _result)\n",
      "File \u001b[1;32mc:\\Users\\andri\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "############################################\n",
    "# MAIN EXECUTION\n",
    "############################################\n",
    "\n",
    "# To train:\n",
    "train_car_racing()\n",
    "# To test:\n",
    "# args = parse_args()\n",
    "# test_car_racing(model_to_load=args['mod'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
